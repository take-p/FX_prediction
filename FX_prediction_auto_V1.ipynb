{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリをインポートする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.initializers import glorot_uniform, orthogonal, TruncatedNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.recurrent import GRU, SimpleRNN\n",
    "\n",
    "import pandas as pd #行列計算\n",
    "import numpy as np #行列計算\n",
    "import math #数値計算\n",
    "import itertools #順列・組み合わせ\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt #グラフ\n",
    "import winsound # ビープ音\n",
    "\n",
    "from df_method import rise_fall_rate, moving_average, GCDC, df_shift, add_data, RSI, Z_score_normalization, Min_Max_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワーク構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    #初期化\n",
    "    def __init__(self, maxlen, n_hidden, n_in, n_out, learning_model):\n",
    "        self.maxlen = maxlen #入力系列数\n",
    "        self.n_hidden = n_hidden #出力次元（隠れ層内のニューロン数）\n",
    "        self.n_in = n_in #学習データの列数\n",
    "        self.n_out = n_out #ラベルデータの列数\n",
    "        \n",
    "        self.learning_model = learning_model #●学習モデルの選択\n",
    "\n",
    "    #モデルの生成\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        if self.learning_model == 'RNN':\n",
    "            #RNN層\n",
    "            model.add(SimpleRNN(self.n_hidden,\n",
    "                                batch_input_shape = (None, self.maxlen, self.n_in),\n",
    "                                kernel_initializer = glorot_uniform(seed=20170719),\n",
    "                                recurrent_initializer = orthogonal(gain=1.0, seed=20170719),\n",
    "                                dropout = 0.5,\n",
    "                                recurrent_dropout = 0.5))\n",
    "        elif self.learning_model == 'LSTM':\n",
    "            #LSTM層\n",
    "            model.add(LSTM(self.n_hidden,\n",
    "                           batch_input_shape = (None, self.maxlen, self.n_in),\n",
    "                           kernel_initializer = glorot_uniform(seed=20170719), \n",
    "                           recurrent_initializer = orthogonal(gain=1.0, seed=20170719), \n",
    "                           dropout = 0.5, \n",
    "                           recurrent_dropout = 0.5))\n",
    "        elif self.learning_model == 'GRU':\n",
    "            #GRU層\n",
    "            model.add(GRU(self.n_hidden,\n",
    "                          batch_input_shape = (None, self.maxlen, self.n_in),\n",
    "                          kernel_initializer = glorot_uniform(seed=20170719),\n",
    "                          recurrent_initializer = orthogonal(gain=1.0, seed=20170719),\n",
    "                          dropout = 0.5,\n",
    "                          recurrent_dropout = 0.5))\n",
    "        #ドロップアウト層\n",
    "        model.add(Dropout(0.5))\n",
    "        #結合層\n",
    "        model.add(Dense(self.n_out, kernel_initializer = glorot_uniform(seed=20170719)))\n",
    "        #活性化層\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        #コンパイル\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer = \"Adam\", metrics = ['categorical_accuracy']) # \"RMSprop\"\n",
    "        return model\n",
    "\n",
    "    # 学習\n",
    "    def train(self, x_train, t_train, batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=0, verbose=1)\n",
    "        model = self.create_model()\n",
    "        self.hist = model.fit(x_train, t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "                              shuffle = True, callbacks = [early_stopping], validation_split = 0.1)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変数宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_debug = True\n",
    "csv_path = './csv_realtime/'\n",
    "day_list = ['1'] # '1', '2', '7', '30', '365'\n",
    "learning_model_list = ['LSTM']#['RNN', 'LSTM', 'GRU']\n",
    "year_list = ['2013']#  '1960', '1970', '1980', '1990', '2000', '2010'\n",
    "end_date = '2018-10-31'# 終点年月日\n",
    "\n",
    "min_maxlen = 100\n",
    "max_maxlen = 1000\n",
    "min_n_hidden = 100\n",
    "max_n_hidden = 500\n",
    "\n",
    "target_name = 'USD_JPY_diff'# 'nikkei_Close', 'nikkei_diff', 'USD_JPY'\n",
    "max_score = 0 # 最高正答率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メイン処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            USD_JPY_Open  USD_JPY_High  USD_JPY_Low  USD_JPY_Close  \\\n",
      "Date                                                                 \n",
      "2008-11-13     -2.719703      0.173178     0.052907       2.771180   \n",
      "2008-11-14      2.781128     -0.183374     1.678420      -0.616082   \n",
      "2008-11-17     -1.484716     -0.521394    -0.197845      -0.671733   \n",
      "2008-11-18      0.155691     -0.143604     0.093765       0.599609   \n",
      "2008-11-19      0.620349     -0.267242    -0.375587      -1.338541   \n",
      "2008-11-20     -1.338541     -0.972187    -2.230183      -2.122012   \n",
      "2008-11-21     -2.122012     -0.260159     0.106826       2.361982   \n",
      "2008-11-25      1.407017      0.082144     0.010531      -2.191499   \n",
      "2008-11-26     -2.191499     -1.541118    -0.369257       0.450522   \n",
      "2008-11-27      0.450522     -0.229573     0.421897      -0.408527   \n",
      "2008-11-28     -0.513547      0.000000     0.136734       0.303936   \n",
      "2008-12-01      0.398490     -0.167294    -2.210504      -2.489931   \n",
      "2008-12-02     -2.468738     -1.848286    -0.452343      -0.032191   \n",
      "2008-12-03     -0.042918     -0.213424    -0.108003       0.117981   \n",
      "2008-12-04      0.117981     -0.213881    -0.498322      -1.131905   \n",
      "2008-12-05     -1.131905     -0.042831    -0.522649       0.831314   \n",
      "2008-12-08      0.508247      0.555379     1.074987      -0.204488   \n",
      "2008-12-09      0.118579     -0.887944    -0.704495      -0.757006   \n",
      "2008-12-10     -0.757006     -0.042992     0.163017       0.692344   \n",
      "2008-12-11      0.692344     -0.150619    -1.004046      -1.466063   \n",
      "2008-12-12     -1.411379     -1.104266    -3.130652      -0.405591   \n",
      "2008-12-15     -0.537194     -0.556740     2.116422      -0.429303   \n",
      "2008-12-16     -0.352384     -0.681022    -1.777477      -1.792023   \n",
      "2008-12-17     -1.769564     -1.689492    -1.706332      -2.030815   \n",
      "2008-12-18     -2.064736      0.914981     0.034414       2.479045   \n",
      "2008-12-19      2.501687     -0.211264     1.434778      -0.369645   \n",
      "2008-12-22     -0.179031      0.665634     0.922806       1.282283   \n",
      "2008-12-24      0.794531     -0.010991     0.377443      -0.584249   \n",
      "2008-12-29      0.231903      0.099245    -0.566574       0.364581   \n",
      "2008-12-30      0.011030      0.264172     0.300351      -0.375650   \n",
      "...                  ...           ...          ...            ...   \n",
      "2018-09-28      0.637114      0.211323     0.593421       0.264224   \n",
      "2018-10-01      0.281864      0.289843     0.396599       0.237206   \n",
      "2018-10-02      0.228431     -0.008771    -0.140833      -0.254800   \n",
      "2018-10-03     -0.263621      0.437599    -0.026428       0.736264   \n",
      "2018-10-04      0.701450      0.000000     0.105671      -0.525349   \n",
      "2018-10-05     -0.516842     -0.393753    -0.044016      -0.184526   \n",
      "2018-10-09     -0.440762     -0.484007     0.044309      -0.247612   \n",
      "2018-10-10     -0.194553     -0.105914    -0.524096      -0.586095   \n",
      "2018-10-11     -0.630469     -0.664513    -0.410532      -0.124766   \n",
      "2018-10-12     -0.142628     -0.008890     0.044705       0.035663   \n",
      "2018-10-15      0.062425     -0.258157    -0.223724      -0.375101   \n",
      "2018-10-16     -0.366186      0.089095     0.107450       0.419662   \n",
      "2018-10-17      0.437481      0.311208     0.223484       0.346898   \n",
      "2018-10-18      0.337958      0.044379    -0.071460      -0.400374   \n",
      "2018-10-19     -0.418169     -0.079897     0.169635       0.320428   \n",
      "2018-10-22      0.320456      0.212917     0.204964       0.204181   \n",
      "2018-10-23      0.204199     -0.035455    -0.338862      -0.328670   \n",
      "2018-10-24     -0.319801     -0.088692     0.133899      -0.169197   \n",
      "2018-10-25     -0.187024     -0.062131    -0.250089       0.151400   \n",
      "2018-10-26      0.187024     -0.204417    -0.394266      -0.437013   \n",
      "2018-10-29     -0.463748      0.097817     0.358488       0.401410   \n",
      "2018-10-30      0.410348      0.461116     0.455216       0.621230   \n",
      "2018-10-31      0.621230      0.282711     0.444287      -0.035395   \n",
      "2018-11-01     -0.061950     -0.335808    -0.159716      -0.283613   \n",
      "2018-11-02     -0.274811      0.265205    -0.044411       0.469297   \n",
      "2018-11-05      0.460545      0.017655     0.443224      -0.017669   \n",
      "2018-11-06      0.008836      0.141131     0.026531       0.211827   \n",
      "2018-11-07      0.194192      0.281666    -0.132726       0.105746   \n",
      "2018-11-08      0.105764      0.237040     0.476991       0.430637   \n",
      "2018-11-09      0.460531      0.023673     0.140895      -0.230028   \n",
      "\n",
      "            EUR_JPY_Open  EUR_JPY_High  EUR_JPY_Low  EUR_JPY_Close  \\\n",
      "Date                                                                 \n",
      "2008-11-13     -2.929305      1.713275    -0.381728       4.943941   \n",
      "2008-11-14      4.929129     -0.206595     3.104462      -1.274108   \n",
      "2008-11-17     -3.300361     -1.474386    -0.976991      -0.995033   \n",
      "2008-11-18      1.046698     -0.234372     0.688200       0.343671   \n",
      "2008-11-19      0.368264      0.548698    -1.263945      -2.363942   \n",
      "2008-11-20     -2.363942     -2.534463    -2.594025      -2.412611   \n",
      "2008-11-21     -2.412611     -0.355534     0.051515       3.345019   \n",
      "2008-11-25      4.080216      0.118920     2.535335      -1.301468   \n",
      "2008-11-26     -1.301468     -1.267808    -0.556057      -0.977193   \n",
      "2008-11-27     -0.977193     -0.773324     0.425498      -0.227494   \n",
      "2008-11-28     -0.194964     -0.186167    -1.621635      -1.301750   \n",
      "2008-12-01     -1.391982     -1.608920    -2.648883      -3.207040   \n",
      "2008-12-02     -3.132322     -1.651970    -0.658319       0.788240   \n",
      "2008-12-03      0.771223     -0.167546     0.197095       0.160277   \n",
      "2008-12-04      0.160277      0.016767    -0.377391      -0.651138   \n",
      "2008-12-05     -0.668107     -0.453706    -0.413330       0.347237   \n",
      "2008-12-08      0.076339      1.852214     1.736496       1.660137   \n",
      "2008-12-09      1.948005     -0.572022     0.414675      -0.977656   \n",
      "2008-12-10     -0.977656      0.976263     0.513837       1.409120   \n",
      "2008-12-11      1.409120      1.032035     1.061395       1.070586   \n",
      "2008-12-12      1.119722     -0.154944    -2.210638      -0.246043   \n",
      "2008-12-15     -0.229508      1.667245     3.343116       1.871038   \n",
      "2008-12-16      1.805367      0.703834     0.737044       0.538522   \n",
      "2008-12-17      0.498433      1.030773     1.353398       0.846110   \n",
      "2008-12-18      0.878249      3.282290     1.144516       1.287283   \n",
      "2008-12-19      1.287385     -2.144978    -1.555890      -2.696096   \n",
      "2008-12-22     -2.494965     -1.263604     0.451614       1.408812   \n",
      "2008-12-24      0.728774     -0.126064     0.262248       0.007891   \n",
      "2008-12-29      0.731222      2.253419    -0.150406      -0.260983   \n",
      "2008-12-30     -1.094887     -1.233482    -0.007922       0.537041   \n",
      "...                  ...           ...          ...            ...   \n",
      "2018-09-28     -0.272438     -0.309539    -0.312060      -0.068210   \n",
      "2018-10-01     -0.037897      0.143564     0.433576       0.030321   \n",
      "2018-10-02      0.015161     -0.347932    -0.800157      -0.531957   \n",
      "2018-10-03     -0.539617      0.000000     0.191095       0.167491   \n",
      "2018-10-04      0.068564     -0.303536    -0.168144      -0.220843   \n",
      "2018-10-05     -0.175312     -0.159726    -0.084178      -0.114421   \n",
      "2018-10-09     -0.735410     -0.780298    -0.146837      -0.238563   \n",
      "2018-10-10     -0.200108      0.207143    -0.015469      -0.385982   \n",
      "2018-10-11     -0.424629     -0.222504    -0.085123       0.563034   \n",
      "2018-10-12      0.509339      0.222504     0.154715      -0.277265   \n",
      "2018-10-15     -0.262063     -0.537925    -0.216668      -0.200726   \n",
      "2018-10-16     -0.108108      0.376851     0.232126       0.385654   \n",
      "2018-10-17      0.439426     -0.099843    -0.177915      -0.269802   \n",
      "2018-10-18     -0.346754     -0.330960    -0.668067      -0.844934   \n",
      "2018-10-19     -0.852718     -0.053981     0.109060       0.898952   \n",
      "2018-10-22      0.821837      0.392625     0.605451      -0.223982   \n",
      "2018-10-23     -0.154548     -0.616572    -0.808085      -0.302010   \n",
      "2018-10-24     -0.286544     -0.146996    -0.312549      -0.841126   \n",
      "2018-10-25     -0.895889     -0.605733    -0.219367      -0.031289   \n",
      "2018-10-26      0.039119     -0.398049    -0.716285      -0.180103   \n",
      "2018-10-29     -0.266312      0.242140     0.535730       0.156629   \n",
      "2018-10-30      0.211541      0.155909     0.376442       0.367116   \n",
      "2018-10-31      0.382768      0.085646    -0.054810      -0.351467   \n",
      "2018-11-01     -0.398422      0.171073    -0.039168       0.577315   \n",
      "2018-11-02      0.562018      0.434143     0.593705       0.287412   \n",
      "2018-11-05      0.341907      0.000000     0.178981       0.162759   \n",
      "2018-11-06      0.155027      0.239521     0.194182       0.347880   \n",
      "2018-11-07      0.332496      0.392807     0.379507       0.115692   \n",
      "2018-11-08      0.069452     -0.015375     0.030917      -0.123409   \n",
      "2018-11-09     -0.038579     -0.346567    -0.519119      -0.448639   \n",
      "\n",
      "            nikkei_Open  nikkei_High  nikkei_Low  nikkei_Close  \\\n",
      "Date                                                             \n",
      "2008-11-13    -1.511560    -2.513666   -5.094842     -5.397153   \n",
      "2008-11-14    -2.199749     1.453341    2.781543      2.679636   \n",
      "2008-11-17    -0.134368     0.895087   -1.919804      0.708752   \n",
      "2008-11-18     0.580604    -3.807560    1.009870     -2.304654   \n",
      "2008-11-19    -1.270574    -0.836629   -2.272370     -0.664882   \n",
      "2008-11-20    -1.939163    -2.667245   -5.218662     -7.140870   \n",
      "2008-11-21    -6.979540    -1.921582   -3.930025      2.661259   \n",
      "2008-11-25     5.449944     4.430284    8.033283      5.090681   \n",
      "2008-11-26     2.505820    -0.467777    1.531631     -1.338944   \n",
      "2008-11-27     0.985688     1.679168    1.835063      1.931376   \n",
      "2008-11-28     1.062879     0.700372    0.433732      1.644982   \n",
      "2008-12-01     0.762681    -0.633237   -0.351963     -1.360793   \n",
      "2008-12-02    -2.367498    -2.367498   -5.487632     -6.564471   \n",
      "2008-12-03    -3.709360    -2.572516    0.331734      1.769797   \n",
      "2008-12-04     0.811359     0.634868   -0.508017     -1.002748   \n",
      "2008-12-05    -0.689156    -1.033480    0.746396     -0.084971   \n",
      "2008-12-08    -0.054684     4.077323    0.634751      5.067265   \n",
      "2008-12-09     4.797084     1.676765    4.373843      0.799055   \n",
      "2008-12-10     0.162858     2.386932    0.732745      3.100253   \n",
      "2008-12-11     3.129362     0.179391    1.694144      0.693982   \n",
      "2008-12-12    -0.500421    -1.267313   -5.193164     -5.718327   \n",
      "2008-12-15    -2.941636     1.033340    3.186325      5.075368   \n",
      "2008-12-16     3.049499    -0.760457    1.443340     -1.121609   \n",
      "2008-12-17     0.577061     1.231410   -0.539509      0.518029   \n",
      "2008-12-18    -1.080630    -0.147455    1.287476      0.633240   \n",
      "2008-12-19     0.872518     0.170098    0.417643     -0.912293   \n",
      "2008-12-22    -0.437516     0.091000    0.270331      1.562629   \n",
      "2008-12-24     0.322061    -1.373197   -1.371624     -2.397680   \n",
      "2008-12-29     0.969235     0.261764    0.315818      0.087500   \n",
      "2008-12-30    -0.114998     1.088230    0.742158      1.276684   \n",
      "...                 ...          ...         ...           ...   \n",
      "2018-09-28     0.556279     0.813555    1.017724      1.349439   \n",
      "2018-10-01     0.386955     0.084126    0.424680      0.519876   \n",
      "2018-10-02     0.835443     0.580588    0.387912      0.102478   \n",
      "2018-10-03    -0.646074    -0.769638   -0.773800     -0.659998   \n",
      "2018-10-04     0.094389    -0.052818   -0.447640     -0.562910   \n",
      "2018-10-05    -1.917027    -1.325153   -0.810314     -0.803610   \n",
      "2018-10-09    -0.977308    -1.437733   -1.219911     -1.330430   \n",
      "2018-10-10    -0.049059     0.009878   -0.294437      0.156032   \n",
      "2018-10-11    -2.127716    -2.307928   -3.991228     -3.971200   \n",
      "2018-10-12    -3.174127    -1.486222   -0.605551      0.458429   \n",
      "2018-10-15     0.793764    -0.842516   -0.275919     -1.883077   \n",
      "2018-10-16    -0.906850     0.127138    0.034175      1.240248   \n",
      "2018-10-17     2.254360     1.802651    2.203040      1.286101   \n",
      "2018-10-18     0.283242    -0.376498   -0.565124     -0.804232   \n",
      "2018-10-19    -2.341363    -1.415378   -1.894015     -0.557998   \n",
      "2018-10-22     0.144068     0.533259    0.265351      0.366538   \n",
      "2018-10-23     0.133679    -1.162771   -1.258445     -2.707316   \n",
      "2018-10-24    -1.060682    -0.910240   -0.371946      0.364612   \n",
      "2018-10-25    -2.239502    -2.295138   -3.279923     -3.794048   \n",
      "2018-10-26    -1.094644    -1.049345   -1.102386     -0.396346   \n",
      "2018-10-29    -0.548263    -0.049694    0.656061     -0.164400   \n",
      "2018-10-30    -1.293715     0.475947   -0.351588      1.443392   \n",
      "2018-10-31     2.440535     1.619119    2.323586      2.135609   \n",
      "2018-11-01     1.549621    -0.064119    0.454409     -1.067750   \n",
      "2018-11-02    -0.663326     1.818489    0.566537      2.531404   \n",
      "2018-11-05     1.100872    -1.157674    0.525712     -1.561650   \n",
      "2018-11-06     0.074502     0.493887    0.585036      1.129538   \n",
      "2018-11-07     0.773026     1.272598    0.012094     -0.280101   \n",
      "2018-11-08     1.148283     0.616414    1.909469      1.799890   \n",
      "2018-11-09     0.112655    -0.394204   -0.873481     -1.058056   \n",
      "\n",
      "            nikkei_Adj Close  USD_JPY_diff  treasury_10_Close  \\\n",
      "Date                                                            \n",
      "2008-11-13         -5.397153      2.760657           5.326072   \n",
      "2008-11-14          2.679636     -0.636552          -3.295408   \n",
      "2008-11-17          0.708752      0.176431          -1.975974   \n",
      "2008-11-18         -2.304654      0.620349          -3.590201   \n",
      "2008-11-19         -0.664882     -1.338541          -5.594234   \n",
      "2008-11-20         -7.140870     -2.122012         -10.379679   \n",
      "2008-11-21          2.661259      2.361982           6.903720   \n",
      "2008-11-25          5.090681     -2.191499          -6.772774   \n",
      "2008-11-26         -1.338944      0.450522          -4.000533   \n",
      "2008-11-27          1.931376     -0.408527           0.533868   \n",
      "2008-11-28          1.644982      0.408956          -2.869395   \n",
      "2008-12-01         -1.360793     -2.479466          -6.764837   \n",
      "2008-12-02         -6.564471     -0.042918          -1.327943   \n",
      "2008-12-03          1.769797      0.117981          -1.345815   \n",
      "2008-12-04         -1.002748     -1.131905          -3.992853   \n",
      "2008-12-05         -0.084971      0.831314           5.598263   \n",
      "2008-12-08          5.067265      0.118579           1.580044   \n",
      "2008-12-09          0.799055     -0.757006          -3.373814   \n",
      "2008-12-10          3.100253      0.692344           1.385530   \n",
      "2008-12-11          0.693982     -1.466063          -3.020237   \n",
      "2008-12-12         -5.718327     -0.460275          -1.272920   \n",
      "2008-12-15          5.075368     -0.352384          -2.237581   \n",
      "2008-12-16         -1.121609     -1.792023         -10.672884   \n",
      "2008-12-17          0.518029     -2.053274          -2.867580   \n",
      "2008-12-18          0.633240      2.490507          -5.368851   \n",
      "2008-12-19         -0.912293     -0.380825           2.182250   \n",
      "2008-12-22          1.562629      1.080489           1.951735   \n",
      "2008-12-24         -2.397680     -0.584249           0.228781   \n",
      "2008-12-29          0.087500      0.022058          -1.556268   \n",
      "2008-12-30          1.276684     -0.364621          -2.307795   \n",
      "...                      ...           ...                ...   \n",
      "2018-09-28          1.349439      0.281864           0.326798   \n",
      "2018-10-01          0.519876      0.237206           0.552398   \n",
      "2018-10-02          0.102478     -0.246024          -0.813409   \n",
      "2018-10-03         -0.659998      0.753861           3.845395   \n",
      "2018-10-04         -0.562910     -0.472938           0.188442   \n",
      "2018-10-05         -0.803610     -0.140622           1.433046   \n",
      "2018-10-09         -1.330430     -0.221112          -0.776763   \n",
      "2018-10-10          0.156032     -0.612655          -1.003143   \n",
      "2018-10-11         -3.971200     -0.106952          -0.886082   \n",
      "2018-10-12          0.458429      0.071339           0.665296   \n",
      "2018-10-15         -1.883077     -0.366186          -0.095012   \n",
      "2018-10-16          1.240248      0.419662           0.221554   \n",
      "2018-10-17          1.286101      0.329079           1.381498   \n",
      "2018-10-18         -0.804232     -0.409253          -0.939857   \n",
      "2018-10-19         -0.557998      0.329343           0.596267   \n",
      "2018-10-22          0.366538      0.213068           0.250313   \n",
      "2018-10-23         -2.707316     -0.319801          -0.910381   \n",
      "2018-10-24          0.364612     -0.169197          -1.910278   \n",
      "2018-10-25         -3.794048      0.169227           0.481001   \n",
      "2018-10-26         -0.396346     -0.454810          -1.579914   \n",
      "2018-10-29         -0.164400      0.410348           0.194427   \n",
      "2018-10-30          1.443392      0.621230           0.966502   \n",
      "2018-10-31          2.135609     -0.035395           0.957250   \n",
      "2018-11-01         -1.067750     -0.257058          -0.477480   \n",
      "2018-11-02          2.531404      0.487050           2.707122   \n",
      "2018-11-05         -1.561650      0.008836          -0.280768   \n",
      "2018-11-06          1.129538      0.211827           0.932843   \n",
      "2018-11-07         -0.280101      0.123381           0.185529   \n",
      "2018-11-08          1.799890      0.448254           0.061767   \n",
      "2018-11-09         -1.058056     -0.242305          -1.649843   \n",
      "\n",
      "            treasury_10_Open  treasury_10_High  treasury_10_Low  \n",
      "Date                                                             \n",
      "2008-11-13          5.326072          5.326072         5.326072  \n",
      "2008-11-14         -3.295408         -3.295408        -3.295408  \n",
      "2008-11-17         -1.975974         -1.975974        -1.975974  \n",
      "2008-11-18         -3.590201         -3.590201        -3.590201  \n",
      "2008-11-19         -5.594234         -5.594234        -5.594234  \n",
      "2008-11-20        -10.379679        -10.379679       -10.379679  \n",
      "2008-11-21          6.903720          6.903720         6.903720  \n",
      "2008-11-25         -6.772774         -6.772774        -6.772774  \n",
      "2008-11-26         -4.000533         -4.000533        -4.000533  \n",
      "2008-11-27          0.533868          0.533868         0.533868  \n",
      "2008-11-28         -2.869395         -2.869395        -2.869395  \n",
      "2008-12-01         -6.764837         -6.764837        -6.764837  \n",
      "2008-12-02         -1.327943         -1.327943        -1.327943  \n",
      "2008-12-03         -1.345815         -1.345815        -1.345815  \n",
      "2008-12-04         -3.992853         -3.992853        -3.992853  \n",
      "2008-12-05          5.598263          5.598263         5.598263  \n",
      "2008-12-08          1.580044          1.580044         1.580044  \n",
      "2008-12-09         -3.373814         -3.373814        -3.373814  \n",
      "2008-12-10          1.385530          1.385530         1.385530  \n",
      "2008-12-11         -3.020237         -3.020237        -3.020237  \n",
      "2008-12-12         -1.272920         -1.272920        -1.272920  \n",
      "2008-12-15         -2.237581         -2.237581        -2.237581  \n",
      "2008-12-16        -10.672884        -10.672884       -10.672884  \n",
      "2008-12-17         -2.867580         -2.867580        -2.867580  \n",
      "2008-12-18         -5.368851         -5.368851        -5.368851  \n",
      "2008-12-19          2.182250          2.182250         2.182250  \n",
      "2008-12-22          1.951735          1.951735         1.951735  \n",
      "2008-12-24          0.228781          0.228781         0.228781  \n",
      "2008-12-29         -1.556268         -1.556268        -1.556268  \n",
      "2008-12-30         -2.307795         -2.307795        -2.307795  \n",
      "...                      ...               ...              ...  \n",
      "2018-09-28         -0.196657         -0.293208        -0.132100  \n",
      "2018-10-01         -0.065189          0.843613        -0.195695  \n",
      "2018-10-02          0.649986         -0.258816        -0.556557  \n",
      "2018-10-03         -0.845809          3.188029         0.131234  \n",
      "2018-10-04          4.378395          1.402111         4.048095  \n",
      "2018-10-05         -0.156470          0.493828         0.345749  \n",
      "2018-10-09         -0.185529          0.738692        -0.870382  \n",
      "2018-10-10         -0.527542         -0.522676        -1.193482  \n",
      "2018-10-11         -1.599532         -1.522005        -1.303882  \n",
      "2018-10-12         -0.284946         -0.344882         0.223821  \n",
      "2018-10-15          0.000000          0.189753        -0.444586  \n",
      "2018-10-16          0.000000          0.409901         0.317763  \n",
      "2018-10-17          0.347716          0.908385        -0.190537  \n",
      "2018-10-18          1.191984          0.311333         0.444022  \n",
      "2018-10-19         -1.002829         -0.248989         0.284405  \n",
      "2018-10-22          0.062676          0.531168        -0.408356  \n",
      "2018-10-23          0.000000         -0.468531        -2.099314  \n",
      "2018-10-24         -0.691609         -0.754246        -0.547947  \n",
      "2018-10-25         -2.168452         -0.791770         0.193736  \n",
      "2018-10-26          0.225407         -0.894289        -1.396807  \n",
      "2018-10-29         -0.064893          1.096785        -0.781508  \n",
      "2018-10-30          0.194553          0.256328         0.781508  \n",
      "2018-10-31          1.223454          1.177046         1.289093  \n",
      "2018-11-01          0.955421          0.378788         0.223893  \n",
      "2018-11-02         -0.476570          1.563020         0.191510  \n",
      "2018-11-05         -0.062325          0.062286        -0.750473  \n",
      "2018-11-06          0.000000          0.589789         0.094118  \n",
      "2018-11-07          0.155739          0.586331        -0.408484  \n",
      "2018-11-08          0.713292         -0.215617         0.940151  \n",
      "2018-11-09         -0.123686         -0.216083        -0.814286  \n",
      "\n",
      "[2420 rows x 18 columns]\n",
      "df_x.shape= (1419, 18)\n",
      "df_t.shape= (1418, 4) \n",
      "\n",
      "x_data.shape = (1418, 18)\n",
      "t_data.shape = (1418, 4) \n",
      "\n",
      "len_seq 1319 \n",
      "\n",
      "x.shape= (1319, 100, 18)\n",
      "t.shape= (1319, 4) \n",
      "\n",
      "x_train.shape= (1187, 100, 18)\n",
      "x_test.shape= (132, 100, 18) \n",
      "\n",
      "t_train.shape= (1187, 4)\n",
      "t_test.shape= (132, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  100\n",
      "n_hidden:  100 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1068 samples, validate on 119 samples\n",
      "Epoch 1/100\n",
      "1068/1068 [==============================] - 3s 3ms/step - loss: 1.3856 - categorical_accuracy: 0.3099 - val_loss: 1.3181 - val_categorical_accuracy: 0.5126\n",
      "Epoch 2/100\n",
      "1068/1068 [==============================] - 1s 732us/step - loss: 1.3129 - categorical_accuracy: 0.3745 - val_loss: 1.2427 - val_categorical_accuracy: 0.5126\n",
      "Epoch 3/100\n",
      "1068/1068 [==============================] - 1s 738us/step - loss: 1.2562 - categorical_accuracy: 0.3998 - val_loss: 1.1368 - val_categorical_accuracy: 0.4622\n",
      "Epoch 4/100\n",
      "1068/1068 [==============================] - 1s 749us/step - loss: 1.1599 - categorical_accuracy: 0.4307 - val_loss: 0.9578 - val_categorical_accuracy: 0.4706\n",
      "Epoch 5/100\n",
      "1068/1068 [==============================] - 1s 753us/step - loss: 1.0760 - categorical_accuracy: 0.4457 - val_loss: 0.8116 - val_categorical_accuracy: 0.5126\n",
      "Epoch 6/100\n",
      "1068/1068 [==============================] - 1s 710us/step - loss: 1.0676 - categorical_accuracy: 0.4560 - val_loss: 0.8117 - val_categorical_accuracy: 0.5042\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     70     61      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5303030303030303\n",
      "準正答率（騰落）: 0.5378787878787878\n",
      "学習時間:8.18613314628601[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  100\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1068 samples, validate on 119 samples\n",
      "Epoch 1/100\n",
      "1068/1068 [==============================] - 2s 2ms/step - loss: 1.3647 - categorical_accuracy: 0.3165 - val_loss: 1.2824 - val_categorical_accuracy: 0.4286\n",
      "Epoch 2/100\n",
      "1068/1068 [==============================] - 1s 776us/step - loss: 1.2448 - categorical_accuracy: 0.4288 - val_loss: 1.0537 - val_categorical_accuracy: 0.4874\n",
      "Epoch 3/100\n",
      "1068/1068 [==============================] - 1s 759us/step - loss: 1.0637 - categorical_accuracy: 0.4822 - val_loss: 0.8259 - val_categorical_accuracy: 0.5462\n",
      "Epoch 4/100\n",
      "1068/1068 [==============================] - 1s 777us/step - loss: 1.0831 - categorical_accuracy: 0.4654 - val_loss: 0.8207 - val_categorical_accuracy: 0.5042\n",
      "Epoch 5/100\n",
      "1068/1068 [==============================] - 1s 883us/step - loss: 1.0229 - categorical_accuracy: 0.4607 - val_loss: 0.8549 - val_categorical_accuracy: 0.4706\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     29     24      0\n",
      "fall?      1     41     37      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5\n",
      "準正答率（騰落）: 0.5\n",
      "学習時間:6.553793668746948[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  100\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1068 samples, validate on 119 samples\n",
      "Epoch 1/100\n",
      "1068/1068 [==============================] - 2s 2ms/step - loss: 1.3691 - categorical_accuracy: 0.2818 - val_loss: 1.2710 - val_categorical_accuracy: 0.4790\n",
      "Epoch 2/100\n",
      "1068/1068 [==============================] - 1s 743us/step - loss: 1.2024 - categorical_accuracy: 0.4579 - val_loss: 0.8474 - val_categorical_accuracy: 0.5042\n",
      "Epoch 3/100\n",
      "1068/1068 [==============================] - 1s 765us/step - loss: 1.0904 - categorical_accuracy: 0.4644 - val_loss: 0.8192 - val_categorical_accuracy: 0.5294\n",
      "Epoch 4/100\n",
      "1068/1068 [==============================] - 1s 744us/step - loss: 1.0329 - categorical_accuracy: 0.4710 - val_loss: 0.9265 - val_categorical_accuracy: 0.5042\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     70     61      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5303030303030303\n",
      "準正答率（騰落）: 0.5378787878787878\n",
      "学習時間:5.951660871505737[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  100\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1068 samples, validate on 119 samples\n",
      "Epoch 1/100\n",
      "1068/1068 [==============================] - 2s 2ms/step - loss: 1.3383 - categorical_accuracy: 0.3699 - val_loss: 1.1918 - val_categorical_accuracy: 0.5630\n",
      "Epoch 2/100\n",
      "1068/1068 [==============================] - 1s 767us/step - loss: 1.1309 - categorical_accuracy: 0.4569 - val_loss: 0.8448 - val_categorical_accuracy: 0.4202\n",
      "Epoch 3/100\n",
      "1068/1068 [==============================] - 1s 727us/step - loss: 1.0459 - categorical_accuracy: 0.4560 - val_loss: 0.9339 - val_categorical_accuracy: 0.4958\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     67     57      0\n",
      "fall?      1      3      4      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5378787878787878\n",
      "準正答率（騰落）: 0.5378787878787878\n",
      "学習時間:5.39981746673584[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  100\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1068 samples, validate on 119 samples\n",
      "Epoch 1/100\n",
      "1068/1068 [==============================] - 3s 2ms/step - loss: 1.3404 - categorical_accuracy: 0.3567 - val_loss: 1.1270 - val_categorical_accuracy: 0.4958\n",
      "Epoch 2/100\n",
      "1068/1068 [==============================] - 1s 863us/step - loss: 1.0971 - categorical_accuracy: 0.4569 - val_loss: 0.8432 - val_categorical_accuracy: 0.5042\n",
      "Epoch 3/100\n",
      "1068/1068 [==============================] - 1s 762us/step - loss: 1.0597 - categorical_accuracy: 0.4625 - val_loss: 0.8880 - val_categorical_accuracy: 0.5378\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     57     49      0\n",
      "fall?      1     13     12      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5227272727272727\n",
      "準正答率（騰落）: 0.5227272727272727\n",
      "学習時間:5.750507116317749[sec]\n",
      "\n",
      "len_seq 1219 \n",
      "\n",
      "x.shape= (1219, 200, 18)\n",
      "t.shape= (1219, 4) \n",
      "\n",
      "x_train.shape= (1097, 200, 18)\n",
      "x_test.shape= (122, 200, 18) \n",
      "\n",
      "t_train.shape= (1097, 4)\n",
      "t_test.shape= (122, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  200\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 987 samples, validate on 110 samples\n",
      "Epoch 1/100\n",
      "987/987 [==============================] - 3s 3ms/step - loss: 1.3978 - categorical_accuracy: 0.2746 - val_loss: 1.3417 - val_categorical_accuracy: 0.3909\n",
      "Epoch 2/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.3311 - categorical_accuracy: 0.3546 - val_loss: 1.2831 - val_categorical_accuracy: 0.4909\n",
      "Epoch 3/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.2699 - categorical_accuracy: 0.3961 - val_loss: 1.2117 - val_categorical_accuracy: 0.4818\n",
      "Epoch 4/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.1782 - categorical_accuracy: 0.4580 - val_loss: 1.1032 - val_categorical_accuracy: 0.4727\n",
      "Epoch 5/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.1072 - categorical_accuracy: 0.4711 - val_loss: 0.9227 - val_categorical_accuracy: 0.4909\n",
      "Epoch 6/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.0429 - categorical_accuracy: 0.4681 - val_loss: 0.8557 - val_categorical_accuracy: 0.5091\n",
      "Epoch 7/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.0372 - categorical_accuracy: 0.4934 - val_loss: 0.8566 - val_categorical_accuracy: 0.5091\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     65     57      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5327868852459017\n",
      "準正答率（騰落）: 0.5327868852459017\n",
      "学習時間:12.07169246673584[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  200\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 987 samples, validate on 110 samples\n",
      "Epoch 1/100\n",
      "987/987 [==============================] - 3s 3ms/step - loss: 1.3528 - categorical_accuracy: 0.3262 - val_loss: 1.3095 - val_categorical_accuracy: 0.4273\n",
      "Epoch 2/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.2652 - categorical_accuracy: 0.4164 - val_loss: 1.1689 - val_categorical_accuracy: 0.4545\n",
      "Epoch 3/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.0858 - categorical_accuracy: 0.4539 - val_loss: 0.8590 - val_categorical_accuracy: 0.5364\n",
      "Epoch 4/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.0373 - categorical_accuracy: 0.4924 - val_loss: 0.8680 - val_categorical_accuracy: 0.5091\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     64     57      0\n",
      "fall?      0      1      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5245901639344263\n",
      "準正答率（騰落）: 0.5245901639344263\n",
      "学習時間:8.331544399261475[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  200\n",
      "n_hidden:  300 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 987 samples, validate on 110 samples\n",
      "Epoch 1/100\n",
      "987/987 [==============================] - 3s 3ms/step - loss: 1.3713 - categorical_accuracy: 0.2655 - val_loss: 1.3090 - val_categorical_accuracy: 0.4364\n",
      "Epoch 2/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.2404 - categorical_accuracy: 0.4113 - val_loss: 1.0671 - val_categorical_accuracy: 0.5091\n",
      "Epoch 3/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.0297 - categorical_accuracy: 0.4883 - val_loss: 0.9097 - val_categorical_accuracy: 0.4273\n",
      "Epoch 4/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.0686 - categorical_accuracy: 0.4590 - val_loss: 0.8741 - val_categorical_accuracy: 0.5636\n",
      "Epoch 5/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.0060 - categorical_accuracy: 0.4833 - val_loss: 0.9181 - val_categorical_accuracy: 0.5091\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     65     57      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5327868852459017\n",
      "準正答率（騰落）: 0.5327868852459017\n",
      "学習時間:10.004870891571045[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  200\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 987 samples, validate on 110 samples\n",
      "Epoch 1/100\n",
      "987/987 [==============================] - 4s 4ms/step - loss: 1.3416 - categorical_accuracy: 0.3273 - val_loss: 1.2466 - val_categorical_accuracy: 0.5182\n",
      "Epoch 2/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.1306 - categorical_accuracy: 0.4630 - val_loss: 0.8987 - val_categorical_accuracy: 0.4455\n",
      "Epoch 3/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.0564 - categorical_accuracy: 0.4671 - val_loss: 0.8991 - val_categorical_accuracy: 0.5273\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     33     29      0\n",
      "fall?      0     32     28      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5\n",
      "準正答率（騰落）: 0.5\n",
      "学習時間:7.584000110626221[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  200\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 987 samples, validate on 110 samples\n",
      "Epoch 1/100\n",
      "987/987 [==============================] - 4s 4ms/step - loss: 1.3372 - categorical_accuracy: 0.3343 - val_loss: 1.2396 - val_categorical_accuracy: 0.4818\n",
      "Epoch 2/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.1137 - categorical_accuracy: 0.4671 - val_loss: 0.8723 - val_categorical_accuracy: 0.4455\n",
      "Epoch 3/100\n",
      "987/987 [==============================] - 1s 1ms/step - loss: 1.0122 - categorical_accuracy: 0.4904 - val_loss: 0.9147 - val_categorical_accuracy: 0.5273\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     63     56      0\n",
      "fall?      0      2      1      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5245901639344263\n",
      "準正答率（騰落）: 0.5245901639344263\n",
      "学習時間:7.858905076980591[sec]\n",
      "\n",
      "len_seq 1119 \n",
      "\n",
      "x.shape= (1119, 300, 18)\n",
      "t.shape= (1119, 4) \n",
      "\n",
      "x_train.shape= (1007, 300, 18)\n",
      "x_test.shape= (112, 300, 18) \n",
      "\n",
      "t_train.shape= (1007, 4)\n",
      "t_test.shape= (112, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  300\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 906 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "906/906 [==============================] - 4s 5ms/step - loss: 1.3864 - categorical_accuracy: 0.2859 - val_loss: 1.3396 - val_categorical_accuracy: 0.4059\n",
      "Epoch 2/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.3276 - categorical_accuracy: 0.3587 - val_loss: 1.2819 - val_categorical_accuracy: 0.5743\n",
      "Epoch 3/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.2694 - categorical_accuracy: 0.4084 - val_loss: 1.2097 - val_categorical_accuracy: 0.5545\n",
      "Epoch 4/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.2065 - categorical_accuracy: 0.4161 - val_loss: 1.0989 - val_categorical_accuracy: 0.5545\n",
      "Epoch 5/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.1168 - categorical_accuracy: 0.4294 - val_loss: 0.9126 - val_categorical_accuracy: 0.6040\n",
      "Epoch 6/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.0358 - categorical_accuracy: 0.4636 - val_loss: 0.8365 - val_categorical_accuracy: 0.4752\n",
      "Epoch 7/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.0364 - categorical_accuracy: 0.4614 - val_loss: 0.8441 - val_categorical_accuracy: 0.4950\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     60     52      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5357142857142857\n",
      "準正答率（騰落）: 0.5357142857142857\n",
      "学習時間:16.639506340026855[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  300\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 906 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "906/906 [==============================] - 4s 5ms/step - loss: 1.3594 - categorical_accuracy: 0.3091 - val_loss: 1.3161 - val_categorical_accuracy: 0.4257\n",
      "Epoch 2/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.2640 - categorical_accuracy: 0.4283 - val_loss: 1.1884 - val_categorical_accuracy: 0.4653\n",
      "Epoch 3/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.1140 - categorical_accuracy: 0.4669 - val_loss: 0.8380 - val_categorical_accuracy: 0.5347\n",
      "Epoch 4/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.0251 - categorical_accuracy: 0.4845 - val_loss: 0.8377 - val_categorical_accuracy: 0.4950\n",
      "Epoch 5/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.0286 - categorical_accuracy: 0.4735 - val_loss: 0.8520 - val_categorical_accuracy: 0.4950\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     60     52      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5357142857142857\n",
      "準正答率（騰落）: 0.5357142857142857\n",
      "学習時間:12.983760118484497[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  300\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 906 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "906/906 [==============================] - 4s 5ms/step - loss: 1.3715 - categorical_accuracy: 0.2859 - val_loss: 1.3029 - val_categorical_accuracy: 0.4653\n",
      "Epoch 2/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.2462 - categorical_accuracy: 0.4040 - val_loss: 1.0681 - val_categorical_accuracy: 0.4950\n",
      "Epoch 3/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.0602 - categorical_accuracy: 0.4702 - val_loss: 0.8619 - val_categorical_accuracy: 0.4356\n",
      "Epoch 4/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.0321 - categorical_accuracy: 0.4625 - val_loss: 0.8536 - val_categorical_accuracy: 0.5050\n",
      "Epoch 5/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 0.9992 - categorical_accuracy: 0.4790 - val_loss: 0.8913 - val_categorical_accuracy: 0.5149\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     58     49      0\n",
      "fall?      0      2      3      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5446428571428571\n",
      "準正答率（騰落）: 0.5446428571428571\n",
      "学習時間:13.18631887435913[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  300\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 906 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "906/906 [==============================] - 5s 5ms/step - loss: 1.3492 - categorical_accuracy: 0.3466 - val_loss: 1.2732 - val_categorical_accuracy: 0.4653\n",
      "Epoch 2/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.1566 - categorical_accuracy: 0.4735 - val_loss: 0.8446 - val_categorical_accuracy: 0.4950\n",
      "Epoch 3/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.0360 - categorical_accuracy: 0.4415 - val_loss: 0.8897 - val_categorical_accuracy: 0.5347\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     42     36      0\n",
      "fall?      0     18     16      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5178571428571429\n",
      "準正答率（騰落）: 0.5178571428571429\n",
      "学習時間:9.970897912979126[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  300\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 906 samples, validate on 101 samples\n",
      "Epoch 1/100\n",
      "906/906 [==============================] - 5s 5ms/step - loss: 1.3515 - categorical_accuracy: 0.3124 - val_loss: 1.2468 - val_categorical_accuracy: 0.4653\n",
      "Epoch 2/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.1465 - categorical_accuracy: 0.4647 - val_loss: 0.8393 - val_categorical_accuracy: 0.4950\n",
      "Epoch 3/100\n",
      "906/906 [==============================] - 2s 2ms/step - loss: 1.0311 - categorical_accuracy: 0.4570 - val_loss: 0.9336 - val_categorical_accuracy: 0.5545\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     40     29      0\n",
      "fall?      0     20     23      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5625\n",
      "準正答率（騰落）: 0.5625\n",
      "学習時間:10.318844556808472[sec]\n",
      "\n",
      "len_seq 1019 \n",
      "\n",
      "x.shape= (1019, 400, 18)\n",
      "t.shape= (1019, 4) \n",
      "\n",
      "x_train.shape= (917, 400, 18)\n",
      "x_test.shape= (102, 400, 18) \n",
      "\n",
      "t_train.shape= (917, 4)\n",
      "t_test.shape= (102, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  400\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 825 samples, validate on 92 samples\n",
      "Epoch 1/100\n",
      "825/825 [==============================] - 5s 6ms/step - loss: 1.3944 - categorical_accuracy: 0.3018 - val_loss: 1.3296 - val_categorical_accuracy: 0.4565\n",
      "Epoch 2/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.3343 - categorical_accuracy: 0.4000 - val_loss: 1.2778 - val_categorical_accuracy: 0.5652\n",
      "Epoch 3/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.2800 - categorical_accuracy: 0.3988 - val_loss: 1.2153 - val_categorical_accuracy: 0.5543\n",
      "Epoch 4/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.2081 - categorical_accuracy: 0.4436 - val_loss: 1.1264 - val_categorical_accuracy: 0.5326\n",
      "Epoch 5/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.1282 - categorical_accuracy: 0.4606 - val_loss: 0.9862 - val_categorical_accuracy: 0.5109\n",
      "Epoch 6/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.0852 - categorical_accuracy: 0.4558 - val_loss: 0.8352 - val_categorical_accuracy: 0.4783\n",
      "Epoch 7/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.0363 - categorical_accuracy: 0.4485 - val_loss: 0.8077 - val_categorical_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.0638 - categorical_accuracy: 0.4752 - val_loss: 0.8072 - val_categorical_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.0300 - categorical_accuracy: 0.4594 - val_loss: 0.8147 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     51     41      0\n",
      "fall?      0      3      7      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5686274509803921\n",
      "準正答率（騰落）: 0.5686274509803921\n",
      "学習時間:24.766644954681396[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  400\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 825 samples, validate on 92 samples\n",
      "Epoch 1/100\n",
      "825/825 [==============================] - 5s 6ms/step - loss: 1.3633 - categorical_accuracy: 0.3406 - val_loss: 1.3234 - val_categorical_accuracy: 0.4022\n",
      "Epoch 2/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.2688 - categorical_accuracy: 0.4376 - val_loss: 1.2082 - val_categorical_accuracy: 0.4457\n",
      "Epoch 3/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.1438 - categorical_accuracy: 0.4509 - val_loss: 0.8572 - val_categorical_accuracy: 0.4674\n",
      "Epoch 4/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.0561 - categorical_accuracy: 0.4230 - val_loss: 0.8125 - val_categorical_accuracy: 0.5109\n",
      "Epoch 5/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.0724 - categorical_accuracy: 0.4642 - val_loss: 0.8137 - val_categorical_accuracy: 0.5109\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     53     48      0\n",
      "fall?      0      1      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5196078431372549\n",
      "準正答率（騰落）: 0.5196078431372549\n",
      "学習時間:16.096102476119995[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  400\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 825 samples, validate on 92 samples\n",
      "Epoch 1/100\n",
      "825/825 [==============================] - 6s 7ms/step - loss: 1.3858 - categorical_accuracy: 0.2485 - val_loss: 1.3113 - val_categorical_accuracy: 0.4022\n",
      "Epoch 2/100\n",
      "825/825 [==============================] - 2s 3ms/step - loss: 1.2642 - categorical_accuracy: 0.3939 - val_loss: 1.1383 - val_categorical_accuracy: 0.4239\n",
      "Epoch 3/100\n",
      "825/825 [==============================] - 3s 3ms/step - loss: 1.1065 - categorical_accuracy: 0.4424 - val_loss: 0.8203 - val_categorical_accuracy: 0.4674\n",
      "Epoch 4/100\n",
      "825/825 [==============================] - 3s 3ms/step - loss: 1.0787 - categorical_accuracy: 0.4606 - val_loss: 0.8380 - val_categorical_accuracy: 0.5109\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     50     43      0\n",
      "fall?      0      4      5      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5392156862745098\n",
      "準正答率（騰落）: 0.5392156862745098\n",
      "学習時間:14.80644941329956[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  400\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 825 samples, validate on 92 samples\n",
      "Epoch 1/100\n",
      "825/825 [==============================] - 6s 7ms/step - loss: 1.3476 - categorical_accuracy: 0.3309 - val_loss: 1.2773 - val_categorical_accuracy: 0.5109\n",
      "Epoch 2/100\n",
      "825/825 [==============================] - 3s 3ms/step - loss: 1.1779 - categorical_accuracy: 0.4606 - val_loss: 0.8324 - val_categorical_accuracy: 0.5217\n",
      "Epoch 3/100\n",
      "825/825 [==============================] - 3s 3ms/step - loss: 1.0875 - categorical_accuracy: 0.4424 - val_loss: 0.8611 - val_categorical_accuracy: 0.4674\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     46     38      0\n",
      "fall?      0      8     10      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5490196078431373\n",
      "準正答率（騰落）: 0.5490196078431373\n",
      "学習時間:12.363167524337769[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  400\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 825 samples, validate on 92 samples\n",
      "Epoch 1/100\n",
      "825/825 [==============================] - 6s 8ms/step - loss: 1.3543 - categorical_accuracy: 0.3248 - val_loss: 1.2607 - val_categorical_accuracy: 0.4239\n",
      "Epoch 2/100\n",
      "825/825 [==============================] - 3s 3ms/step - loss: 1.1415 - categorical_accuracy: 0.4448 - val_loss: 0.8307 - val_categorical_accuracy: 0.5217\n",
      "Epoch 3/100\n",
      "825/825 [==============================] - 3s 3ms/step - loss: 1.0754 - categorical_accuracy: 0.4558 - val_loss: 0.9631 - val_categorical_accuracy: 0.4783\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     47     38      0\n",
      "fall?      0      7     10      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5588235294117647\n",
      "準正答率（騰落）: 0.5588235294117647\n",
      "学習時間:12.935587644577026[sec]\n",
      "\n",
      "len_seq 919 \n",
      "\n",
      "x.shape= (919, 500, 18)\n",
      "t.shape= (919, 4) \n",
      "\n",
      "x_train.shape= (827, 500, 18)\n",
      "x_test.shape= (92, 500, 18) \n",
      "\n",
      "t_train.shape= (827, 4)\n",
      "t_test.shape= (92, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  500\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 744 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      "744/744 [==============================] - 6s 7ms/step - loss: 1.3882 - categorical_accuracy: 0.2997 - val_loss: 1.3356 - val_categorical_accuracy: 0.4578\n",
      "Epoch 2/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.3551 - categorical_accuracy: 0.3306 - val_loss: 1.2900 - val_categorical_accuracy: 0.5904\n",
      "Epoch 3/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.3063 - categorical_accuracy: 0.4126 - val_loss: 1.2407 - val_categorical_accuracy: 0.5663\n",
      "Epoch 4/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.2682 - categorical_accuracy: 0.4140 - val_loss: 1.1805 - val_categorical_accuracy: 0.5301\n",
      "Epoch 5/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.2053 - categorical_accuracy: 0.4476 - val_loss: 1.0992 - val_categorical_accuracy: 0.5301\n",
      "Epoch 6/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.1572 - categorical_accuracy: 0.4449 - val_loss: 0.9818 - val_categorical_accuracy: 0.5301\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/744 [==============================] - 2s 3ms/step - loss: 1.0962 - categorical_accuracy: 0.4368 - val_loss: 0.8462 - val_categorical_accuracy: 0.5422\n",
      "Epoch 8/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.0348 - categorical_accuracy: 0.4758 - val_loss: 0.8105 - val_categorical_accuracy: 0.4940\n",
      "Epoch 9/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.0539 - categorical_accuracy: 0.4543 - val_loss: 0.8152 - val_categorical_accuracy: 0.5060\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     50     42      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5434782608695652\n",
      "準正答率（騰落）: 0.5434782608695652\n",
      "学習時間:25.15278387069702[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  500\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 744 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      "744/744 [==============================] - 6s 8ms/step - loss: 1.3673 - categorical_accuracy: 0.3293 - val_loss: 1.3299 - val_categorical_accuracy: 0.3976\n",
      "Epoch 2/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.3046 - categorical_accuracy: 0.3952 - val_loss: 1.2542 - val_categorical_accuracy: 0.4217\n",
      "Epoch 3/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.2200 - categorical_accuracy: 0.4341 - val_loss: 1.1062 - val_categorical_accuracy: 0.3976\n",
      "Epoch 4/100\n",
      "744/744 [==============================] - 3s 3ms/step - loss: 1.0951 - categorical_accuracy: 0.4691 - val_loss: 0.8168 - val_categorical_accuracy: 0.4217\n",
      "Epoch 5/100\n",
      "744/744 [==============================] - 3s 3ms/step - loss: 1.0501 - categorical_accuracy: 0.4395 - val_loss: 0.8203 - val_categorical_accuracy: 0.5060\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     49     40      0\n",
      "fall?      0      1      2      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5543478260869565\n",
      "準正答率（騰落）: 0.5543478260869565\n",
      "学習時間:17.25955033302307[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  500\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 744 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      "744/744 [==============================] - 6s 8ms/step - loss: 1.3786 - categorical_accuracy: 0.2634 - val_loss: 1.3266 - val_categorical_accuracy: 0.3855\n",
      "Epoch 2/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.2859 - categorical_accuracy: 0.4194 - val_loss: 1.2260 - val_categorical_accuracy: 0.4458\n",
      "Epoch 3/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.1587 - categorical_accuracy: 0.4368 - val_loss: 0.8447 - val_categorical_accuracy: 0.5181\n",
      "Epoch 4/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.0659 - categorical_accuracy: 0.4516 - val_loss: 0.8387 - val_categorical_accuracy: 0.4819\n",
      "Epoch 5/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.0447 - categorical_accuracy: 0.4677 - val_loss: 0.8282 - val_categorical_accuracy: 0.4940\n",
      "Epoch 6/100\n",
      "744/744 [==============================] - 3s 3ms/step - loss: 1.0110 - categorical_accuracy: 0.4570 - val_loss: 0.8731 - val_categorical_accuracy: 0.5181\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     50     41      0\n",
      "fall?      0      0      1      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5543478260869565\n",
      "準正答率（騰落）: 0.5543478260869565\n",
      "学習時間:20.22522211074829[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  500\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 744 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      "744/744 [==============================] - 7s 9ms/step - loss: 1.3585 - categorical_accuracy: 0.3320 - val_loss: 1.3031 - val_categorical_accuracy: 0.4578\n",
      "Epoch 2/100\n",
      "744/744 [==============================] - 3s 3ms/step - loss: 1.2317 - categorical_accuracy: 0.4570 - val_loss: 1.0421 - val_categorical_accuracy: 0.4699\n",
      "Epoch 3/100\n",
      "744/744 [==============================] - 3s 3ms/step - loss: 1.0778 - categorical_accuracy: 0.4516 - val_loss: 0.8186 - val_categorical_accuracy: 0.5301\n",
      "Epoch 4/100\n",
      "744/744 [==============================] - 3s 4ms/step - loss: 1.0461 - categorical_accuracy: 0.4570 - val_loss: 0.9039 - val_categorical_accuracy: 0.4699\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     10      8      0\n",
      "fall?      0     40     34      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4782608695652174\n",
      "準正答率（騰落）: 0.4782608695652174\n",
      "学習時間:15.627623081207275[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  500\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 744 samples, validate on 83 samples\n",
      "Epoch 1/100\n",
      "744/744 [==============================] - 7s 9ms/step - loss: 1.3685 - categorical_accuracy: 0.2917 - val_loss: 1.2909 - val_categorical_accuracy: 0.4096\n",
      "Epoch 2/100\n",
      "744/744 [==============================] - 3s 4ms/step - loss: 1.2231 - categorical_accuracy: 0.4113 - val_loss: 0.8158 - val_categorical_accuracy: 0.5181\n",
      "Epoch 3/100\n",
      "744/744 [==============================] - 2s 3ms/step - loss: 1.1021 - categorical_accuracy: 0.4664 - val_loss: 0.8371 - val_categorical_accuracy: 0.4337\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     10      7      0\n",
      "fall?      0     40     35      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4891304347826087\n",
      "準正答率（騰落）: 0.4891304347826087\n",
      "学習時間:13.427194356918335[sec]\n",
      "\n",
      "len_seq 819 \n",
      "\n",
      "x.shape= (819, 600, 18)\n",
      "t.shape= (819, 4) \n",
      "\n",
      "x_train.shape= (737, 600, 18)\n",
      "x_test.shape= (82, 600, 18) \n",
      "\n",
      "t_train.shape= (737, 4)\n",
      "t_test.shape= (82, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  600\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 663 samples, validate on 74 samples\n",
      "Epoch 1/100\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 1.3904 - categorical_accuracy: 0.2926 - val_loss: 1.3359 - val_categorical_accuracy: 0.5135\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.3622 - categorical_accuracy: 0.3092 - val_loss: 1.2976 - val_categorical_accuracy: 0.5676\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.3141 - categorical_accuracy: 0.3741 - val_loss: 1.2553 - val_categorical_accuracy: 0.5405\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.2908 - categorical_accuracy: 0.3831 - val_loss: 1.2036 - val_categorical_accuracy: 0.5135\n",
      "Epoch 5/100\n",
      "663/663 [==============================] - 3s 5ms/step - loss: 1.2496 - categorical_accuracy: 0.4193 - val_loss: 1.1346 - val_categorical_accuracy: 0.5135\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.1895 - categorical_accuracy: 0.4284 - val_loss: 1.0373 - val_categorical_accuracy: 0.5135\n",
      "Epoch 7/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.1023 - categorical_accuracy: 0.4314 - val_loss: 0.9044 - val_categorical_accuracy: 0.5135\n",
      "Epoch 8/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0714 - categorical_accuracy: 0.4344 - val_loss: 0.8269 - val_categorical_accuracy: 0.5135\n",
      "Epoch 9/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0491 - categorical_accuracy: 0.4510 - val_loss: 0.8193 - val_categorical_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0348 - categorical_accuracy: 0.4706 - val_loss: 0.8226 - val_categorical_accuracy: 0.5135\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     44     38      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5365853658536586\n",
      "準正答率（騰落）: 0.5365853658536586\n",
      "学習時間:33.811580419540405[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  600\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 663 samples, validate on 74 samples\n",
      "Epoch 1/100\n",
      "663/663 [==============================] - 7s 10ms/step - loss: 1.3724 - categorical_accuracy: 0.3379 - val_loss: 1.3421 - val_categorical_accuracy: 0.4054\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.3209 - categorical_accuracy: 0.3831 - val_loss: 1.2761 - val_categorical_accuracy: 0.4459\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.2400 - categorical_accuracy: 0.4615 - val_loss: 1.1431 - val_categorical_accuracy: 0.4459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.1259 - categorical_accuracy: 0.4253 - val_loss: 0.8354 - val_categorical_accuracy: 0.4459\n",
      "Epoch 5/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0494 - categorical_accuracy: 0.4630 - val_loss: 0.8294 - val_categorical_accuracy: 0.4865\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0335 - categorical_accuracy: 0.4947 - val_loss: 0.8238 - val_categorical_accuracy: 0.5135\n",
      "Epoch 7/100\n",
      "663/663 [==============================] - 3s 5ms/step - loss: 1.0494 - categorical_accuracy: 0.4646 - val_loss: 0.8404 - val_categorical_accuracy: 0.4730\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     31     24      0\n",
      "fall?      0     13     14      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5487804878048781\n",
      "準正答率（騰落）: 0.5487804878048781\n",
      "学習時間:24.99537181854248[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  600\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 663 samples, validate on 74 samples\n",
      "Epoch 1/100\n",
      "663/663 [==============================] - 7s 11ms/step - loss: 1.3911 - categorical_accuracy: 0.2413 - val_loss: 1.3360 - val_categorical_accuracy: 0.4595\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.3089 - categorical_accuracy: 0.3831 - val_loss: 1.2497 - val_categorical_accuracy: 0.5135\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.1945 - categorical_accuracy: 0.4495 - val_loss: 0.9376 - val_categorical_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0382 - categorical_accuracy: 0.4510 - val_loss: 0.8404 - val_categorical_accuracy: 0.5135\n",
      "Epoch 5/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0623 - categorical_accuracy: 0.4495 - val_loss: 0.8260 - val_categorical_accuracy: 0.4730\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0213 - categorical_accuracy: 0.4827 - val_loss: 0.9111 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     14     12      0\n",
      "fall?      0     30     26      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4878048780487805\n",
      "準正答率（騰落）: 0.4878048780487805\n",
      "学習時間:22.66836142539978[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  600\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 663 samples, validate on 74 samples\n",
      "Epoch 1/100\n",
      "663/663 [==============================] - 8s 11ms/step - loss: 1.3640 - categorical_accuracy: 0.2986 - val_loss: 1.3152 - val_categorical_accuracy: 0.4730\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.2610 - categorical_accuracy: 0.4238 - val_loss: 1.0959 - val_categorical_accuracy: 0.5135\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0973 - categorical_accuracy: 0.4404 - val_loss: 0.8331 - val_categorical_accuracy: 0.5135\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - 3s 4ms/step - loss: 1.0673 - categorical_accuracy: 0.4630 - val_loss: 0.8767 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     13      8      0\n",
      "fall?      0     31     30      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.524390243902439\n",
      "準正答率（騰落）: 0.524390243902439\n",
      "学習時間:18.0916109085083[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  600\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 663 samples, validate on 74 samples\n",
      "Epoch 1/100\n",
      "663/663 [==============================] - 8s 12ms/step - loss: 1.3666 - categorical_accuracy: 0.3167 - val_loss: 1.3060 - val_categorical_accuracy: 0.4459\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - 3s 5ms/step - loss: 1.2471 - categorical_accuracy: 0.3891 - val_loss: 0.8313 - val_categorical_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - 3s 5ms/step - loss: 1.0631 - categorical_accuracy: 0.4781 - val_loss: 0.8456 - val_categorical_accuracy: 0.4459\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     14     10      0\n",
      "fall?      0     30     28      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5121951219512195\n",
      "準正答率（騰落）: 0.5121951219512195\n",
      "学習時間:15.854367017745972[sec]\n",
      "\n",
      "len_seq 719 \n",
      "\n",
      "x.shape= (719, 700, 18)\n",
      "t.shape= (719, 4) \n",
      "\n",
      "x_train.shape= (647, 700, 18)\n",
      "x_test.shape= (72, 700, 18) \n",
      "\n",
      "t_train.shape= (647, 4)\n",
      "t_test.shape= (72, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  700\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 582 samples, validate on 65 samples\n",
      "Epoch 1/100\n",
      "582/582 [==============================] - 8s 14ms/step - loss: 1.3876 - categorical_accuracy: 0.3024 - val_loss: 1.3423 - val_categorical_accuracy: 0.3385\n",
      "Epoch 2/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.3653 - categorical_accuracy: 0.3316 - val_loss: 1.3023 - val_categorical_accuracy: 0.5077\n",
      "Epoch 3/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.3239 - categorical_accuracy: 0.3780 - val_loss: 1.2593 - val_categorical_accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.2911 - categorical_accuracy: 0.3986 - val_loss: 1.2096 - val_categorical_accuracy: 0.4923\n",
      "Epoch 5/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.2288 - categorical_accuracy: 0.4553 - val_loss: 1.1459 - val_categorical_accuracy: 0.4923\n",
      "Epoch 6/100\n",
      "582/582 [==============================] - 4s 6ms/step - loss: 1.1887 - categorical_accuracy: 0.4450 - val_loss: 1.0564 - val_categorical_accuracy: 0.4923\n",
      "Epoch 7/100\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 1.1421 - categorical_accuracy: 0.4364 - val_loss: 0.9249 - val_categorical_accuracy: 0.5077\n",
      "Epoch 8/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.0739 - categorical_accuracy: 0.4656 - val_loss: 0.8020 - val_categorical_accuracy: 0.4154\n",
      "Epoch 9/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.0260 - categorical_accuracy: 0.4416 - val_loss: 0.7743 - val_categorical_accuracy: 0.5692\n",
      "Epoch 10/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.0415 - categorical_accuracy: 0.4605 - val_loss: 0.7737 - val_categorical_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 1.0672 - categorical_accuracy: 0.4828 - val_loss: 0.7779 - val_categorical_accuracy: 0.5077\n",
      "Epoch 00011: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     23     26      0\n",
      "fall?      0     15      8      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4305555555555556\n",
      "準正答率（騰落）: 0.4305555555555556\n",
      "学習時間:43.05777955055237[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  700\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 582 samples, validate on 65 samples\n",
      "Epoch 1/100\n",
      "582/582 [==============================] - 8s 14ms/step - loss: 1.3746 - categorical_accuracy: 0.2801 - val_loss: 1.3388 - val_categorical_accuracy: 0.4154\n",
      "Epoch 2/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.3290 - categorical_accuracy: 0.3729 - val_loss: 1.2818 - val_categorical_accuracy: 0.4923\n",
      "Epoch 3/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.2691 - categorical_accuracy: 0.4210 - val_loss: 1.1834 - val_categorical_accuracy: 0.4462\n",
      "Epoch 4/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.1695 - categorical_accuracy: 0.4588 - val_loss: 0.9145 - val_categorical_accuracy: 0.4462\n",
      "Epoch 5/100\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 1.0566 - categorical_accuracy: 0.4656 - val_loss: 0.7774 - val_categorical_accuracy: 0.4462\n",
      "Epoch 6/100\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 1.0692 - categorical_accuracy: 0.4416 - val_loss: 0.7724 - val_categorical_accuracy: 0.5538\n",
      "Epoch 7/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.0482 - categorical_accuracy: 0.4553 - val_loss: 0.7941 - val_categorical_accuracy: 0.5385\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     20     16      0\n",
      "fall?      0     18     18      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5277777777777778\n",
      "準正答率（騰落）: 0.5277777777777778\n",
      "学習時間:28.949028968811035[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  700\n",
      "n_hidden:  300 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 582 samples, validate on 65 samples\n",
      "Epoch 1/100\n",
      "582/582 [==============================] - 9s 15ms/step - loss: 1.3939 - categorical_accuracy: 0.2337 - val_loss: 1.3366 - val_categorical_accuracy: 0.4154\n",
      "Epoch 2/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.3262 - categorical_accuracy: 0.3849 - val_loss: 1.2602 - val_categorical_accuracy: 0.4769\n",
      "Epoch 3/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.2335 - categorical_accuracy: 0.4227 - val_loss: 1.0508 - val_categorical_accuracy: 0.5231\n",
      "Epoch 4/100\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 1.0725 - categorical_accuracy: 0.4691 - val_loss: 0.8016 - val_categorical_accuracy: 0.4462\n",
      "Epoch 5/100\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 1.1310 - categorical_accuracy: 0.4553 - val_loss: 0.7917 - val_categorical_accuracy: 0.4462\n",
      "Epoch 6/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.0711 - categorical_accuracy: 0.4605 - val_loss: 0.8094 - val_categorical_accuracy: 0.4923\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     30     25      0\n",
      "fall?      0      8      9      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5416666666666666\n",
      "準正答率（騰落）: 0.5416666666666666\n",
      "学習時間:26.20490312576294[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  700\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 582 samples, validate on 65 samples\n",
      "Epoch 1/100\n",
      "582/582 [==============================] - 9s 15ms/step - loss: 1.3640 - categorical_accuracy: 0.3282 - val_loss: 1.3151 - val_categorical_accuracy: 0.4308\n",
      "Epoch 2/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.2664 - categorical_accuracy: 0.4192 - val_loss: 1.1109 - val_categorical_accuracy: 0.4154\n",
      "Epoch 3/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.0772 - categorical_accuracy: 0.4570 - val_loss: 0.7846 - val_categorical_accuracy: 0.5385\n",
      "Epoch 4/100\n",
      "582/582 [==============================] - 3s 6ms/step - loss: 1.0691 - categorical_accuracy: 0.4296 - val_loss: 0.8371 - val_categorical_accuracy: 0.4615\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     34     26      0\n",
      "fall?      0      4      8      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5833333333333334\n",
      "準正答率（騰落）: 0.5833333333333334\n",
      "学習時間:20.36939811706543[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  700\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 582 samples, validate on 65 samples\n",
      "Epoch 1/100\n",
      "582/582 [==============================] - 10s 18ms/step - loss: 1.3875 - categorical_accuracy: 0.2612 - val_loss: 1.3009 - val_categorical_accuracy: 0.4154\n",
      "Epoch 2/100\n",
      "582/582 [==============================] - 4s 7ms/step - loss: 1.2684 - categorical_accuracy: 0.3832 - val_loss: 0.9305 - val_categorical_accuracy: 0.4462\n",
      "Epoch 3/100\n",
      "582/582 [==============================] - 4s 7ms/step - loss: 1.1185 - categorical_accuracy: 0.4845 - val_loss: 0.7725 - val_categorical_accuracy: 0.5231\n",
      "Epoch 4/100\n",
      "582/582 [==============================] - 4s 6ms/step - loss: 1.0512 - categorical_accuracy: 0.4639 - val_loss: 0.8899 - val_categorical_accuracy: 0.6154\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     14      9      0\n",
      "fall?      0     24     25      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5416666666666666\n",
      "準正答率（騰落）: 0.5416666666666666\n",
      "学習時間:22.93932557106018[sec]\n",
      "\n",
      "len_seq 619 \n",
      "\n",
      "x.shape= (619, 800, 18)\n",
      "t.shape= (619, 4) \n",
      "\n",
      "x_train.shape= (557, 800, 18)\n",
      "x_test.shape= (62, 800, 18) \n",
      "\n",
      "t_train.shape= (557, 4)\n",
      "t_test.shape= (62, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  800\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 501 samples, validate on 56 samples\n",
      "Epoch 1/100\n",
      "501/501 [==============================] - 8s 16ms/step - loss: 1.4039 - categorical_accuracy: 0.2495 - val_loss: 1.3610 - val_categorical_accuracy: 0.3036\n",
      "Epoch 2/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.3751 - categorical_accuracy: 0.3194 - val_loss: 1.3320 - val_categorical_accuracy: 0.3929\n",
      "Epoch 3/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.3442 - categorical_accuracy: 0.3473 - val_loss: 1.3023 - val_categorical_accuracy: 0.3929\n",
      "Epoch 4/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.3058 - categorical_accuracy: 0.4072 - val_loss: 1.2690 - val_categorical_accuracy: 0.4286\n",
      "Epoch 5/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.2895 - categorical_accuracy: 0.4092 - val_loss: 1.2312 - val_categorical_accuracy: 0.4464\n",
      "Epoch 6/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.2637 - categorical_accuracy: 0.3852 - val_loss: 1.1856 - val_categorical_accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.2182 - categorical_accuracy: 0.4311 - val_loss: 1.1273 - val_categorical_accuracy: 0.4464\n",
      "Epoch 8/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.1723 - categorical_accuracy: 0.4611 - val_loss: 1.0464 - val_categorical_accuracy: 0.4464\n",
      "Epoch 9/100\n",
      "501/501 [==============================] - 3s 6ms/step - loss: 1.1599 - categorical_accuracy: 0.4331 - val_loss: 0.9325 - val_categorical_accuracy: 0.4464\n",
      "Epoch 10/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.0682 - categorical_accuracy: 0.4351 - val_loss: 0.8027 - val_categorical_accuracy: 0.4643\n",
      "Epoch 11/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.0246 - categorical_accuracy: 0.5309 - val_loss: 0.7353 - val_categorical_accuracy: 0.4286\n",
      "Epoch 12/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.0440 - categorical_accuracy: 0.4591 - val_loss: 0.7211 - val_categorical_accuracy: 0.5179\n",
      "Epoch 13/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.0678 - categorical_accuracy: 0.4651 - val_loss: 0.7237 - val_categorical_accuracy: 0.4821\n",
      "Epoch 00013: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     30     22      0\n",
      "fall?      0      5      5      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5645161290322581\n",
      "準正答率（騰落）: 0.5645161290322581\n",
      "学習時間:42.22442960739136[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  800\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 501 samples, validate on 56 samples\n",
      "Epoch 1/100\n",
      "501/501 [==============================] - 9s 17ms/step - loss: 1.3692 - categorical_accuracy: 0.2874 - val_loss: 1.3560 - val_categorical_accuracy: 0.3393\n",
      "Epoch 2/100\n",
      "501/501 [==============================] - 3s 6ms/step - loss: 1.3397 - categorical_accuracy: 0.3593 - val_loss: 1.3176 - val_categorical_accuracy: 0.4107\n",
      "Epoch 3/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.2826 - categorical_accuracy: 0.4351 - val_loss: 1.2677 - val_categorical_accuracy: 0.3929\n",
      "Epoch 4/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.2626 - categorical_accuracy: 0.3992 - val_loss: 1.1828 - val_categorical_accuracy: 0.3929\n",
      "Epoch 5/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.1514 - categorical_accuracy: 0.4451 - val_loss: 0.9785 - val_categorical_accuracy: 0.4107\n",
      "Epoch 6/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.0467 - categorical_accuracy: 0.4810 - val_loss: 0.7237 - val_categorical_accuracy: 0.4821\n",
      "Epoch 7/100\n",
      "501/501 [==============================] - 3s 6ms/step - loss: 1.0366 - categorical_accuracy: 0.4371 - val_loss: 0.7101 - val_categorical_accuracy: 0.4464\n",
      "Epoch 8/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.0998 - categorical_accuracy: 0.4471 - val_loss: 0.7237 - val_categorical_accuracy: 0.4643\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     35     27      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5645161290322581\n",
      "準正答率（騰落）: 0.5645161290322581\n",
      "学習時間:28.819174766540527[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  800\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 501 samples, validate on 56 samples\n",
      "Epoch 1/100\n",
      "501/501 [==============================] - 9s 17ms/step - loss: 1.4025 - categorical_accuracy: 0.1936 - val_loss: 1.3593 - val_categorical_accuracy: 0.3036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.3391 - categorical_accuracy: 0.3613 - val_loss: 1.3119 - val_categorical_accuracy: 0.4107\n",
      "Epoch 3/100\n",
      "501/501 [==============================] - 3s 6ms/step - loss: 1.2840 - categorical_accuracy: 0.4092 - val_loss: 1.2360 - val_categorical_accuracy: 0.3750\n",
      "Epoch 4/100\n",
      "501/501 [==============================] - 3s 6ms/step - loss: 1.2034 - categorical_accuracy: 0.4371 - val_loss: 1.0289 - val_categorical_accuracy: 0.4643\n",
      "Epoch 5/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.0586 - categorical_accuracy: 0.4830 - val_loss: 0.7169 - val_categorical_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.0814 - categorical_accuracy: 0.4731 - val_loss: 0.7121 - val_categorical_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "501/501 [==============================] - 3s 5ms/step - loss: 1.0550 - categorical_accuracy: 0.4451 - val_loss: 0.7454 - val_categorical_accuracy: 0.4821\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     29     18      0\n",
      "fall?      0      6      9      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.6129032258064516\n",
      "準正答率（騰落）: 0.6129032258064516\n",
      "学習時間:26.326387405395508[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  800\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 501 samples, validate on 56 samples\n",
      "Epoch 1/100\n",
      "501/501 [==============================] - 9s 18ms/step - loss: 1.3748 - categorical_accuracy: 0.2854 - val_loss: 1.3418 - val_categorical_accuracy: 0.2679\n",
      "Epoch 2/100\n",
      "501/501 [==============================] - 3s 6ms/step - loss: 1.3107 - categorical_accuracy: 0.4052 - val_loss: 1.2739 - val_categorical_accuracy: 0.3571\n",
      "Epoch 3/100\n",
      "501/501 [==============================] - 3s 6ms/step - loss: 1.2259 - categorical_accuracy: 0.4411 - val_loss: 1.0565 - val_categorical_accuracy: 0.3929\n",
      "Epoch 4/100\n",
      "501/501 [==============================] - 3s 6ms/step - loss: 1.0800 - categorical_accuracy: 0.4491 - val_loss: 0.7129 - val_categorical_accuracy: 0.3929\n",
      "Epoch 5/100\n",
      "501/501 [==============================] - 3s 6ms/step - loss: 1.0835 - categorical_accuracy: 0.4411 - val_loss: 0.7578 - val_categorical_accuracy: 0.4464\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      0      1      0\n",
      "fall?      0     35     26      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.41935483870967744\n",
      "準正答率（騰落）: 0.41935483870967744\n",
      "学習時間:21.813742637634277[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  800\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 501 samples, validate on 56 samples\n",
      "Epoch 1/100\n",
      "501/501 [==============================] - 10s 21ms/step - loss: 1.3888 - categorical_accuracy: 0.2794 - val_loss: 1.3331 - val_categorical_accuracy: 0.4286\n",
      "Epoch 2/100\n",
      "501/501 [==============================] - 3s 7ms/step - loss: 1.2939 - categorical_accuracy: 0.4092 - val_loss: 1.2489 - val_categorical_accuracy: 0.3393\n",
      "Epoch 3/100\n",
      "501/501 [==============================] - 3s 7ms/step - loss: 1.1710 - categorical_accuracy: 0.4351 - val_loss: 0.7179 - val_categorical_accuracy: 0.4107\n",
      "Epoch 4/100\n",
      "501/501 [==============================] - 3s 7ms/step - loss: 1.1002 - categorical_accuracy: 0.4571 - val_loss: 0.7233 - val_categorical_accuracy: 0.3571\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     19     13      0\n",
      "fall?      0     16     14      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.532258064516129\n",
      "準正答率（騰落）: 0.532258064516129\n",
      "学習時間:21.880654096603394[sec]\n",
      "\n",
      "len_seq 519 \n",
      "\n",
      "x.shape= (519, 900, 18)\n",
      "t.shape= (519, 4) \n",
      "\n",
      "x_train.shape= (467, 900, 18)\n",
      "x_test.shape= (52, 900, 18) \n",
      "\n",
      "t_train.shape= (467, 4)\n",
      "t_test.shape= (52, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  900\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 420 samples, validate on 47 samples\n",
      "Epoch 1/100\n",
      "420/420 [==============================] - 9s 22ms/step - loss: 1.4080 - categorical_accuracy: 0.2405 - val_loss: 1.3699 - val_categorical_accuracy: 0.2766\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.3776 - categorical_accuracy: 0.3071 - val_loss: 1.3439 - val_categorical_accuracy: 0.3404\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.3371 - categorical_accuracy: 0.3762 - val_loss: 1.3157 - val_categorical_accuracy: 0.3830\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.3146 - categorical_accuracy: 0.3810 - val_loss: 1.2845 - val_categorical_accuracy: 0.3830\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.2897 - categorical_accuracy: 0.4381 - val_loss: 1.2480 - val_categorical_accuracy: 0.4255\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.2368 - categorical_accuracy: 0.4286 - val_loss: 1.2027 - val_categorical_accuracy: 0.4681\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.2126 - categorical_accuracy: 0.4190 - val_loss: 1.1436 - val_categorical_accuracy: 0.4681\n",
      "Epoch 8/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.1486 - categorical_accuracy: 0.4405 - val_loss: 1.0603 - val_categorical_accuracy: 0.4894\n",
      "Epoch 9/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.0972 - categorical_accuracy: 0.4643 - val_loss: 0.9358 - val_categorical_accuracy: 0.5106\n",
      "Epoch 10/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.0458 - categorical_accuracy: 0.4905 - val_loss: 0.7932 - val_categorical_accuracy: 0.5106\n",
      "Epoch 11/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.9829 - categorical_accuracy: 0.5119 - val_loss: 0.7279 - val_categorical_accuracy: 0.4681\n",
      "Epoch 12/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.9832 - categorical_accuracy: 0.4857 - val_loss: 0.7179 - val_categorical_accuracy: 0.4255\n",
      "Epoch 13/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.9992 - categorical_accuracy: 0.4786 - val_loss: 0.7187 - val_categorical_accuracy: 0.4681\n",
      "Epoch 00013: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     25     17      0\n",
      "fall?      0      6      4      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5576923076923077\n",
      "準正答率（騰落）: 0.5576923076923077\n",
      "学習時間:46.92572474479675[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  900\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 420 samples, validate on 47 samples\n",
      "Epoch 1/100\n",
      "420/420 [==============================] - 9s 22ms/step - loss: 1.3682 - categorical_accuracy: 0.3167 - val_loss: 1.3555 - val_categorical_accuracy: 0.3404\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.3354 - categorical_accuracy: 0.3595 - val_loss: 1.3191 - val_categorical_accuracy: 0.3617\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.2983 - categorical_accuracy: 0.3905 - val_loss: 1.2682 - val_categorical_accuracy: 0.4043\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.2338 - categorical_accuracy: 0.4619 - val_loss: 1.1751 - val_categorical_accuracy: 0.5319\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.1366 - categorical_accuracy: 0.4619 - val_loss: 0.9120 - val_categorical_accuracy: 0.5319\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.0183 - categorical_accuracy: 0.4786 - val_loss: 0.7023 - val_categorical_accuracy: 0.5319\n",
      "Epoch 7/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 0.9503 - categorical_accuracy: 0.4881 - val_loss: 0.7129 - val_categorical_accuracy: 0.4681\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     31     21      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5961538461538461\n",
      "準正答率（騰落）: 0.5961538461538461\n",
      "学習時間:28.89950442314148[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  900\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 420 samples, validate on 47 samples\n",
      "Epoch 1/100\n",
      "420/420 [==============================] - 10s 23ms/step - loss: 1.3955 - categorical_accuracy: 0.2071 - val_loss: 1.3621 - val_categorical_accuracy: 0.2766\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.3311 - categorical_accuracy: 0.3714 - val_loss: 1.3127 - val_categorical_accuracy: 0.4043\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.2751 - categorical_accuracy: 0.3595 - val_loss: 1.2353 - val_categorical_accuracy: 0.5106\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.1840 - categorical_accuracy: 0.4333 - val_loss: 0.9982 - val_categorical_accuracy: 0.5532\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.0406 - categorical_accuracy: 0.4690 - val_loss: 0.7014 - val_categorical_accuracy: 0.4894\n",
      "Epoch 6/100\n",
      "420/420 [==============================] - 3s 7ms/step - loss: 1.0053 - categorical_accuracy: 0.5286 - val_loss: 0.7055 - val_categorical_accuracy: 0.4681\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     30     19      0\n",
      "fall?      0      1      2      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.6153846153846154\n",
      "準正答率（騰落）: 0.6153846153846154\n",
      "学習時間:26.06831932067871[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  900\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 420 samples, validate on 47 samples\n",
      "Epoch 1/100\n",
      "420/420 [==============================] - 10s 24ms/step - loss: 1.3801 - categorical_accuracy: 0.2643 - val_loss: 1.3410 - val_categorical_accuracy: 0.3191\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.3090 - categorical_accuracy: 0.3786 - val_loss: 1.2722 - val_categorical_accuracy: 0.4255\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.2225 - categorical_accuracy: 0.4286 - val_loss: 1.0145 - val_categorical_accuracy: 0.5957\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.0421 - categorical_accuracy: 0.4667 - val_loss: 0.6997 - val_categorical_accuracy: 0.4681\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 1.0366 - categorical_accuracy: 0.4643 - val_loss: 0.7260 - val_categorical_accuracy: 0.4681\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     31     20      0\n",
      "fall?      0      0      1      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.6153846153846154\n",
      "準正答率（騰落）: 0.6153846153846154\n",
      "学習時間:24.51955485343933[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  900\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 420 samples, validate on 47 samples\n",
      "Epoch 1/100\n",
      "420/420 [==============================] - 11s 26ms/step - loss: 1.3860 - categorical_accuracy: 0.2524 - val_loss: 1.3270 - val_categorical_accuracy: 0.4894\n",
      "Epoch 2/100\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 1.3044 - categorical_accuracy: 0.3762 - val_loss: 1.2378 - val_categorical_accuracy: 0.4468\n",
      "Epoch 3/100\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 1.1568 - categorical_accuracy: 0.4595 - val_loss: 0.7113 - val_categorical_accuracy: 0.4681\n",
      "Epoch 4/100\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 1.0585 - categorical_accuracy: 0.4643 - val_loss: 0.7042 - val_categorical_accuracy: 0.4468\n",
      "Epoch 5/100\n",
      "420/420 [==============================] - 4s 8ms/step - loss: 0.9714 - categorical_accuracy: 0.5238 - val_loss: 0.7444 - val_categorical_accuracy: 0.4468\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     24     14      0\n",
      "fall?      0      7      7      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5961538461538461\n",
      "準正答率（騰落）: 0.5961538461538461\n",
      "学習時間:26.561338186264038[sec]\n",
      "\n",
      "len_seq 419 \n",
      "\n",
      "x.shape= (419, 1000, 18)\n",
      "t.shape= (419, 4) \n",
      "\n",
      "x_train.shape= (377, 1000, 18)\n",
      "x_test.shape= (42, 1000, 18) \n",
      "\n",
      "t_train.shape= (377, 4)\n",
      "t_test.shape= (42, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  1000\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 339 samples, validate on 38 samples\n",
      "Epoch 1/100\n",
      "339/339 [==============================] - 10s 31ms/step - loss: 1.3764 - categorical_accuracy: 0.3304 - val_loss: 1.3688 - val_categorical_accuracy: 0.3421\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.3693 - categorical_accuracy: 0.2891 - val_loss: 1.3396 - val_categorical_accuracy: 0.4211\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.3365 - categorical_accuracy: 0.3835 - val_loss: 1.3099 - val_categorical_accuracy: 0.4211\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.3111 - categorical_accuracy: 0.4100 - val_loss: 1.2790 - val_categorical_accuracy: 0.4474\n",
      "Epoch 5/100\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 1.2817 - categorical_accuracy: 0.4366 - val_loss: 1.2435 - val_categorical_accuracy: 0.4211\n",
      "Epoch 6/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.2471 - categorical_accuracy: 0.4543 - val_loss: 1.2004 - val_categorical_accuracy: 0.4474\n",
      "Epoch 7/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.2140 - categorical_accuracy: 0.4543 - val_loss: 1.1448 - val_categorical_accuracy: 0.4211\n",
      "Epoch 8/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.1680 - categorical_accuracy: 0.4661 - val_loss: 1.0675 - val_categorical_accuracy: 0.4474\n",
      "Epoch 9/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.0874 - categorical_accuracy: 0.4985 - val_loss: 0.9491 - val_categorical_accuracy: 0.4474\n",
      "Epoch 10/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.0128 - categorical_accuracy: 0.4808 - val_loss: 0.7991 - val_categorical_accuracy: 0.5526\n",
      "Epoch 11/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.9479 - categorical_accuracy: 0.4808 - val_loss: 0.7250 - val_categorical_accuracy: 0.5526\n",
      "Epoch 12/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.8983 - categorical_accuracy: 0.4838 - val_loss: 0.7054 - val_categorical_accuracy: 0.4737\n",
      "Epoch 13/100\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.8505 - categorical_accuracy: 0.5133 - val_loss: 0.7030 - val_categorical_accuracy: 0.4211\n",
      "Epoch 14/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.9231 - categorical_accuracy: 0.4749 - val_loss: 0.7068 - val_categorical_accuracy: 0.4737\n",
      "Epoch 00014: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     19     14      0\n",
      "fall?      0      6      3      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5238095238095238\n",
      "準正答率（騰落）: 0.5238095238095238\n",
      "学習時間:55.56695771217346[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  1000\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 339 samples, validate on 38 samples\n",
      "Epoch 1/100\n",
      "339/339 [==============================] - 11s 31ms/step - loss: 1.3849 - categorical_accuracy: 0.2773 - val_loss: 1.3498 - val_categorical_accuracy: 0.4474\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.3394 - categorical_accuracy: 0.3599 - val_loss: 1.3089 - val_categorical_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.2999 - categorical_accuracy: 0.3953 - val_loss: 1.2548 - val_categorical_accuracy: 0.5263\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 1.2267 - categorical_accuracy: 0.4602 - val_loss: 1.1588 - val_categorical_accuracy: 0.5263\n",
      "Epoch 5/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.1341 - categorical_accuracy: 0.5310 - val_loss: 0.8891 - val_categorical_accuracy: 0.5263\n",
      "Epoch 6/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.9741 - categorical_accuracy: 0.4779 - val_loss: 0.7072 - val_categorical_accuracy: 0.5263\n",
      "Epoch 7/100\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.8697 - categorical_accuracy: 0.4602 - val_loss: 0.6957 - val_categorical_accuracy: 0.5526\n",
      "Epoch 8/100\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 0.8710 - categorical_accuracy: 0.5280 - val_loss: 0.7124 - val_categorical_accuracy: 0.4737\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     25     17      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5952380952380952\n",
      "準正答率（騰落）: 0.5952380952380952\n",
      "学習時間:34.562487840652466[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  1000\n",
      "n_hidden:  300 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples, validate on 38 samples\n",
      "Epoch 1/100\n",
      "339/339 [==============================] - 11s 32ms/step - loss: 1.3959 - categorical_accuracy: 0.1799 - val_loss: 1.3608 - val_categorical_accuracy: 0.3158\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.3446 - categorical_accuracy: 0.3451 - val_loss: 1.3121 - val_categorical_accuracy: 0.3947\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.2898 - categorical_accuracy: 0.4277 - val_loss: 1.2388 - val_categorical_accuracy: 0.4474\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 1.2018 - categorical_accuracy: 0.4897 - val_loss: 1.0566 - val_categorical_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "339/339 [==============================] - 3s 9ms/step - loss: 1.0323 - categorical_accuracy: 0.4926 - val_loss: 0.7119 - val_categorical_accuracy: 0.4737\n",
      "Epoch 6/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.8312 - categorical_accuracy: 0.4985 - val_loss: 0.6962 - val_categorical_accuracy: 0.5263\n",
      "Epoch 7/100\n",
      "339/339 [==============================] - 4s 10ms/step - loss: 0.9107 - categorical_accuracy: 0.4838 - val_loss: 0.6938 - val_categorical_accuracy: 0.5263\n",
      "Epoch 8/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.8658 - categorical_accuracy: 0.5162 - val_loss: 0.6941 - val_categorical_accuracy: 0.6053\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      4      1      0\n",
      "fall?      0     21     16      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.47619047619047616\n",
      "準正答率（騰落）: 0.47619047619047616\n",
      "学習時間:35.406339168548584[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  1000\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 339 samples, validate on 38 samples\n",
      "Epoch 1/100\n",
      "339/339 [==============================] - 12s 34ms/step - loss: 1.3885 - categorical_accuracy: 0.2448 - val_loss: 1.3313 - val_categorical_accuracy: 0.4211\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 1.3204 - categorical_accuracy: 0.4307 - val_loss: 1.2604 - val_categorical_accuracy: 0.4737\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.2314 - categorical_accuracy: 0.4661 - val_loss: 1.0586 - val_categorical_accuracy: 0.4737\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 1.0130 - categorical_accuracy: 0.5015 - val_loss: 0.7048 - val_categorical_accuracy: 0.4737\n",
      "Epoch 5/100\n",
      "339/339 [==============================] - 3s 10ms/step - loss: 0.9073 - categorical_accuracy: 0.4926 - val_loss: 0.6912 - val_categorical_accuracy: 0.5263\n",
      "Epoch 6/100\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.9499 - categorical_accuracy: 0.4779 - val_loss: 0.6939 - val_categorical_accuracy: 0.5263\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     19     10      0\n",
      "fall?      0      6      7      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.6190476190476191\n",
      "準正答率（騰落）: 0.6190476190476191\n",
      "学習時間:30.421555042266846[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2013\n",
      "maxlen:  1000\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 339 samples, validate on 38 samples\n",
      "Epoch 1/100\n",
      "339/339 [==============================] - 13s 38ms/step - loss: 1.3799 - categorical_accuracy: 0.2950 - val_loss: 1.3171 - val_categorical_accuracy: 0.5789\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 1.3109 - categorical_accuracy: 0.4100 - val_loss: 1.2174 - val_categorical_accuracy: 0.5263\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 1.1683 - categorical_accuracy: 0.4661 - val_loss: 0.6976 - val_categorical_accuracy: 0.5263\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 4s 11ms/step - loss: 0.8491 - categorical_accuracy: 0.5103 - val_loss: 0.7244 - val_categorical_accuracy: 0.4737\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     25     17      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5952380952380952\n",
      "準正答率（騰落）: 0.5952380952380952\n",
      "学習時間:25.502180337905884[sec]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_csv = pd.DataFrame(columns=['time', 'day', 'model', 'start date', 'end date', 'maxlen', 'n_hidden', 'correct', 'semi_correct'])\n",
    "\n",
    "for learning_model in learning_model_list:\n",
    "    for x_days_later in day_list:\n",
    "        x_days_later = int(x_days_later)\n",
    "    \n",
    "        df_list = [] #データフレームのリスト\n",
    "        \n",
    "        if target_name == 'nikkei_Close':\n",
    "            #日経\n",
    "            df_list.append(add_data(csv_path+'nikkei.csv'))\n",
    "            \n",
    "        elif target_name == 'nikkei_diff':\n",
    "            df_list.append(add_data(csv_path+'NASDAQ.csv'))\n",
    "            df_list.append(add_data(csv_path+'USD_JPY.csv'))\n",
    "            #df_list.append(add_data(csv_path+'EUR_JPY.csv'))\n",
    "            #df_list.append(add_data(csv_path+'EUR_USD.csv'))\n",
    "            df_list.append(add_data(csv_path+'nikkei.csv'))\n",
    "            \n",
    "            #日経平均の始値と終値の差\n",
    "            df = pd.read_csv(csv_path+'nikkei.csv', index_col='Date', parse_dates=True)#読み込み\n",
    "            df = df.apply(np.log)*100#正規化\n",
    "            df = df['nikkei_Close'] - df['nikkei_Open']#終値と始値の差を求める\n",
    "            df = df['1988-04-08':]#始値と終値と高値と安値が記録され始めた日からのみ抽出\n",
    "            #df = df.diff(x_days_later)#特定の日数後の増減を求める\n",
    "            #df = df.drop(df.index[0:x_days_later], axis=0)#特定の日数分の行を削除\n",
    "            #df = df_shift(df, 1) \n",
    "            df = df.rename('nikkei_diff')#名前を付ける\n",
    "            df_list.append(df)\n",
    "            \n",
    "            #取引量\n",
    "            df = pd.read_csv(csv_path+'nikkei_volume.csv', index_col='Date', parse_dates=True)\n",
    "            df = df[df.Volume != 0]\n",
    "            df = rise_fall_rate(df, 1)\n",
    "            #df = df.apply(np.log)*100\n",
    "            #df = np.log(df)*100\n",
    "            df_list.append(df)\n",
    "            \n",
    "            #米国債\n",
    "            #df = pd.read_csv('./csv_realtime/treasury_10.csv', index_col='Date', parse_dates=True)\n",
    "            #df = df.drop('Rate', axis=1)\n",
    "            #df_list.append(rise_fall_rate(df, x_days_later))\n",
    "            \n",
    "        elif target_name == 'USD_JPY_diff':\n",
    "            #df_list.append(add_data(csv_path+'NASDAQ.csv', x_days_later))\n",
    "            df_list.append(add_data(csv_path+'USD_JPY.csv', x_days_later))\n",
    "            df_list.append(add_data(csv_path+'EUR_JPY.csv', x_days_later))\n",
    "            #df_list.append(add_data(csv_path+'EUR_USD.csv', x_days_later))\n",
    "            df_list.append(add_data(csv_path+'nikkei.csv', x_days_later))\n",
    "            #df_list.append(add_data(csv_path+'DOW30.csv', x_days_later))\n",
    "            \n",
    "            #f_list.append(add_data(csv_path+'TNX.csv'))#1米国債10年？\n",
    "            #_list.append(add_data(csv_path+'GSPC.csv'))#S&P500\n",
    "            #df_list.append(add_data(csv_path+'RUT.csv'))#Russell2000\n",
    "            #df_list.append(add_data(csv_path+'TOPIX.csv'))\n",
    "            #df_list.append(add_data(csv_path+'BTC_USD.csv'))\n",
    "            \n",
    "            #ドル円の始値と終値の差\n",
    "            df = pd.read_csv(csv_path+'USD_JPY.csv', index_col='Date', parse_dates=True)#読み込み\n",
    "            df = df.apply(np.log)*100#正規化\n",
    "            df = df['USD_JPY_Close'] - df['USD_JPY_Open']#終値と始値の差を求める\n",
    "            df = df['1989-10-16':]#始値と終値と高値と安値が記録され始めた日からのみ抽出\n",
    "            #df = df.diff(x_days_later)#特定の日数後の増減を求める\n",
    "            #df = df.drop(df.index[0:x_days_later], axis=0)#特定の日数分の行を削除\n",
    "            #df = df_shift(df, 1)\n",
    "            df = df.rename('USD_JPY_diff')#名前を付ける\n",
    "            df_list.append(df)\n",
    "            \n",
    "            # 米国債\n",
    "            df = pd.read_csv(csv_path+'treasury_10.csv', index_col='Date', parse_dates=True)\n",
    "            df_list.append(rise_fall_rate(df, x_days_later))         \n",
    "\n",
    "        #全データフレームを結合\n",
    "        df_x = df_list[0]\n",
    "        for i in range(len(df_list) - 1):   \n",
    "            df = df_list[i + 1]\n",
    "            df_x = df_x.join(df, how='inner', rsuffix='_' + str(i))\n",
    "            \n",
    "        print(df_x)\n",
    "\n",
    "        \n",
    "        #指定の期間を抽出してラベルデータを作成------------------------------------------ \n",
    "        for year in year_list:        \n",
    "            #指定の期間を抽出\n",
    "            if end_date == '':\n",
    "                df_x = df_x[year:]\n",
    "            else:\n",
    "                df_x = df_x[year:end_date]\n",
    "        \n",
    "            if is_debug == True:\n",
    "                print('df_x.shape=', df_x.shape)\n",
    "                #print(df_x)\n",
    "    \n",
    "            #ラベルデータを作成する列\n",
    "            target = df_x[target_name]\n",
    "            \n",
    "            #空のデータフレーム作成\n",
    "            df_t = pd.DataFrame(index=df_x.index, columns=['jump', 'rise', 'fall', 'drop'])\n",
    "            df_t = df_t.fillna(0) #０で埋める\n",
    "\n",
    "            #条件にあった値を置換する\n",
    "            df_t.loc[0.995033085 <= target, 'jump'] = 1\n",
    "            df_t.loc[(0 <= target) & (target < 0.995033085), 'rise'] = 1\n",
    "            df_t.loc[(-0.995033085 <= target) & (target < 0), 'fall'] = 1\n",
    "            df_t.loc[target < -0.995033085, 'drop'] = 1\n",
    "\n",
    "            df_t = df_t.shift(-1 * x_days_later, axis=0)#予測先日数分だけ縦にずらす\n",
    "            df_t = df_t.drop(df_t.index[-1*x_days_later:], axis=0)#ラベルデータ末尾の行を削除\n",
    "            df_x = df_x.drop(df_x.index[-1*x_days_later:], axis=0)#学習データの末尾の行を削除\n",
    "\n",
    "            if is_debug == True:\n",
    "                print('df_t.shape=', df_t.shape, '\\n')\n",
    "                #print(df_t)\n",
    "        \n",
    "            #インデックスと列名を外し２次元配列に変換------------------------------------\n",
    "            #print(df_x)\n",
    "            x_data = df_x.values\n",
    "            #print(df_t)\n",
    "            t_data = df_t.values\n",
    "        \n",
    "            if is_debug == True:\n",
    "                print('x_data.shape =', x_data.shape)\n",
    "                print('t_data.shape =', t_data.shape, '\\n')\n",
    "        \n",
    "            #学習データのテンソル化------------------------------------------------------\n",
    "            maxlen = min_maxlen\n",
    "            while maxlen <= max_maxlen:\n",
    "                n_in = x_data.shape[1]   # 学習データ（＝入力）の列数\n",
    "                n_out = t_data.shape[1]  # ラベルデータ（=出力）の列数\n",
    "                len_seq = x_data.shape[0] - maxlen + 1\n",
    "                print('len_seq', len_seq, '\\n')#●デバッグ\n",
    "                data = []\n",
    "                target = []\n",
    "\n",
    "                #\n",
    "                for i in range(0, len_seq):\n",
    "                    data.append(x_data[i:i+maxlen, :])\n",
    "                    target.append(t_data[i+maxlen-1, :])\n",
    "\n",
    "                x = np.array(data).reshape(len(data), maxlen, n_in)\n",
    "                t = np.array(target).reshape(len(data), n_out)\n",
    "\n",
    "                if is_debug == True:\n",
    "                    print('x.shape=', x.shape)\n",
    "                    print('t.shape=', t.shape, '\\n')\n",
    "\n",
    "                # ここからソースコードの後半\n",
    "                n_train = int(len(data)*0.9)              # 訓練データ長\n",
    "                x_train,x_test = np.vsplit(x, [n_train])  # 学習データを訓練用とテスト用に分割\n",
    "                t_train,t_test = np.vsplit(t, [n_train])  # ラベルデータを訓練用とテスト用に分割\n",
    "\n",
    "                if is_debug == True:\n",
    "                    print('x_train.shape=', x_train.shape)\n",
    "                    print('x_test.shape=', x_test.shape, '\\n')\n",
    "                    print('t_train.shape=', t_train.shape)\n",
    "                    print('t_test.shape=', t_test.shape, '\\n')\n",
    "            \n",
    "                #メイン処理--------------------------------------------------------------\n",
    "                n_hidden = min_n_hidden\n",
    "                while n_hidden <= max_n_hidden:   \n",
    "                    epochs = 100      # エポック数（同じデータでの学習回数）\n",
    "                    batch_size = 256  #バッチサイズ\n",
    "                \n",
    "                    #パラメータの表示\n",
    "                    print('model: ', learning_model)\n",
    "                    print('day: ', x_days_later)\n",
    "                    print('since: ', year)\n",
    "                    print('maxlen: ', maxlen)\n",
    "                    print('n_hidden: ', n_hidden, '\\n')\n",
    "                \n",
    "                    # モデル定義\n",
    "                    prediction = Prediction(maxlen, n_hidden, n_in, n_out, learning_model)\n",
    "                    \n",
    "                    # 学習時間の計測開始\n",
    "                    start = time.time()\n",
    "                    \n",
    "                    # 学習\n",
    "                    model = prediction.train(x_train, t_train, batch_size, epochs)\n",
    "                    \n",
    "                    # 学習時間の計測終了と表示\n",
    "                    end = time.time()\n",
    "\n",
    "                    #予測精度の評価------------------------------------------------------\n",
    "\n",
    "                    # 正答率、準正答率（騰落）集計\n",
    "                    preds = model.predict(x_test)\n",
    "                \n",
    "                    #正解数を数える変数\n",
    "                    correct = 0\n",
    "                    semi_correct = 0\n",
    "                \n",
    "                    #表を作るためのデータフレーム\n",
    "                    matrix = pd.DataFrame(columns=['jump!', 'rise!', 'fall!', 'drop!'], index=['jump?', 'rise?', 'fall?', 'drop?'])\n",
    "                    matrix = matrix.fillna(0)\n",
    "\n",
    "                    #正解数を数える\n",
    "                    for i in range(len(preds)):\n",
    "                        pred = np.argmax(preds[i,:])#argmaxとは配列の最大要素のインデックスを返すメソッドである\n",
    "                        tar = np.argmax(t_test[i,:])\n",
    "                        matrix.iat[pred, tar] = matrix.iat[pred, tar] + 1 #●マトリックスのセルをインクリメント\n",
    "                        if pred == tar :#完全一致\n",
    "                           correct += 1\n",
    "                        else :\n",
    "                            if pred+tar == 1 or pred+tar == 5 :\n",
    "                                semi_correct += 1\n",
    "                \n",
    "                    #正答率と準正答率を求める\n",
    "                    correct_rate = 1.0 *correct / len(preds) \n",
    "                    semi_correct_rate = 1.0 * (correct+semi_correct) / len(preds)\n",
    "                \n",
    "                    #csvに記録\n",
    "                    series = pd.Series([end - start,\n",
    "                                        x_days_later,\n",
    "                                        learning_model,\n",
    "                                        year,\n",
    "                                        end_date,\n",
    "                                        maxlen,\n",
    "                                        n_hidden,\n",
    "                                        correct_rate,\n",
    "                                        semi_correct_rate],\n",
    "                                        index = result_csv.columns)\n",
    "                    result_csv = result_csv.append(series, ignore_index = True)\n",
    "                    result_csv.to_csv('./log/log.csv', index=False)\n",
    "                \n",
    "                    #表と正答率と学習時間を表示\n",
    "                    print('\\n', matrix, '\\n')\n",
    "                    print(\"正答率:\", 1.0 * correct / len(preds))\n",
    "                    print(\"準正答率（騰落）:\", 1.0 * (correct+semi_correct) / len(preds))\n",
    "                    print (\"学習時間:{0}\".format(end - start) + \"[sec]\\n\")\n",
    "                \n",
    "                \n",
    "                    #次のステップへ\n",
    "                    n_hidden += 100\n",
    "                    \n",
    "                #次のステップへ\n",
    "                maxlen += 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算終了の合図"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    winsound.Beep(784,300)\n",
    "    winsound.Beep(698,300)\n",
    "    winsound.Beep(784,600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果発表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#最大\n",
    "for i in day_list:\n",
    "    print('\\n', i, 'days later\\n')\n",
    "    result2 = result_csv[result_csv['day'] == int(i)]\n",
    "    \n",
    "    print('平均計算時間')\n",
    "    print(result2['time'].mean(), '秒')\n",
    "    \n",
    "    print('max correct')\n",
    "    print(result2[result2['correct'] == result2['correct'].max()])\n",
    "    \n",
    "    print('\\nmax semi correct')\n",
    "    print(result2[result2['semi_correct'] == result2['semi_correct'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正答率の平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正答率\n",
      "0.5332163099208822\n",
      "準正答率\n",
      "0.5339205352729949\n"
     ]
    }
   ],
   "source": [
    "print('正答率')\n",
    "print(result_csv['correct'].mean())\n",
    "print('準正答率')\n",
    "print(result_csv['semi_correct'].mean())\n",
    "#csv = pd.read_csv('./log/log.csv')\n",
    "#print(csv['semi_correct'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "a\n",
      "b\n",
      "c\n",
      "1\n",
      "2\n",
      "3\n",
      "a 1\n",
      "b 2\n",
      "c 3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = {'a': 1,\n",
    "     'b': 2,\n",
    "     'c' : 3}\n",
    "\n",
    "# キーを取得\n",
    "for i in x:\n",
    "    print(i)\n",
    "    \n",
    "# キーを取得\n",
    "for i in x.keys():\n",
    "    print(i)\n",
    "\n",
    "# 要素を取得\n",
    "for i in x.values():\n",
    "    print(i)\n",
    "\n",
    "# キーと要素を取得\n",
    "for i, j in x.items():\n",
    "    print(i, j)\n",
    "    \n",
    "print(x['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
