{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.initializers import glorot_uniform, orthogonal, TruncatedNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.recurrent import GRU, SimpleRNN\n",
    "\n",
    "import pandas as pd #行列計算\n",
    "import numpy as np #行列計算\n",
    "import math #数値計算\n",
    "import itertools #順列・組み合わせ\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt #グラフ\n",
    "import winsound # ビープ音\n",
    "import gc\n",
    "\n",
    "from df_method import rise_fall_rate, moving_average, GCDC, df_shift, add_data, RSI, Z_score_normalization, Min_Max_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction :\n",
    "    #初期化\n",
    "    def __init__(self, maxlen, n_hidden, n_in, n_out, learning_model):\n",
    "        self.maxlen = maxlen #入力系列数\n",
    "        self.n_hidden = n_hidden #出力次元（隠れ層内のニューロン数）\n",
    "        self.n_in = n_in #学習データの列数\n",
    "        self.n_out = n_out #ラベルデータの列数\n",
    "        \n",
    "        self.learning_model = learning_model #●学習モデルの選択\n",
    "\n",
    "    #モデルの生成\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        if self.learning_model == 'RNN':\n",
    "            #RNN層\n",
    "            model.add(SimpleRNN(self.n_hidden,\n",
    "                                batch_input_shape = (None, self.maxlen, self.n_in),\n",
    "                                kernel_initializer = glorot_uniform(seed=20170719),\n",
    "                                recurrent_initializer = orthogonal(gain=1.0, seed=20170719),\n",
    "                                dropout = 0.5,\n",
    "                                recurrent_dropout = 0.5))\n",
    "        elif self.learning_model == 'LSTM':\n",
    "            #LSTM層\n",
    "            model.add(LSTM(self.n_hidden,\n",
    "                           batch_input_shape = (None, self.maxlen, self.n_in),\n",
    "                           kernel_initializer = glorot_uniform(seed=20170719), \n",
    "                           recurrent_initializer = orthogonal(gain=1.0, seed=20170719), \n",
    "                           dropout = 0.5, \n",
    "                           recurrent_dropout = 0.5))\n",
    "        elif self.learning_model == 'GRU':\n",
    "            #GRU層\n",
    "            model.add(GRU(self.n_hidden,\n",
    "                          batch_input_shape = (None, self.maxlen, self.n_in),\n",
    "                          kernel_initializer = glorot_uniform(seed=20170719),\n",
    "                          recurrent_initializer = orthogonal(gain=1.0, seed=20170719),\n",
    "                          dropout = 0.5,\n",
    "                          recurrent_dropout = 0.5))\n",
    "        #ドロップアウト層\n",
    "        model.add(Dropout(0.5))\n",
    "        #結合層\n",
    "        model.add(Dense(self.n_out, kernel_initializer = glorot_uniform(seed=20170719)))\n",
    "        #活性化層\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        #コンパイル\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer = \"Adam\", metrics = ['categorical_accuracy']) # \"RMSprop\"\n",
    "        return model\n",
    "\n",
    "    # 学習\n",
    "    def train(self, x_train, t_train, batch_size, epochs) :\n",
    "        early_stopping = EarlyStopping(patience=0, verbose=1)\n",
    "        model = self.create_model()\n",
    "        self.hist = model.fit(x_train, t_train, batch_size = batch_size, epochs = epochs, verbose = 1,\n",
    "                              shuffle = True, callbacks = [early_stopping], validation_split = 0.1)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変数宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_debug = True\n",
    "csv_path = './csv_realtime/'\n",
    "#day_list = ['1'] # '1', '2', '7', '30', '365'\n",
    "x_days_later = 1\n",
    "learning_model_list = ['LSTM']#['RNN', 'LSTM', 'GRU']\n",
    "year_list = ['2009-3-10']#  '1960', '1970', '1980', '1990', '2000', '2010'\n",
    "end_date = '2018-10-31'# 終点年月日\n",
    "\n",
    "min_maxlen = 100\n",
    "max_maxlen = 1000#1000\n",
    "min_n_hidden = 100\n",
    "max_n_hidden = 500#500\n",
    "\n",
    "target_name = 'USD_JPY_diff'# 'nikkei_Close', 'nikkei_diff', 'USD_JPY'\n",
    "\n",
    "max_correct = 0 # 最高正答率\n",
    "max_correct_number = -1 # 最高正答率を出したデータフレームの番号 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 絶対に必要なデータフレームを用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1989-10-16    0.105734\n",
      "1989-10-17    0.028052\n",
      "1989-10-18    0.042400\n",
      "1989-10-19    0.077582\n",
      "1989-10-20    0.049142\n",
      "1989-10-23    0.007045\n",
      "1989-10-24    0.000000\n",
      "1989-10-25    0.007066\n",
      "1989-10-26    0.035217\n",
      "1989-10-27    0.035312\n",
      "1989-10-30    0.035156\n",
      "1989-10-31    0.035008\n",
      "1989-11-01    0.034794\n",
      "1989-11-02    0.034874\n",
      "1989-11-03    0.020931\n",
      "1989-11-06    0.020856\n",
      "1989-11-07    0.027996\n",
      "1989-11-08    0.034898\n",
      "1989-11-09    0.013980\n",
      "1989-11-10    0.034861\n",
      "1989-11-13    0.027807\n",
      "1989-11-14    0.034947\n",
      "1989-11-15    0.013907\n",
      "1989-11-16    0.013878\n",
      "1989-11-17    0.034644\n",
      "1989-11-20    0.020782\n",
      "1989-11-21    0.006966\n",
      "1989-11-22    0.034930\n",
      "1989-11-23    0.034692\n",
      "1989-11-24    0.034825\n",
      "                ...   \n",
      "2018-10-01    0.237206\n",
      "2018-10-02   -0.246024\n",
      "2018-10-03    0.753861\n",
      "2018-10-04   -0.472938\n",
      "2018-10-05   -0.140622\n",
      "2018-10-08   -0.414262\n",
      "2018-10-09   -0.221112\n",
      "2018-10-10   -0.612655\n",
      "2018-10-11   -0.106952\n",
      "2018-10-12    0.071339\n",
      "2018-10-15   -0.366186\n",
      "2018-10-16    0.419662\n",
      "2018-10-17    0.329079\n",
      "2018-10-18   -0.409253\n",
      "2018-10-19    0.329343\n",
      "2018-10-22    0.213068\n",
      "2018-10-23   -0.319801\n",
      "2018-10-24   -0.169197\n",
      "2018-10-25    0.169227\n",
      "2018-10-26   -0.454810\n",
      "2018-10-29    0.410348\n",
      "2018-10-30    0.621230\n",
      "2018-10-31   -0.035395\n",
      "2018-11-01   -0.257058\n",
      "2018-11-02    0.487050\n",
      "2018-11-05    0.008836\n",
      "2018-11-06    0.211827\n",
      "2018-11-07    0.123381\n",
      "2018-11-08    0.448254\n",
      "2018-11-09   -0.242305\n",
      "Name: USD_JPY_diff, Length: 7564, dtype: float64\n",
      "            USD_JPY_Open  USD_JPY_High  USD_JPY_Low  USD_JPY_Close  \\\n",
      "Date                                                                 \n",
      "1989-10-16      0.218873     -1.776865    -0.851794       0.324607   \n",
      "1989-10-17      0.548602      0.399930     0.142470       0.470920   \n",
      "1989-10-18     -0.767474     -0.049028    -0.064087      -0.753127   \n",
      "1989-10-19      0.176547     -0.357933     0.206354       0.211730   \n",
      "1989-10-20      0.478638      0.266817     0.361869       0.450198   \n",
      "1989-10-23     -0.330579     -0.042082     0.381734      -0.372676   \n",
      "1989-10-24     -0.402387     -0.217704    -0.459673      -0.409432   \n",
      "1989-10-25      0.106048     -0.246366     0.000000       0.113114   \n",
      "1989-10-26      0.303383      0.716295     0.184123       0.331535   \n",
      "1989-10-27     -0.268059      0.216685     0.021223      -0.267964   \n",
      "1989-10-30      0.444022     -0.525046     0.077780       0.443866   \n",
      "1989-10-31      0.421053      0.294365     0.345740       0.420906   \n",
      "1989-11-01      0.614355      0.669599     0.442774       0.614141   \n",
      "1989-11-02     -0.229941      0.277682     0.384952      -0.229861   \n",
      "1989-11-03     -0.027908     -0.326355    -0.630696      -0.041850   \n",
      "1989-11-06      0.362193      0.159839     0.504875       0.362117   \n",
      "1989-11-07     -0.676692      0.055536    -0.118977      -0.669552   \n",
      "1989-11-08      0.272623     -0.549777    -0.189255       0.279525   \n",
      "1989-11-09     -0.139714      0.055811    -0.302147      -0.160631   \n",
      "1989-11-10      0.244371      0.153321     0.238982       0.265252   \n",
      "1989-11-13      0.299412      0.285108     0.413354       0.292357   \n",
      "1989-11-14     -0.543783      0.117978    -0.125927      -0.536643   \n",
      "1989-11-15      0.522923     -0.145757     0.069979       0.501883   \n",
      "1989-11-16      0.208406      0.408970     0.279427       0.208377   \n",
      "1989-11-17      0.138696     -0.062277     0.313425       0.159462   \n",
      "1989-11-20      0.027716      0.283394     0.222284       0.013854   \n",
      "1989-11-21     -0.548822     -0.221117    -0.465974      -0.562638   \n",
      "1989-11-22     -0.299997     -0.339535    -0.279232      -0.272033   \n",
      "1989-11-23      0.682406      0.249567    -0.083922       0.682169   \n",
      "1989-11-24     -0.382410     -0.214868     0.153803      -0.382277   \n",
      "...                  ...           ...          ...            ...   \n",
      "2018-10-01      0.281864      0.289843     0.396599       0.237206   \n",
      "2018-10-02      0.228431     -0.008771    -0.140833      -0.254800   \n",
      "2018-10-03     -0.263621      0.437599    -0.026428       0.736264   \n",
      "2018-10-04      0.701450      0.000000     0.105671      -0.525349   \n",
      "2018-10-05     -0.516842     -0.393753    -0.044016      -0.184526   \n",
      "2018-10-08     -0.149418     -0.131596    -0.662576      -0.423057   \n",
      "2018-10-09     -0.440762     -0.484007     0.044309      -0.247612   \n",
      "2018-10-10     -0.194553     -0.105914    -0.524096      -0.586095   \n",
      "2018-10-11     -0.630469     -0.664513    -0.410532      -0.124766   \n",
      "2018-10-12     -0.142628     -0.008890     0.044705       0.035663   \n",
      "2018-10-15      0.062425     -0.258157    -0.223724      -0.375101   \n",
      "2018-10-16     -0.366186      0.089095     0.107450       0.419662   \n",
      "2018-10-17      0.437481      0.311208     0.223484       0.346898   \n",
      "2018-10-18      0.337958      0.044379    -0.071460      -0.400374   \n",
      "2018-10-19     -0.418169     -0.079897     0.169635       0.320428   \n",
      "2018-10-22      0.320456      0.212917     0.204964       0.204181   \n",
      "2018-10-23      0.204199     -0.035455    -0.338862      -0.328670   \n",
      "2018-10-24     -0.319801     -0.088692     0.133899      -0.169197   \n",
      "2018-10-25     -0.187024     -0.062131    -0.250089       0.151400   \n",
      "2018-10-26      0.187024     -0.204417    -0.394266      -0.437013   \n",
      "2018-10-29     -0.463748      0.097817     0.358488       0.401410   \n",
      "2018-10-30      0.410348      0.461116     0.455216       0.621230   \n",
      "2018-10-31      0.621230      0.282711     0.444287      -0.035395   \n",
      "2018-11-01     -0.061950     -0.335808    -0.159716      -0.283613   \n",
      "2018-11-02     -0.274811      0.265205    -0.044411       0.469297   \n",
      "2018-11-05      0.460545      0.017655     0.443224      -0.017669   \n",
      "2018-11-06      0.008836      0.141131     0.026531       0.211827   \n",
      "2018-11-07      0.194192      0.281666    -0.132726       0.105746   \n",
      "2018-11-08      0.105764      0.237040     0.476991       0.430637   \n",
      "2018-11-09      0.460531      0.023673     0.140895      -0.230028   \n",
      "\n",
      "            USD_JPY_diff  \n",
      "Date                      \n",
      "1989-10-16      0.105734  \n",
      "1989-10-17      0.028052  \n",
      "1989-10-18      0.042400  \n",
      "1989-10-19      0.077582  \n",
      "1989-10-20      0.049142  \n",
      "1989-10-23      0.007045  \n",
      "1989-10-24      0.000000  \n",
      "1989-10-25      0.007066  \n",
      "1989-10-26      0.035217  \n",
      "1989-10-27      0.035312  \n",
      "1989-10-30      0.035156  \n",
      "1989-10-31      0.035008  \n",
      "1989-11-01      0.034794  \n",
      "1989-11-02      0.034874  \n",
      "1989-11-03      0.020931  \n",
      "1989-11-06      0.020856  \n",
      "1989-11-07      0.027996  \n",
      "1989-11-08      0.034898  \n",
      "1989-11-09      0.013980  \n",
      "1989-11-10      0.034861  \n",
      "1989-11-13      0.027807  \n",
      "1989-11-14      0.034947  \n",
      "1989-11-15      0.013907  \n",
      "1989-11-16      0.013878  \n",
      "1989-11-17      0.034644  \n",
      "1989-11-20      0.020782  \n",
      "1989-11-21      0.006966  \n",
      "1989-11-22      0.034930  \n",
      "1989-11-23      0.034692  \n",
      "1989-11-24      0.034825  \n",
      "...                  ...  \n",
      "2018-10-01      0.237206  \n",
      "2018-10-02     -0.246024  \n",
      "2018-10-03      0.753861  \n",
      "2018-10-04     -0.472938  \n",
      "2018-10-05     -0.140622  \n",
      "2018-10-08     -0.414262  \n",
      "2018-10-09     -0.221112  \n",
      "2018-10-10     -0.612655  \n",
      "2018-10-11     -0.106952  \n",
      "2018-10-12      0.071339  \n",
      "2018-10-15     -0.366186  \n",
      "2018-10-16      0.419662  \n",
      "2018-10-17      0.329079  \n",
      "2018-10-18     -0.409253  \n",
      "2018-10-19      0.329343  \n",
      "2018-10-22      0.213068  \n",
      "2018-10-23     -0.319801  \n",
      "2018-10-24     -0.169197  \n",
      "2018-10-25      0.169227  \n",
      "2018-10-26     -0.454810  \n",
      "2018-10-29      0.410348  \n",
      "2018-10-30      0.621230  \n",
      "2018-10-31     -0.035395  \n",
      "2018-11-01     -0.257058  \n",
      "2018-11-02      0.487050  \n",
      "2018-11-05      0.008836  \n",
      "2018-11-06      0.211827  \n",
      "2018-11-07      0.123381  \n",
      "2018-11-08      0.448254  \n",
      "2018-11-09     -0.242305  \n",
      "\n",
      "[7564 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_target = add_data(csv_path+'USD_JPY.csv', x_days_later)\n",
    "\n",
    "#ドル円の始値と終値の差\n",
    "usd_jpy_diff = pd.read_csv(csv_path+'USD_JPY.csv', index_col='Date', parse_dates=True)#読み込み\n",
    "usd_jpy_diff = usd_jpy_diff.apply(np.log)*100#正規化\n",
    "usd_jpy_diff = usd_jpy_diff['USD_JPY_Close'] - usd_jpy_diff['USD_JPY_Open']#終値と始値の差を求める\n",
    "usd_jpy_diff = usd_jpy_diff['1989-10-16':]#始値と終値と高値と安値が記録され始めた日からのみ抽出\n",
    "#usd_jpy_diff = usd_jpy_diff.diff(x_days_later)#特定の日数後の増減を求める\n",
    "#usd_jpy_diff = usd_jpy_diff.drop(df.index[0:x_days_later], axis=0)#特定の日数分の行を削除\n",
    "#usd_jpy_diff = df_shift(df, 1)\n",
    "usd_jpy_diff = usd_jpy_diff.rename('USD_JPY_diff')#名前を付ける\n",
    "print(usd_jpy_diff)\n",
    "\n",
    "df_target = df_target.join(usd_jpy_diff, how='inner')\n",
    "print(df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証するデータフレームを用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[            NASDAQ_Open  NASDAQ_High  NASDAQ_Low  NASDAQ_Close  \\\n",
      "Date                                                             \n",
      "1971-02-08     0.836488     0.836488    0.836488      0.836488   \n",
      "1971-02-09    -0.079359    -0.079359   -0.079359     -0.079359   \n",
      "1971-02-10    -0.069496    -0.069496   -0.069496     -0.069496   \n",
      "1971-02-11     0.751953     0.751953    0.751953      0.751953   \n",
      "1971-02-12     0.589688     0.589688    0.589688      0.589688   \n",
      "1971-02-16     0.137093     0.137093    0.137093      0.137093   \n",
      "1971-02-17    -0.441333    -0.441333   -0.441333     -0.441333   \n",
      "1971-02-18    -0.315023    -0.315023   -0.315023     -0.315023   \n",
      "1971-02-19    -0.712452    -0.712452   -0.712452     -0.712452   \n",
      "1971-02-22    -1.018071    -1.018071   -1.018071     -1.018071   \n",
      "1971-02-23     0.040121     0.040121    0.040121      0.040121   \n",
      "1971-02-24     0.918351     0.918351    0.918351      0.918351   \n",
      "1971-02-25     0.584540     0.584540    0.584540      0.584540   \n",
      "1971-02-26     0.108598     0.108598    0.108598      0.108598   \n",
      "1971-03-01     0.433245     0.433245    0.433245      0.433245   \n",
      "1971-03-02     0.058930     0.058930    0.058930      0.058930   \n",
      "1971-03-03     0.225594     0.225594    0.225594      0.225594   \n",
      "1971-03-04     0.693192     0.693192    0.693192      0.693192   \n",
      "1971-03-05     0.213822     0.213822    0.213822      0.213822   \n",
      "1971-03-08     1.187104     1.187104    1.187104      1.187104   \n",
      "1971-03-09     0.172547     0.172547    0.172547      0.172547   \n",
      "1971-03-10    -0.258936    -0.258936   -0.258936     -0.258936   \n",
      "1971-03-11     0.115166     0.115166    0.115166      0.115166   \n",
      "1971-03-12     0.229927     0.229927    0.229927      0.229927   \n",
      "1971-03-15     0.601058     0.601058    0.601058      0.601058   \n",
      "1971-03-16     0.408184     0.408184    0.408184      0.408184   \n",
      "1971-03-17    -0.056854    -0.056854   -0.056854     -0.056854   \n",
      "1971-03-18     0.359540     0.359540    0.359540      0.359540   \n",
      "1971-03-19    -0.103945    -0.103945   -0.103945     -0.103945   \n",
      "1971-03-22    -0.378890    -0.378890   -0.378890     -0.378890   \n",
      "...                 ...          ...         ...           ...   \n",
      "2018-10-01     0.831477     0.523359    0.048640     -0.112540   \n",
      "2018-10-02    -0.831848    -0.658727   -0.447143     -0.470792   \n",
      "2018-10-03     0.126778    -0.002728    0.350582      0.318760   \n",
      "2018-10-04    -0.515597    -0.707247   -2.257811     -1.830717   \n",
      "2018-10-05    -1.494478    -1.188705   -1.507379     -1.162380   \n",
      "2018-10-08    -1.634409    -1.342060   -0.795413     -0.676357   \n",
      "2018-10-09    -0.240253     0.031162    0.834026      0.026752   \n",
      "2018-10-10    -0.446485    -1.271550   -3.942384     -4.169057   \n",
      "2018-10-11    -4.058470    -2.737891   -1.994268     -1.260800   \n",
      "2018-10-12     1.608127     0.312860    1.287925      2.264101   \n",
      "2018-10-15    -0.460709    -0.209884    0.429834     -0.886280   \n",
      "2018-10-16     0.379960     2.074212    1.253853      2.849048   \n",
      "2018-10-17     2.207980     0.161138    0.925185     -0.036499   \n",
      "2018-10-18    -0.690706    -0.701634   -1.473564     -2.083123   \n",
      "2018-10-19    -1.139673    -0.446978   -0.324717     -0.483595   \n",
      "2018-10-22    -0.578282    -0.825646   -0.047931      0.262777   \n",
      "2018-10-23    -2.135583    -0.639762   -2.241998     -0.417141   \n",
      "2018-10-24     1.283392    -0.494896   -2.244379     -4.526298   \n",
      "2018-10-25    -3.087919    -0.957679    1.114210      2.910634   \n",
      "2018-10-26    -1.009737    -1.112781   -1.707599     -2.086705   \n",
      "2018-10-29     2.045409     0.168600   -1.919538     -1.644770   \n",
      "2018-10-30    -3.562933    -1.780797    1.129690      1.567163   \n",
      "2018-10-31     3.620671     2.774802    3.772138      1.994184   \n",
      "2018-11-01     0.701155     0.910408    0.218039      1.738992   \n",
      "2018-11-02     1.304265     0.411342    0.167021     -1.042124   \n",
      "2018-11-05    -1.082614    -1.583479   -0.588138     -0.383229   \n",
      "2018-11-06    -0.245536     0.697096    0.891977      0.640743   \n",
      "2018-11-07     1.624985     2.301357    1.558368      2.606608   \n",
      "2018-11-08     1.308616    -0.079267    0.854901     -0.527960   \n",
      "2018-11-09    -1.007939    -1.231173   -2.023438     -2.279664   \n",
      "\n",
      "            NASDAQ_Adj Close  \n",
      "Date                          \n",
      "1971-02-08          0.836488  \n",
      "1971-02-09         -0.079359  \n",
      "1971-02-10         -0.069496  \n",
      "1971-02-11          0.751953  \n",
      "1971-02-12          0.589688  \n",
      "1971-02-16          0.137093  \n",
      "1971-02-17         -0.441333  \n",
      "1971-02-18         -0.315023  \n",
      "1971-02-19         -0.712452  \n",
      "1971-02-22         -1.018071  \n",
      "1971-02-23          0.040121  \n",
      "1971-02-24          0.918351  \n",
      "1971-02-25          0.584540  \n",
      "1971-02-26          0.108598  \n",
      "1971-03-01          0.433245  \n",
      "1971-03-02          0.058930  \n",
      "1971-03-03          0.225594  \n",
      "1971-03-04          0.693192  \n",
      "1971-03-05          0.213822  \n",
      "1971-03-08          1.187104  \n",
      "1971-03-09          0.172547  \n",
      "1971-03-10         -0.258936  \n",
      "1971-03-11          0.115166  \n",
      "1971-03-12          0.229927  \n",
      "1971-03-15          0.601058  \n",
      "1971-03-16          0.408184  \n",
      "1971-03-17         -0.056854  \n",
      "1971-03-18          0.359540  \n",
      "1971-03-19         -0.103945  \n",
      "1971-03-22         -0.378890  \n",
      "...                      ...  \n",
      "2018-10-01         -0.112540  \n",
      "2018-10-02         -0.470792  \n",
      "2018-10-03          0.318760  \n",
      "2018-10-04         -1.830717  \n",
      "2018-10-05         -1.162380  \n",
      "2018-10-08         -0.676357  \n",
      "2018-10-09          0.026752  \n",
      "2018-10-10         -4.169057  \n",
      "2018-10-11         -1.260800  \n",
      "2018-10-12          2.264101  \n",
      "2018-10-15         -0.886280  \n",
      "2018-10-16          2.849048  \n",
      "2018-10-17         -0.036499  \n",
      "2018-10-18         -2.083123  \n",
      "2018-10-19         -0.483595  \n",
      "2018-10-22          0.262777  \n",
      "2018-10-23         -0.417141  \n",
      "2018-10-24         -4.526298  \n",
      "2018-10-25          2.910634  \n",
      "2018-10-26         -2.086705  \n",
      "2018-10-29         -1.644770  \n",
      "2018-10-30          1.567163  \n",
      "2018-10-31          1.994184  \n",
      "2018-11-01          1.738992  \n",
      "2018-11-02         -1.042124  \n",
      "2018-11-05         -0.383229  \n",
      "2018-11-06          0.640743  \n",
      "2018-11-07          2.606608  \n",
      "2018-11-08         -0.527960  \n",
      "2018-11-09         -2.279664  \n",
      "\n",
      "[12049 rows x 5 columns],             EUR_JPY_Open  EUR_JPY_High  EUR_JPY_Low  EUR_JPY_Close\n",
      "Date                                                              \n",
      "2007-04-03      0.095271      0.777280     0.260889       0.658064\n",
      "2007-04-04      0.626525      0.075510     0.462832       0.037833\n",
      "2007-04-05      0.094587      0.295199     0.183272       0.490536\n",
      "2007-04-06      0.471595      0.156666     0.547809       0.087791\n",
      "2007-04-09      0.075249     -0.056372     0.006279      -0.119163\n",
      "2007-04-10     -0.119171      0.312774    -0.125660       0.407077\n",
      "2007-04-11      0.419603      0.205896     0.332654       0.218511\n",
      "2007-04-12      0.212261      0.267654     0.375258       0.186916\n",
      "2007-04-13      0.186916      0.359891    -0.174945       0.416188\n",
      "2007-04-16      0.409989      0.605164     0.871682       0.463837\n",
      "2007-04-17      0.457695     -0.160197    -0.049606      -0.457638\n",
      "2007-04-18     -0.451496     -0.333540    -0.503654       0.111510\n",
      "2007-04-19      0.123900     -0.068080    -0.499939      -0.148708\n",
      "2007-04-20     -0.148699      0.272042     0.929137       0.018601\n",
      "2007-04-23      0.018599     -0.092658    -0.398035      -0.136485\n",
      "2007-04-24     -0.136476     -0.012361    -0.149673       0.408897\n",
      "2007-04-25      0.408872      0.123541     0.646970       0.123579\n",
      "2007-04-26      0.098869      0.474212     0.260094       0.400580\n",
      "2007-04-27      0.425257      0.331228     0.333416       0.435731\n",
      "2007-04-30      0.411208     -0.018373     0.117049      -0.153210\n",
      "2007-05-01     -0.134837      0.018373     0.239830       0.024529\n",
      "2007-05-02      0.024529      0.055098    -0.147520       0.165416\n",
      "2007-05-03      0.147050      0.122332     0.350005      -0.097991\n",
      "2007-05-04     -0.085753     -0.116212    -0.171779       0.079625\n",
      "2007-05-07      0.085753      0.024477     0.067520       0.012244\n",
      "2007-05-08      0.000000     -0.030597    -0.658727      -0.478646\n",
      "2007-05-09     -0.472553     -0.496979     0.104948      -0.067686\n",
      "2007-05-10     -0.080002      0.270270    -0.284232      -0.481274\n",
      "2007-05-11     -0.462807     -0.233372    -0.297453       0.542809\n",
      "2007-05-14      0.561262      0.337600     0.889719       0.288707\n",
      "...                  ...           ...          ...            ...\n",
      "2018-10-08     -0.045784     -0.106626    -0.868869      -0.704660\n",
      "2018-10-09     -0.735410     -0.780298    -0.146837      -0.238563\n",
      "2018-10-10     -0.200108      0.207143    -0.015469      -0.385982\n",
      "2018-10-11     -0.424629     -0.222504    -0.085123       0.563034\n",
      "2018-10-12      0.509339      0.222504     0.154715      -0.277265\n",
      "2018-10-15     -0.262063     -0.537925    -0.216668      -0.200726\n",
      "2018-10-16     -0.108108      0.376851     0.232126       0.385654\n",
      "2018-10-17      0.439426     -0.099843    -0.177915      -0.269802\n",
      "2018-10-18     -0.346754     -0.330960    -0.668067      -0.844934\n",
      "2018-10-19     -0.852718     -0.053981     0.109060       0.898952\n",
      "2018-10-22      0.821837      0.392625     0.605451      -0.223982\n",
      "2018-10-23     -0.154548     -0.616572    -0.808085      -0.302010\n",
      "2018-10-24     -0.286544     -0.146996    -0.312549      -0.841126\n",
      "2018-10-25     -0.895889     -0.605733    -0.219367      -0.031289\n",
      "2018-10-26      0.039119     -0.398049    -0.716285      -0.180103\n",
      "2018-10-29     -0.266312      0.242140     0.535730       0.156629\n",
      "2018-10-30      0.211541      0.155909     0.376442       0.367116\n",
      "2018-10-31      0.382768      0.085646    -0.054810      -0.351467\n",
      "2018-11-01     -0.398422      0.171073    -0.039168       0.577315\n",
      "2018-11-02      0.562018      0.434143     0.593705       0.287412\n",
      "2018-11-05      0.341907      0.000000     0.178981       0.162759\n",
      "2018-11-06      0.155027      0.239521     0.194182       0.347880\n",
      "2018-11-07      0.332496      0.392807     0.379507       0.115692\n",
      "2018-11-08      0.069452     -0.015375     0.030917      -0.123409\n",
      "2018-11-09     -0.038579     -0.346567    -0.519119      -0.448639\n",
      "2018-11-12     -0.533912     -0.371001    -0.842504      -1.020775\n",
      "2018-11-13     -0.927556     -0.341297    -0.117578       0.616828\n",
      "2018-11-14      0.570025      0.364525     0.508509       0.015567\n",
      "2018-11-15      0.007786     -0.131696    -0.304795       0.147762\n",
      "2018-11-16      0.132270     -0.124108     0.296991       0.124262\n",
      "\n",
      "[3022 rows x 4 columns],             EUR_USD_Open  EUR_USD_High  EUR_USD_Low  EUR_USD_Close\n",
      "Date                                                              \n",
      "2007-04-03      0.074845     -0.022417    -0.090050      -0.269683\n",
      "2007-04-04     -0.254701      0.000000    -0.007508       0.269683\n",
      "2007-04-05      0.262182      0.447395     0.254949       0.470203\n",
      "2007-04-06      0.470203     -0.066982     0.082345      -0.395420\n",
      "2007-04-09     -0.402895     -0.395361    -0.179748      -0.164597\n",
      "2007-04-10     -0.157121      0.566447     0.074934       0.627008\n",
      "2007-04-11      0.627008     -0.096665     0.426057      -0.059546\n",
      "2007-04-12     -0.059546      0.452775     0.171405       0.386416\n",
      "2007-04-13      0.371582      0.376982     0.379028       0.347981\n",
      "2007-04-16      0.370206      0.169548     0.370206       0.036948\n",
      "2007-04-17      0.029557      0.125133    -0.044352       0.236145\n",
      "2007-04-18      0.236145      0.169049     0.236319       0.309097\n",
      "2007-04-19      0.309097      0.014686     0.029501       0.029388\n",
      "2007-04-20      0.029388      0.139414     0.184182      -0.169099\n",
      "2007-04-23     -0.154383     -0.227565    -0.324388      -0.095704\n",
      "2007-04-24     -0.110420      0.264220     0.051678       0.455615\n",
      "2007-04-25      0.455615      0.168443     0.544680      -0.007332\n",
      "2007-04-26     -0.007332     -0.087848    -0.279330      -0.271669\n",
      "2007-04-27     -0.271669      0.182929     0.007361       0.374271\n",
      "2007-04-30      0.374271      0.000000     0.029438      -0.029304\n",
      "2007-05-01     -0.036631     -0.051186     0.007358      -0.315562\n",
      "2007-05-02     -0.308235     -0.447166    -0.213604      -0.095599\n",
      "2007-05-03     -0.095599      0.080784    -0.110664      -0.309484\n",
      "2007-05-04     -0.309484     -0.088132    -0.081232       0.324197\n",
      "2007-05-07      0.324197      0.124830     0.412858       0.058832\n",
      "2007-05-08      0.051480     -0.044040    -0.560722      -0.434703\n",
      "2007-05-09     -0.427351     -0.411977     0.036986      -0.103428\n",
      "2007-05-10     -0.103428     -0.014745    -0.407604      -0.325757\n",
      "2007-05-11     -0.325757     -0.236215    -0.014853       0.303580\n",
      "2007-05-14      0.310973      0.199343     0.452037       0.155136\n",
      "...                  ...           ...          ...            ...\n",
      "2018-10-08      0.225969     -0.173340    -0.139519      -0.269437\n",
      "2018-10-09     -0.252075     -0.243182    -0.262123       0.008703\n",
      "2018-10-10     -0.026113      0.373216     0.410355       0.226008\n",
      "2018-10-11      0.304229      0.475348     0.373962       0.640473\n",
      "2018-10-12      0.579812      0.094799     0.112784      -0.293762\n",
      "2018-10-15     -0.276506     -0.043079     0.060677       0.172906\n",
      "2018-10-16      0.190180      0.129182     0.207756      -0.043198\n",
      "2018-10-17     -0.060473     -0.344858    -0.607166      -0.632831\n",
      "2018-10-18     -0.641528     -0.467452    -0.409747      -0.435769\n",
      "2018-10-19     -0.400872      0.069390    -0.148621       0.583498\n",
      "2018-10-22      0.522558      0.112657     0.235942      -0.470016\n",
      "2018-10-23     -0.426551     -0.503604    -0.157233       0.061053\n",
      "2018-10-24      0.061047     -0.113226    -0.517114      -0.682417\n",
      "2018-10-25     -0.664803     -0.410427    -0.211119      -0.175732\n",
      "2018-10-26     -0.202065     -0.105060    -0.185095       0.272252\n",
      "2018-10-29      0.254710     -0.035045     0.220313      -0.254665\n",
      "2018-10-30     -0.237123     -0.228090    -0.193850      -0.264131\n",
      "2018-10-31     -0.281765     -0.246219    -0.335719      -0.273670\n",
      "2018-11-01     -0.247197      0.535629     0.061928       0.836309\n",
      "2018-11-02      0.792397      0.279843     0.582012      -0.175485\n",
      "2018-11-05     -0.166762     -0.279843    -0.176010       0.166718\n",
      "2018-11-06      0.193067      0.122528     0.316595       0.166440\n",
      "2018-11-07      0.140179      0.540825     0.070219       0.008752\n",
      "2018-11-08      0.043766     -0.462136    -0.413242      -0.561701\n",
      "2018-11-09     -0.561651     -0.675234    -0.308846      -0.237917\n",
      "2018-11-12     -0.379139     -0.334920    -0.887711      -1.055395\n",
      "2018-11-13     -0.896230     -0.336046     0.000000       0.631029\n",
      "2018-11-14      0.604285      0.477201     0.427085       0.168194\n",
      "2018-11-15      0.185882      0.123348     0.062131       0.176741\n",
      "2018-11-16      0.150223      0.509399     0.433840       0.782731\n",
      "\n",
      "[3022 rows x 4 columns],             nikkei_Open  nikkei_High  nikkei_Low  nikkei_Close  \\\n",
      "Date                                                             \n",
      "1965-01-06     0.497284     0.497284    0.497284      0.497284   \n",
      "1965-01-07     0.810010     0.810010    0.810010      0.810010   \n",
      "1965-01-08     0.949750     0.949750    0.949750      0.949750   \n",
      "1965-01-12     0.163884     0.163884    0.163884      0.163884   \n",
      "1965-01-13    -0.534588    -0.534588   -0.534588     -0.534588   \n",
      "1965-01-14     0.609060     0.609060    0.609060      0.609060   \n",
      "1965-01-18    -1.391564    -1.391564   -1.391564     -1.391564   \n",
      "1965-01-19    -0.105435    -0.105435   -0.105435     -0.105435   \n",
      "1965-01-20    -0.114993    -0.114993   -0.114993     -0.114993   \n",
      "1965-01-21     0.124438     0.124438    0.124438      0.124438   \n",
      "1965-01-22    -0.681600    -0.681600   -0.681600     -0.681600   \n",
      "1965-01-25    -0.964351    -0.964351   -0.964351     -0.964351   \n",
      "1965-01-26    -0.133713    -0.133713   -0.133713     -0.133713   \n",
      "1965-01-27     0.810767     0.810767    0.810767      0.810767   \n",
      "1965-01-28    -0.878905    -0.878905   -0.878905     -0.878905   \n",
      "1965-01-29    -0.396063    -0.396063   -0.396063     -0.396063   \n",
      "1965-02-01     0.045063     0.045063    0.045063      0.045063   \n",
      "1965-02-02    -0.328820    -0.328820   -0.328820     -0.328820   \n",
      "1965-02-03     0.746352     0.746352    0.746352      0.746352   \n",
      "1965-02-04     1.081441     1.081441    1.081441      1.081441   \n",
      "1965-02-05     0.157611     0.157611    0.157611      0.157611   \n",
      "1965-02-08    -0.369465    -0.369465   -0.369465     -0.369465   \n",
      "1965-02-09    -0.577550    -0.577550   -0.577550     -0.577550   \n",
      "1965-02-10    -0.245577    -0.245577   -0.245577     -0.245577   \n",
      "1965-02-12     0.744449     0.744449    0.744449      0.744449   \n",
      "1965-02-15    -0.673194    -0.673194   -0.673194     -0.673194   \n",
      "1965-02-16    -0.199478    -0.199478   -0.199478     -0.199478   \n",
      "1965-02-17    -0.799497    -0.799497   -0.799497     -0.799497   \n",
      "1965-02-18     0.349413     0.349413    0.349413      0.349413   \n",
      "1965-02-19    -0.327588    -0.327588   -0.327588     -0.327588   \n",
      "...                 ...          ...         ...           ...   \n",
      "2018-09-28     0.556279     0.813555    1.017724      1.349439   \n",
      "2018-10-01     0.386955     0.084126    0.424680      0.519876   \n",
      "2018-10-02     0.835443     0.580588    0.387912      0.102478   \n",
      "2018-10-03    -0.646074    -0.769638   -0.773800     -0.659998   \n",
      "2018-10-04     0.094389    -0.052818   -0.447640     -0.562910   \n",
      "2018-10-05    -1.917027    -1.325153   -0.810314     -0.803610   \n",
      "2018-10-09    -0.977308    -1.437733   -1.219911     -1.330430   \n",
      "2018-10-10    -0.049059     0.009878   -0.294437      0.156032   \n",
      "2018-10-11    -2.127716    -2.307928   -3.991228     -3.971200   \n",
      "2018-10-12    -3.174127    -1.486222   -0.605551      0.458429   \n",
      "2018-10-15     0.793764    -0.842516   -0.275919     -1.883077   \n",
      "2018-10-16    -0.906850     0.127138    0.034175      1.240248   \n",
      "2018-10-17     2.254360     1.802651    2.203040      1.286101   \n",
      "2018-10-18     0.283242    -0.376498   -0.565124     -0.804232   \n",
      "2018-10-19    -2.341363    -1.415378   -1.894015     -0.557998   \n",
      "2018-10-22     0.144068     0.533259    0.265351      0.366538   \n",
      "2018-10-23     0.133679    -1.162771   -1.258445     -2.707316   \n",
      "2018-10-24    -1.060682    -0.910240   -0.371946      0.364612   \n",
      "2018-10-25    -2.239502    -2.295138   -3.279923     -3.794048   \n",
      "2018-10-26    -1.094644    -1.049345   -1.102386     -0.396346   \n",
      "2018-10-29    -0.548263    -0.049694    0.656061     -0.164400   \n",
      "2018-10-30    -1.293715     0.475947   -0.351588      1.443392   \n",
      "2018-10-31     2.440535     1.619119    2.323586      2.135609   \n",
      "2018-11-01     1.549621    -0.064119    0.454409     -1.067750   \n",
      "2018-11-02    -0.663326     1.818489    0.566537      2.531404   \n",
      "2018-11-05     1.100872    -1.157674    0.525712     -1.561650   \n",
      "2018-11-06     0.074502     0.493887    0.585036      1.129538   \n",
      "2018-11-07     0.773026     1.272598    0.012094     -0.280101   \n",
      "2018-11-08     1.148283     0.616414    1.909469      1.799890   \n",
      "2018-11-09     0.112655    -0.394204   -0.873481     -1.058056   \n",
      "\n",
      "            nikkei_Adj Close  \n",
      "Date                          \n",
      "1965-01-06          0.497284  \n",
      "1965-01-07          0.810010  \n",
      "1965-01-08          0.949750  \n",
      "1965-01-12          0.163884  \n",
      "1965-01-13         -0.534588  \n",
      "1965-01-14          0.609060  \n",
      "1965-01-18         -1.391564  \n",
      "1965-01-19         -0.105435  \n",
      "1965-01-20         -0.114993  \n",
      "1965-01-21          0.124438  \n",
      "1965-01-22         -0.681600  \n",
      "1965-01-25         -0.964351  \n",
      "1965-01-26         -0.133713  \n",
      "1965-01-27          0.810767  \n",
      "1965-01-28         -0.878905  \n",
      "1965-01-29         -0.396063  \n",
      "1965-02-01          0.045063  \n",
      "1965-02-02         -0.328820  \n",
      "1965-02-03          0.746352  \n",
      "1965-02-04          1.081441  \n",
      "1965-02-05          0.157611  \n",
      "1965-02-08         -0.369465  \n",
      "1965-02-09         -0.577550  \n",
      "1965-02-10         -0.245577  \n",
      "1965-02-12          0.744449  \n",
      "1965-02-15         -0.673194  \n",
      "1965-02-16         -0.199478  \n",
      "1965-02-17         -0.799497  \n",
      "1965-02-18          0.349413  \n",
      "1965-02-19         -0.327588  \n",
      "...                      ...  \n",
      "2018-09-28          1.349439  \n",
      "2018-10-01          0.519876  \n",
      "2018-10-02          0.102478  \n",
      "2018-10-03         -0.659998  \n",
      "2018-10-04         -0.562910  \n",
      "2018-10-05         -0.803610  \n",
      "2018-10-09         -1.330430  \n",
      "2018-10-10          0.156032  \n",
      "2018-10-11         -3.971200  \n",
      "2018-10-12          0.458429  \n",
      "2018-10-15         -1.883077  \n",
      "2018-10-16          1.240248  \n",
      "2018-10-17          1.286101  \n",
      "2018-10-18         -0.804232  \n",
      "2018-10-19         -0.557998  \n",
      "2018-10-22          0.366538  \n",
      "2018-10-23         -2.707316  \n",
      "2018-10-24          0.364612  \n",
      "2018-10-25         -3.794048  \n",
      "2018-10-26         -0.396346  \n",
      "2018-10-29         -0.164400  \n",
      "2018-10-30          1.443392  \n",
      "2018-10-31          2.135609  \n",
      "2018-11-01         -1.067750  \n",
      "2018-11-02          2.531404  \n",
      "2018-11-05         -1.561650  \n",
      "2018-11-06          1.129538  \n",
      "2018-11-07         -0.280101  \n",
      "2018-11-08          1.799890  \n",
      "2018-11-09         -1.058056  \n",
      "\n",
      "[13258 rows x 5 columns],             DOW_Open  DOW_High   DOW_Low  DOW_Close  DOW_Adj Close  DOW_Volume\n",
      "Date                                                                          \n",
      "1985-01-30  1.526192  0.739065  0.945874  -0.367370      -0.367370   21.544437\n",
      "1985-01-31 -1.095101 -0.900522 -0.493034  -0.086224      -0.086224  -17.852378\n",
      "1985-02-01 -0.492158 -0.565228 -0.225770  -0.705800      -0.705800  -24.796944\n",
      "1985-02-04 -0.381322  0.684217 -0.061450   0.962698       0.962698    5.751253\n",
      "1985-02-05  1.713129  0.476881  0.754441  -0.376652      -0.376652   17.108063\n",
      "1985-02-06 -0.711149 -0.510860 -0.276467  -0.361679      -0.361679    5.703763\n",
      "1985-02-07  0.008560  0.196026  0.371064   0.738332       0.738332  -24.459024\n",
      "1985-02-08  0.394548  0.008479  0.121033  -0.008526      -0.008526  -35.767444\n",
      "1985-02-11 -0.162134 -0.417943 -0.996075  -1.084169      -1.084169   45.425527\n",
      "1985-02-12 -1.312156 -0.668773 -0.183043   0.043086       0.043086   -5.968261\n",
      "1985-02-13  0.520199  1.664009  0.643098   1.655490       1.655490   16.860819\n",
      "1985-02-14  1.857698  0.219739  0.716920  -0.776556      -0.776556   -0.213751\n",
      "1985-02-15 -0.971844 -0.864896 -0.672996  -0.456048      -0.456048  -47.371951\n",
      "1985-02-19 -0.731016 -0.684290 -0.121630  -0.111609      -0.111609  -26.615150\n",
      "1985-02-20  0.026560  0.393805 -0.077767   0.198153       0.198153   47.522168\n",
      "1985-02-21  0.017182 -0.419447  0.008643  -0.319258      -0.319258  -22.407335\n",
      "1985-02-22 -0.189973 -0.042735 -0.208448  -0.250507      -0.250507   -1.169604\n",
      "1985-02-25 -0.624034 -0.266185 -0.479890   0.130028       0.130028   -0.945634\n",
      "1985-02-26  0.494060  0.780193  0.662407   0.671710       0.671710   34.676856\n",
      "1985-02-27  0.733040  0.161484  0.164131  -0.395768      -0.395768   -0.083998\n",
      "1985-02-28 -0.594450 -0.538018 -0.234108   0.232354       0.232354  -30.292369\n",
      "1985-03-01  0.568773  1.665757  0.882497   1.188382       1.188382   51.627152\n",
      "1985-03-04  1.127181 -0.413838  0.034302  -0.759399      -0.759399  -20.414659\n",
      "1985-03-05 -0.759086 -0.347853 -0.163794   0.179745       0.179745  -17.717247\n",
      "1985-03-06  0.137108 -0.237969 -0.431836  -0.892619      -0.892619    8.841860\n",
      "1985-03-07 -1.169487 -1.061185 -0.791044  -0.692817      -0.692817  -10.748591\n",
      "1985-03-08 -0.268204 -0.189539 -0.105152  -0.147175      -0.147175   -7.903005\n",
      "1985-03-11 -0.365043 -0.293997 -0.253456  -0.087462      -0.087462  -16.795162\n",
      "1985-03-12 -0.095410  0.190096  0.122844   0.251935       0.251935    7.854503\n",
      "1985-03-13  0.269440 -0.094611 -0.385698  -0.793393      -0.793393    5.822366\n",
      "...              ...       ...       ...        ...            ...         ...\n",
      "2018-10-11 -3.554407 -3.083262 -2.644781  -2.155634      -2.155634   17.667657\n",
      "2018-10-12 -0.434984 -0.844911  0.405048   1.139699       1.139699  -27.413190\n",
      "2018-10-15 -0.296294  0.058368  0.967476  -0.353582      -0.353582  -32.462351\n",
      "2018-10-16  0.075244  1.307072  0.425527   2.146528       2.146528    6.233472\n",
      "2018-10-17  1.388028 -0.029402  0.502181  -0.356238      -0.356238   -2.513336\n",
      "2018-10-18 -0.234886 -0.460682 -0.958894  -1.281111      -1.281111    9.527665\n",
      "2018-10-19 -0.879134 -0.322611  0.450757   0.255355       0.255355    6.717018\n",
      "2018-10-22  0.279106 -0.185152 -0.450594  -0.500101      -0.500101  -10.786262\n",
      "2018-10-23 -1.795711 -0.997238 -1.868920  -0.498846      -0.498846   32.624585\n",
      "2018-10-24  0.535418 -0.005804 -0.955748  -2.443162      -2.443162   12.875406\n",
      "2018-10-25 -1.748579 -0.801192  0.456991   1.618544       1.618544  -12.135761\n",
      "2018-10-26  0.136187 -0.752212 -0.816334  -1.192779      -1.192779   13.914766\n",
      "2018-10-29  0.196537  0.498112 -1.329960  -0.998927      -0.998927  -12.968543\n",
      "2018-10-30 -1.366895 -0.536168  1.209209   1.750824       1.750824    5.735240\n",
      "2018-10-31  2.128883  1.711202  2.400264   0.964669       0.964669   -4.597210\n",
      "2018-11-01  0.531436  0.236217  0.396230   1.049510       1.049510  -15.630255\n",
      "2018-11-02  1.192128  0.716072 -0.117117  -0.433986      -0.433986   11.201075\n",
      "2018-11-05 -0.718388 -0.280431  0.726063   0.752456       0.752456  -24.922106\n",
      "2018-11-06  0.754660  0.564943  0.723501   0.678365       0.678365  -23.192761\n",
      "2018-11-07  1.310020  2.114872  1.253582   2.104826       2.104826   30.960979\n",
      "2018-11-08  1.352388  0.296047  1.219043   0.041702       0.041702  -20.185997\n",
      "2018-11-09  0.036411 -0.443676 -0.765869  -0.773932      -0.773932    9.295512\n",
      "2018-11-12 -0.728405 -0.747312 -2.117862  -2.344063      -2.344063    6.693394\n",
      "2018-11-13 -2.488866 -1.770449 -0.580718  -0.397404      -0.397404   -2.103194\n",
      "2018-11-14  0.263735 -0.038188 -1.029177  -0.817962      -0.817962   12.323392\n",
      "2018-11-15 -1.294775 -0.577039 -0.595418   0.828952       0.828952    2.190592\n",
      "2018-11-16  0.719110  0.612095  1.441929   0.488936       0.488936  -10.257777\n",
      "2018-11-19  0.593504 -0.462140 -0.986327  -1.569638      -1.569638    1.018885\n",
      "2018-11-20 -3.095267 -2.736104 -2.159615  -2.230345      -2.230345   21.935521\n",
      "2018-11-21 -0.313380 -0.151774  0.386216  -0.003888      -0.003888  -43.243342\n",
      "\n",
      "[8525 rows x 6 columns],             treasury_10_Close  treasury_10_Open  treasury_10_High  \\\n",
      "Date                                                                \n",
      "2008-11-13           5.326072          5.326072          5.326072   \n",
      "2008-11-14          -3.295408         -3.295408         -3.295408   \n",
      "2008-11-17          -1.975974         -1.975974         -1.975974   \n",
      "2008-11-18          -3.590201         -3.590201         -3.590201   \n",
      "2008-11-19          -5.594234         -5.594234         -5.594234   \n",
      "2008-11-20         -10.379679        -10.379679        -10.379679   \n",
      "2008-11-21           6.903720          6.903720          6.903720   \n",
      "2008-11-24           3.235936          3.235936          3.235936   \n",
      "2008-11-25          -6.772774         -6.772774         -6.772774   \n",
      "2008-11-26          -4.000533         -4.000533         -4.000533   \n",
      "2008-11-27           0.533868          0.533868          0.533868   \n",
      "2008-11-28          -2.869395         -2.869395         -2.869395   \n",
      "2008-12-01          -6.764837         -6.764837         -6.764837   \n",
      "2008-12-02          -1.327943         -1.327943         -1.327943   \n",
      "2008-12-03          -1.345815         -1.345815         -1.345815   \n",
      "2008-12-04          -3.992853         -3.992853         -3.992853   \n",
      "2008-12-05           5.598263          5.598263          5.598263   \n",
      "2008-12-08           1.580044          1.580044          1.580044   \n",
      "2008-12-09          -3.373814         -3.373814         -3.373814   \n",
      "2008-12-10           1.385530          1.385530          1.385530   \n",
      "2008-12-11          -3.020237         -3.020237         -3.020237   \n",
      "2008-12-12          -1.272920         -1.272920         -1.272920   \n",
      "2008-12-15          -2.237581         -2.237581         -2.237581   \n",
      "2008-12-16         -10.672884        -10.672884        -10.672884   \n",
      "2008-12-17          -2.867580         -2.867580         -2.867580   \n",
      "2008-12-18          -5.368851         -5.368851         -5.368851   \n",
      "2008-12-19           2.182250          2.182250          2.182250   \n",
      "2008-12-22           1.951735          1.951735          1.951735   \n",
      "2008-12-23           0.459138          0.459138          0.459138   \n",
      "2008-12-24           0.228781          0.228781          0.228781   \n",
      "...                       ...               ...               ...   \n",
      "2018-11-07           0.185529          0.155739          0.586331   \n",
      "2018-11-08           0.061767          0.713292         -0.215617   \n",
      "2018-11-09          -1.649843         -0.123686         -0.216083   \n",
      "2018-11-12          -1.104635         -1.433493         -1.557179   \n",
      "2018-11-13          -0.286032         -1.104635         -0.314367   \n",
      "2018-11-14          -0.478546         -0.190597         -0.346949   \n",
      "2018-11-15          -0.545135         -0.701981         -0.920495   \n",
      "2018-11-16          -1.457516         -0.417135         -0.415402   \n",
      "2018-11-18          -0.261353         -1.718868         -2.136004   \n",
      "2018-11-19           0.196078          0.000000          1.267691   \n",
      "2018-11-20          -0.065317          0.196078         -0.843339   \n",
      "2018-11-21           0.130591          0.065274          0.584607   \n",
      "2018-11-22           0.000000          0.000000         -0.747606   \n",
      "2018-11-23          -0.621831          0.097831          0.358248   \n",
      "2018-11-25           0.065638         -0.654025         -0.914441   \n",
      "2018-11-26           0.360243          0.065595          1.011923   \n",
      "2018-11-27           0.000000          0.294647         -0.162522   \n",
      "2018-11-28           0.065359         -0.065402          0.032526   \n",
      "2018-11-29          -0.951919         -0.294841         -0.750779   \n",
      "2018-11-30          -1.294624         -0.724402         -0.657465   \n",
      "2018-12-02           1.525229          0.362857          0.230605   \n",
      "2018-12-03          -2.431427          0.000000          0.361308   \n",
      "2018-12-04          -1.734442         -2.062615         -2.422551   \n",
      "2018-12-05           0.068587         -2.140391         -2.036039   \n",
      "2018-12-06          -0.860739          0.171556          0.239685   \n",
      "2018-12-07          -1.182622         -0.550019         -0.102652   \n",
      "2018-12-09          -1.019879         -2.654714         -3.200273   \n",
      "2018-12-10           1.194673          0.141493          1.369163   \n",
      "2018-12-11           0.696139          0.739570          0.694930   \n",
      "2018-12-12           0.242508          1.012402          0.242089   \n",
      "\n",
      "            treasury_10_Low  \n",
      "Date                         \n",
      "2008-11-13         5.326072  \n",
      "2008-11-14        -3.295408  \n",
      "2008-11-17        -1.975974  \n",
      "2008-11-18        -3.590201  \n",
      "2008-11-19        -5.594234  \n",
      "2008-11-20       -10.379679  \n",
      "2008-11-21         6.903720  \n",
      "2008-11-24         3.235936  \n",
      "2008-11-25        -6.772774  \n",
      "2008-11-26        -4.000533  \n",
      "2008-11-27         0.533868  \n",
      "2008-11-28        -2.869395  \n",
      "2008-12-01        -6.764837  \n",
      "2008-12-02        -1.327943  \n",
      "2008-12-03        -1.345815  \n",
      "2008-12-04        -3.992853  \n",
      "2008-12-05         5.598263  \n",
      "2008-12-08         1.580044  \n",
      "2008-12-09        -3.373814  \n",
      "2008-12-10         1.385530  \n",
      "2008-12-11        -3.020237  \n",
      "2008-12-12        -1.272920  \n",
      "2008-12-15        -2.237581  \n",
      "2008-12-16       -10.672884  \n",
      "2008-12-17        -2.867580  \n",
      "2008-12-18        -5.368851  \n",
      "2008-12-19         2.182250  \n",
      "2008-12-22         1.951735  \n",
      "2008-12-23         0.459138  \n",
      "2008-12-24         0.228781  \n",
      "...                     ...  \n",
      "2018-11-07        -0.408484  \n",
      "2018-11-08         0.940151  \n",
      "2018-11-09        -0.814286  \n",
      "2018-11-12        -0.916133  \n",
      "2018-11-13        -0.413421  \n",
      "2018-11-14        -1.476752  \n",
      "2018-11-15        -0.356391  \n",
      "2018-11-16        -0.520665  \n",
      "2018-11-18        -0.261353  \n",
      "2018-11-19        -0.163693  \n",
      "2018-11-20        -0.525625  \n",
      "2018-11-21         0.820080  \n",
      "2018-11-22         0.130591  \n",
      "2018-11-23        -1.082510  \n",
      "2018-11-25         0.526317  \n",
      "2018-11-26        -0.065638  \n",
      "2018-11-27        -0.065681  \n",
      "2018-11-28        -0.032857  \n",
      "2018-11-29        -1.523208  \n",
      "2018-11-30        -0.300752  \n",
      "2018-12-02         1.626592  \n",
      "2018-12-03        -2.365594  \n",
      "2018-12-04        -2.768934  \n",
      "2018-12-05         0.931523  \n",
      "2018-12-06        -2.997785  \n",
      "2018-12-07         0.740352  \n",
      "2018-12-09        -0.775744  \n",
      "2018-12-10         0.000000  \n",
      "2018-12-11         0.705470  \n",
      "2018-12-12         1.187994  \n",
      "\n",
      "[2880 rows x 4 columns]]\n"
     ]
    }
   ],
   "source": [
    "df_x_name = 'USD_JPY'\n",
    "\n",
    "df_list_name = [\n",
    "    'NASDAQ',\n",
    "    'EUR_JPY',\n",
    "    'EUR_USD',\n",
    "    'nikkei',\n",
    "    'DOW30',\n",
    "    'treasury_10',\n",
    "]\n",
    "\n",
    "df_list = [] #データフレームのリスト\n",
    "\n",
    "df_list.append(add_data(csv_path+'NASDAQ.csv', x_days_later))\n",
    "df_list.append(add_data(csv_path+'EUR_JPY.csv', x_days_later))\n",
    "df_list.append(add_data(csv_path+'EUR_USD.csv', x_days_later))\n",
    "df_list.append(add_data(csv_path+'nikkei.csv', x_days_later))\n",
    "df_list.append(add_data(csv_path+'DOW30.csv', x_days_later))\n",
    "            \n",
    "#f_list.append(add_data(csv_path+'TNX.csv'))#1米国債10年？\n",
    "#_list.append(add_data(csv_path+'GSPC.csv'))#S&P500\n",
    "#df_list.append(add_data(csv_path+'RUT.csv'))#Russell2000\n",
    "#df_list.append(add_data(csv_path+'TOPIX.csv'))\n",
    "#df_list.append(add_data(csv_path+'BTC_USD.csv'))\n",
    "                        \n",
    "# 米国債\n",
    "df = pd.read_csv(csv_path+'treasury_10.csv', index_col='Date', parse_dates=True)\n",
    "df_list.append(rise_fall_rate(df, x_days_later))\n",
    "\n",
    "print(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メイン処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            USD_JPY_Open  USD_JPY_High  USD_JPY_Low  USD_JPY_Close  \\\n",
      "Date                                                                 \n",
      "2009-03-10      0.578359     -0.040339     0.010213      -0.182279   \n",
      "2009-03-11     -0.172143     -0.303061    -0.882147      -1.408618   \n",
      "2009-03-12     -1.418753     -0.324281    -1.442457       0.451283   \n",
      "2009-03-13      0.451283      0.131866     1.524847       0.326931   \n",
      "2009-03-16      0.377918      0.000000     0.861014       0.142697   \n",
      "2009-03-17      0.091710      0.323854     0.112205       0.416731   \n",
      "2009-03-18      0.416731     -0.131439    -2.477162      -2.433260   \n",
      "2009-03-19     -2.402086     -2.282013    -2.261775      -1.761421   \n",
      "2009-03-20     -1.834914     -0.352551     0.649941       1.438723   \n",
      "2009-03-23      1.251397      1.105326     1.580478       1.068198   \n",
      "2009-03-24      1.308158      1.235403     1.318883       0.954784   \n",
      "2009-03-25      0.975117     -0.203149     0.010316      -0.348004   \n",
      "2009-03-26     -0.378653      0.527331     0.514457       1.212754   \n",
      "2009-03-27      1.202624      0.000000    -0.339245      -0.813674   \n",
      "2009-03-30     -0.528188     -0.557839    -1.180871      -0.686584   \n",
      "2009-03-31     -0.961939      1.042150     1.304366       1.753179   \n",
      "2009-04-01      1.732969      0.110658     0.992691      -0.435422   \n",
      "2009-04-02     -0.415211      0.431403     0.203459       0.969509   \n",
      "2009-04-03      0.969509      0.449484     0.940684       0.740967   \n",
      "2009-04-06      0.960199      1.080449     1.011678       0.705803   \n",
      "2009-04-07      0.466757     -0.335770    -0.489536      -0.556274   \n",
      "2009-04-08     -0.536461     -0.247611    -0.562420      -0.649580   \n",
      "2009-04-09     -0.659607     -0.297944     0.341846       0.649580   \n",
      "2009-04-13      0.009961     -0.019861    -0.359892      -0.199581   \n",
      "2009-04-14     -0.279274     -0.278469    -1.117893      -1.145281   \n",
      "2009-04-15     -1.155269     -0.759776    -0.619700       0.363087   \n",
      "2009-04-16      0.363087     -0.130542     0.386494      -0.070497   \n",
      "2009-04-17     -0.070497      0.210791     0.192688      -0.050385   \n",
      "2009-04-20     -0.050385     -0.361628    -1.079770      -1.298588   \n",
      "2009-04-21     -1.329227     -0.494326     0.081900       0.773069   \n",
      "...                  ...           ...          ...            ...   \n",
      "2018-09-20     -0.062330      0.115581    -0.107047       0.177968   \n",
      "2018-09-21      0.160199      0.257355     0.320799       0.071098   \n",
      "2018-09-24      0.088889     -0.035458     0.026687       0.204127   \n",
      "2018-09-25      0.186410      0.150609     0.266477       0.150609   \n",
      "2018-09-26      0.159504      0.115019    -0.097626      -0.212691   \n",
      "2018-09-27     -0.257104      0.317825    -0.044407       0.592634   \n",
      "2018-09-28      0.637114      0.211323     0.593421       0.264224   \n",
      "2018-10-01      0.281864      0.289843     0.396599       0.237206   \n",
      "2018-10-02      0.228431     -0.008771    -0.140833      -0.254800   \n",
      "2018-10-03     -0.263621      0.437599    -0.026428       0.736264   \n",
      "2018-10-04      0.701450      0.000000     0.105671      -0.525349   \n",
      "2018-10-05     -0.516842     -0.393753    -0.044016      -0.184526   \n",
      "2018-10-08     -0.149418     -0.131596    -0.662576      -0.423057   \n",
      "2018-10-09     -0.440762     -0.484007     0.044309      -0.247612   \n",
      "2018-10-10     -0.194553     -0.105914    -0.524096      -0.586095   \n",
      "2018-10-11     -0.630469     -0.664513    -0.410532      -0.124766   \n",
      "2018-10-12     -0.142628     -0.008890     0.044705       0.035663   \n",
      "2018-10-15      0.062425     -0.258157    -0.223724      -0.375101   \n",
      "2018-10-16     -0.366186      0.089095     0.107450       0.419662   \n",
      "2018-10-17      0.437481      0.311208     0.223484       0.346898   \n",
      "2018-10-18      0.337958      0.044379    -0.071460      -0.400374   \n",
      "2018-10-19     -0.418169     -0.079897     0.169635       0.320428   \n",
      "2018-10-22      0.320456      0.212917     0.204964       0.204181   \n",
      "2018-10-23      0.204199     -0.035455    -0.338862      -0.328670   \n",
      "2018-10-24     -0.319801     -0.088692     0.133899      -0.169197   \n",
      "2018-10-25     -0.187024     -0.062131    -0.250089       0.151400   \n",
      "2018-10-26      0.187024     -0.204417    -0.394266      -0.437013   \n",
      "2018-10-29     -0.463748      0.097817     0.358488       0.401410   \n",
      "2018-10-30      0.410348      0.461116     0.455216       0.621230   \n",
      "2018-10-31      0.621230      0.282711     0.444287      -0.035395   \n",
      "\n",
      "            USD_JPY_diff  NASDAQ_Open  NASDAQ_High  NASDAQ_Low  NASDAQ_Close  \\\n",
      "Date                                                                           \n",
      "2009-03-10     -0.182279     0.319372     3.150839    1.834477      6.827374   \n",
      "2009-03-11     -1.418753     5.718004     1.969032    4.820075      0.978790   \n",
      "2009-03-12      0.451283     0.218108     3.005019    0.180974      3.893631   \n",
      "2009-03-13      0.326931     4.240637     0.449406    3.851652      0.377942   \n",
      "2009-03-16      0.091710     1.270079     0.784239   -0.411282     -1.938328   \n",
      "2009-03-17      0.416731    -2.494050     1.158442    0.202291      4.054102   \n",
      "2009-03-18     -2.433260     3.126524     3.050574    3.038093      1.971397   \n",
      "2009-03-19     -1.792595     3.686607     0.110065    1.834421     -0.520389   \n",
      "2009-03-20      1.481042    -1.395323    -0.483589   -1.826829     -1.782583   \n",
      "2009-03-23      1.297843     0.208765     3.531952    2.277191      6.540578   \n",
      "2009-03-24      0.944469     2.935191    -0.616386    2.233744     -2.555236   \n",
      "2009-03-25     -0.378653    -0.528201     0.518636   -1.843862      0.816294   \n",
      "2009-03-26      1.212754     1.417647     2.085233    3.776722      3.726425   \n",
      "2009-03-27     -0.803544     0.945559    -1.127316   -0.115255     -2.669212   \n",
      "2009-03-30     -0.961939    -3.072708    -3.379799   -3.860596     -2.848890   \n",
      "2009-03-31      1.753179     0.125839     2.436034    2.199898      1.768130   \n",
      "2009-04-01     -0.415211    -0.914816    -0.092675   -1.290895      1.494092   \n",
      "2009-04-02      0.969509     4.869933     4.427785    5.091880      3.235939   \n",
      "2009-04-03      0.740967     1.823813    -0.090593    1.024032      1.193377   \n",
      "2009-04-06      0.486571    -0.424133    -0.883743   -0.781428     -0.939122   \n",
      "2009-04-07     -0.536461    -1.045240    -1.226701   -1.349659     -2.847125   \n",
      "2009-04-08     -0.649580    -0.547029     0.500632    0.496375      1.843172   \n",
      "2009-04-09      0.659607     2.622369     3.483184    3.080532      3.816448   \n",
      "2009-04-13     -0.289263     1.397382     0.500393    0.880262      0.046585   \n",
      "2009-04-14     -1.155269    -0.250677    -0.576669   -0.769571     -1.682860   \n",
      "2009-04-15      0.363087    -1.472773    -1.437052   -1.176835      0.066415   \n",
      "2009-04-16     -0.070497     1.961350     2.933121    1.795416      2.647210   \n",
      "2009-04-17     -0.050385     1.212895     0.361478    1.569846      0.157320   \n",
      "2009-04-20     -1.298588    -1.466635    -2.340768   -2.881788     -3.953849   \n",
      "2009-04-21      0.803707    -2.612185     0.032248   -0.494727      2.191930   \n",
      "...                  ...          ...          ...         ...           ...   \n",
      "2018-09-20      0.186874     0.388316     0.786008    0.863682      0.978711   \n",
      "2018-09-21      0.097773     0.600682     0.226135   -0.084432     -0.515387   \n",
      "2018-09-24      0.213012    -1.280408    -0.739452   -0.845702      0.078723   \n",
      "2018-09-25      0.177211     0.780508     0.202601    0.840942      0.177745   \n",
      "2018-09-26     -0.194984     0.126025     0.658036    0.043475     -0.213780   \n",
      "2018-09-27      0.654754     0.119006     0.056142    0.439362      0.643702   \n",
      "2018-09-28      0.281864     0.040880    -0.080562   -0.025447      0.054448   \n",
      "2018-10-01      0.237206     0.831477     0.523359    0.048640     -0.112540   \n",
      "2018-10-02     -0.246024    -0.831848    -0.658727   -0.447143     -0.470792   \n",
      "2018-10-03      0.753861     0.126778    -0.002728    0.350582      0.318760   \n",
      "2018-10-04     -0.472938    -0.515597    -0.707247   -2.257811     -1.830717   \n",
      "2018-10-05     -0.140622    -1.494478    -1.188705   -1.507379     -1.162380   \n",
      "2018-10-08     -0.414262    -1.634409    -1.342060   -0.795413     -0.676357   \n",
      "2018-10-09     -0.221112    -0.240253     0.031162    0.834026      0.026752   \n",
      "2018-10-10     -0.612655    -0.446485    -1.271550   -3.942384     -4.169057   \n",
      "2018-10-11     -0.106952    -4.058470    -2.737891   -1.994268     -1.260800   \n",
      "2018-10-12      0.071339     1.608127     0.312860    1.287925      2.264101   \n",
      "2018-10-15     -0.366186    -0.460709    -0.209884    0.429834     -0.886280   \n",
      "2018-10-16      0.419662     0.379960     2.074212    1.253853      2.849048   \n",
      "2018-10-17      0.329079     2.207980     0.161138    0.925185     -0.036499   \n",
      "2018-10-18     -0.409253    -0.690706    -0.701634   -1.473564     -2.083123   \n",
      "2018-10-19      0.329343    -1.139673    -0.446978   -0.324717     -0.483595   \n",
      "2018-10-22      0.213068    -0.578282    -0.825646   -0.047931      0.262777   \n",
      "2018-10-23     -0.319801    -2.135583    -0.639762   -2.241998     -0.417141   \n",
      "2018-10-24     -0.169197     1.283392    -0.494896   -2.244379     -4.526298   \n",
      "2018-10-25      0.169227    -3.087919    -0.957679    1.114210      2.910634   \n",
      "2018-10-26     -0.454810    -1.009737    -1.112781   -1.707599     -2.086705   \n",
      "2018-10-29      0.410348     2.045409     0.168600   -1.919538     -1.644770   \n",
      "2018-10-30      0.621230    -3.562933    -1.780797    1.129690      1.567163   \n",
      "2018-10-31     -0.035395     3.620671     2.774802    3.772138      1.994184   \n",
      "\n",
      "            NASDAQ_Adj Close  \n",
      "Date                          \n",
      "2009-03-10          6.827374  \n",
      "2009-03-11          0.978790  \n",
      "2009-03-12          3.893631  \n",
      "2009-03-13          0.377942  \n",
      "2009-03-16         -1.938328  \n",
      "2009-03-17          4.054102  \n",
      "2009-03-18          1.971397  \n",
      "2009-03-19         -0.520389  \n",
      "2009-03-20         -1.782583  \n",
      "2009-03-23          6.540578  \n",
      "2009-03-24         -2.555236  \n",
      "2009-03-25          0.816294  \n",
      "2009-03-26          3.726425  \n",
      "2009-03-27         -2.669212  \n",
      "2009-03-30         -2.848890  \n",
      "2009-03-31          1.768130  \n",
      "2009-04-01          1.494092  \n",
      "2009-04-02          3.235939  \n",
      "2009-04-03          1.193377  \n",
      "2009-04-06         -0.939122  \n",
      "2009-04-07         -2.847125  \n",
      "2009-04-08          1.843172  \n",
      "2009-04-09          3.816448  \n",
      "2009-04-13          0.046585  \n",
      "2009-04-14         -1.682860  \n",
      "2009-04-15          0.066415  \n",
      "2009-04-16          2.647210  \n",
      "2009-04-17          0.157320  \n",
      "2009-04-20         -3.953849  \n",
      "2009-04-21          2.191930  \n",
      "...                      ...  \n",
      "2018-09-20          0.978711  \n",
      "2018-09-21         -0.515387  \n",
      "2018-09-24          0.078723  \n",
      "2018-09-25          0.177745  \n",
      "2018-09-26         -0.213780  \n",
      "2018-09-27          0.643702  \n",
      "2018-09-28          0.054448  \n",
      "2018-10-01         -0.112540  \n",
      "2018-10-02         -0.470792  \n",
      "2018-10-03          0.318760  \n",
      "2018-10-04         -1.830717  \n",
      "2018-10-05         -1.162380  \n",
      "2018-10-08         -0.676357  \n",
      "2018-10-09          0.026752  \n",
      "2018-10-10         -4.169057  \n",
      "2018-10-11         -1.260800  \n",
      "2018-10-12          2.264101  \n",
      "2018-10-15         -0.886280  \n",
      "2018-10-16          2.849048  \n",
      "2018-10-17         -0.036499  \n",
      "2018-10-18         -2.083123  \n",
      "2018-10-19         -0.483595  \n",
      "2018-10-22          0.262777  \n",
      "2018-10-23         -0.417141  \n",
      "2018-10-24         -4.526298  \n",
      "2018-10-25          2.910634  \n",
      "2018-10-26         -2.086705  \n",
      "2018-10-29         -1.644770  \n",
      "2018-10-30          1.567163  \n",
      "2018-10-31          1.994184  \n",
      "\n",
      "[2431 rows x 10 columns]\n",
      "df_t.shape= (2430, 4) \n",
      "\n",
      "x_data.shape = (2430, 10)\n",
      "t_data.shape = (2430, 4) \n",
      "\n",
      "len_seq 2331 \n",
      "\n",
      "x.shape= (2331, 100, 10)\n",
      "t.shape= (2331, 4) \n",
      "\n",
      "x_train.shape= (2097, 100, 10)\n",
      "x_test.shape= (234, 100, 10) \n",
      "\n",
      "t_train.shape= (2097, 4)\n",
      "t_test.shape= (234, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  100 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1887 samples, validate on 210 samples\n",
      "Epoch 1/100\n",
      "1887/1887 [==============================] - 3s 2ms/step - loss: 1.3770 - categorical_accuracy: 0.2819 - val_loss: 1.3145 - val_categorical_accuracy: 0.4286\n",
      "Epoch 2/100\n",
      "1887/1887 [==============================] - 1s 653us/step - loss: 1.2825 - categorical_accuracy: 0.4128 - val_loss: 1.0972 - val_categorical_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1887/1887 [==============================] - 1s 614us/step - loss: 1.1084 - categorical_accuracy: 0.4626 - val_loss: 0.8595 - val_categorical_accuracy: 0.4667\n",
      "Epoch 4/100\n",
      "1887/1887 [==============================] - 1s 621us/step - loss: 1.0598 - categorical_accuracy: 0.4489 - val_loss: 0.8667 - val_categorical_accuracy: 0.4571\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    118    106      1\n",
      "fall?      0      3      4      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5213675213675214\n",
      "準正答率（騰落）: 0.5299145299145299\n",
      "学習時間:8.097653865814209[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1887 samples, validate on 210 samples\n",
      "Epoch 1/100\n",
      "1887/1887 [==============================] - 2s 1ms/step - loss: 1.3543 - categorical_accuracy: 0.3355 - val_loss: 1.2254 - val_categorical_accuracy: 0.5381\n",
      "Epoch 2/100\n",
      "1887/1887 [==============================] - 1s 705us/step - loss: 1.1536 - categorical_accuracy: 0.4589 - val_loss: 0.8809 - val_categorical_accuracy: 0.4619\n",
      "Epoch 3/100\n",
      "1887/1887 [==============================] - 1s 678us/step - loss: 1.0449 - categorical_accuracy: 0.4653 - val_loss: 0.8749 - val_categorical_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1887/1887 [==============================] - 1s 669us/step - loss: 1.0349 - categorical_accuracy: 0.4637 - val_loss: 0.8714 - val_categorical_accuracy: 0.4762\n",
      "Epoch 5/100\n",
      "1887/1887 [==============================] - 1s 630us/step - loss: 1.0327 - categorical_accuracy: 0.4441 - val_loss: 0.8751 - val_categorical_accuracy: 0.4762\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    107     95      1\n",
      "fall?      0     14     15      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5213675213675214\n",
      "準正答率（騰落）: 0.5299145299145299\n",
      "学習時間:8.83414912223816[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1887 samples, validate on 210 samples\n",
      "Epoch 1/100\n",
      "1887/1887 [==============================] - 3s 1ms/step - loss: 1.3438 - categorical_accuracy: 0.3095 - val_loss: 1.1304 - val_categorical_accuracy: 0.5286\n",
      "Epoch 2/100\n",
      "1887/1887 [==============================] - 1s 639us/step - loss: 1.1215 - categorical_accuracy: 0.4494 - val_loss: 0.9266 - val_categorical_accuracy: 0.5095\n",
      "Epoch 3/100\n",
      "1887/1887 [==============================] - 1s 720us/step - loss: 1.0407 - categorical_accuracy: 0.4764 - val_loss: 0.8600 - val_categorical_accuracy: 0.5429\n",
      "Epoch 4/100\n",
      "1887/1887 [==============================] - 1s 654us/step - loss: 1.0280 - categorical_accuracy: 0.4605 - val_loss: 0.8692 - val_categorical_accuracy: 0.4857\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     68     71      0\n",
      "fall?      1     53     39      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.45726495726495725\n",
      "準正答率（騰落）: 0.4658119658119658\n",
      "学習時間:7.600819110870361[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1887 samples, validate on 210 samples\n",
      "Epoch 1/100\n",
      "1887/1887 [==============================] - 3s 1ms/step - loss: 1.3125 - categorical_accuracy: 0.3561 - val_loss: 0.9063 - val_categorical_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1887/1887 [==============================] - 1s 682us/step - loss: 1.0778 - categorical_accuracy: 0.4653 - val_loss: 0.8806 - val_categorical_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1887/1887 [==============================] - 1s 701us/step - loss: 1.0340 - categorical_accuracy: 0.4589 - val_loss: 0.8650 - val_categorical_accuracy: 0.5095\n",
      "Epoch 4/100\n",
      "1887/1887 [==============================] - 1s 701us/step - loss: 1.0320 - categorical_accuracy: 0.4542 - val_loss: 0.8957 - val_categorical_accuracy: 0.4667\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    111    107      1\n",
      "fall?      0     10      3      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.48717948717948717\n",
      "準正答率（騰落）: 0.49572649572649574\n",
      "学習時間:7.998891592025757[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1887 samples, validate on 210 samples\n",
      "Epoch 1/100\n",
      "1887/1887 [==============================] - 3s 2ms/step - loss: 1.2889 - categorical_accuracy: 0.3816 - val_loss: 0.9048 - val_categorical_accuracy: 0.4619\n",
      "Epoch 2/100\n",
      "1887/1887 [==============================] - 1s 754us/step - loss: 1.0608 - categorical_accuracy: 0.4356 - val_loss: 0.8663 - val_categorical_accuracy: 0.4952\n",
      "Epoch 3/100\n",
      "1887/1887 [==============================] - 1s 750us/step - loss: 1.0194 - categorical_accuracy: 0.4732 - val_loss: 0.8648 - val_categorical_accuracy: 0.5048\n",
      "Epoch 4/100\n",
      "1887/1887 [==============================] - 1s 767us/step - loss: 1.0238 - categorical_accuracy: 0.4701 - val_loss: 0.8800 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     96     90      1\n",
      "fall?      1     25     20      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.49572649572649574\n",
      "準正答率（騰落）: 0.5\n",
      "学習時間:8.691076040267944[sec]\n",
      "\n",
      "len_seq 2231 \n",
      "\n",
      "x.shape= (2231, 200, 10)\n",
      "t.shape= (2231, 4) \n",
      "\n",
      "x_train.shape= (2007, 200, 10)\n",
      "x_test.shape= (224, 200, 10) \n",
      "\n",
      "t_train.shape= (2007, 4)\n",
      "t_test.shape= (224, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1806 samples, validate on 201 samples\n",
      "Epoch 1/100\n",
      "1806/1806 [==============================] - 4s 2ms/step - loss: 1.3795 - categorical_accuracy: 0.2973 - val_loss: 1.3189 - val_categorical_accuracy: 0.4527\n",
      "Epoch 2/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.2963 - categorical_accuracy: 0.4025 - val_loss: 1.1569 - val_categorical_accuracy: 0.4826\n",
      "Epoch 3/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.1422 - categorical_accuracy: 0.4629 - val_loss: 0.8380 - val_categorical_accuracy: 0.4776\n",
      "Epoch 4/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.0711 - categorical_accuracy: 0.4524 - val_loss: 0.8536 - val_categorical_accuracy: 0.4925\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    114    107      1\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5089285714285714\n",
      "準正答率（騰落）: 0.5178571428571429\n",
      "学習時間:12.063364744186401[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1806 samples, validate on 201 samples\n",
      "Epoch 1/100\n",
      "1806/1806 [==============================] - 4s 2ms/step - loss: 1.3517 - categorical_accuracy: 0.3405 - val_loss: 1.2381 - val_categorical_accuracy: 0.4826\n",
      "Epoch 2/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.1591 - categorical_accuracy: 0.4546 - val_loss: 0.8509 - val_categorical_accuracy: 0.4925\n",
      "Epoch 3/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.0401 - categorical_accuracy: 0.4690 - val_loss: 0.8571 - val_categorical_accuracy: 0.4925\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     29     28      0\n",
      "fall?      1     85     79      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.48214285714285715\n",
      "準正答率（騰落）: 0.49107142857142855\n",
      "学習時間:10.045764684677124[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1806 samples, validate on 201 samples\n",
      "Epoch 1/100\n",
      "1806/1806 [==============================] - 4s 2ms/step - loss: 1.3484 - categorical_accuracy: 0.3101 - val_loss: 1.1637 - val_categorical_accuracy: 0.4726\n",
      "Epoch 2/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.1031 - categorical_accuracy: 0.4535 - val_loss: 0.8649 - val_categorical_accuracy: 0.5174\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.0449 - categorical_accuracy: 0.4607 - val_loss: 0.8543 - val_categorical_accuracy: 0.4975\n",
      "Epoch 4/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.0128 - categorical_accuracy: 0.4723 - val_loss: 0.8468 - val_categorical_accuracy: 0.4826\n",
      "Epoch 5/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.0073 - categorical_accuracy: 0.4790 - val_loss: 0.8654 - val_categorical_accuracy: 0.4826\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     21     24      0\n",
      "fall?      1     93     83      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4642857142857143\n",
      "準正答率（騰落）: 0.4732142857142857\n",
      "学習時間:14.788713693618774[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1806 samples, validate on 201 samples\n",
      "Epoch 1/100\n",
      "1806/1806 [==============================] - 4s 2ms/step - loss: 1.3175 - categorical_accuracy: 0.3516 - val_loss: 0.8652 - val_categorical_accuracy: 0.4776\n",
      "Epoch 2/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.0905 - categorical_accuracy: 0.4385 - val_loss: 0.8519 - val_categorical_accuracy: 0.4677\n",
      "Epoch 3/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.0180 - categorical_accuracy: 0.4684 - val_loss: 0.8390 - val_categorical_accuracy: 0.4876\n",
      "Epoch 4/100\n",
      "1806/1806 [==============================] - 2s 1ms/step - loss: 1.0215 - categorical_accuracy: 0.4496 - val_loss: 0.8541 - val_categorical_accuracy: 0.4925\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     24     33      0\n",
      "fall?      1     90     74      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4375\n",
      "準正答率（騰落）: 0.44642857142857145\n",
      "学習時間:13.11354923248291[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1806 samples, validate on 201 samples\n",
      "Epoch 1/100\n",
      "1806/1806 [==============================] - 5s 3ms/step - loss: 1.3088 - categorical_accuracy: 0.3926 - val_loss: 0.8344 - val_categorical_accuracy: 0.4925\n",
      "Epoch 2/100\n",
      "1806/1806 [==============================] - 3s 2ms/step - loss: 1.0469 - categorical_accuracy: 0.4635 - val_loss: 0.8306 - val_categorical_accuracy: 0.4925\n",
      "Epoch 3/100\n",
      "1806/1806 [==============================] - 3s 1ms/step - loss: 1.0394 - categorical_accuracy: 0.4568 - val_loss: 0.8804 - val_categorical_accuracy: 0.4776\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      0      0      0\n",
      "fall?      2    114    107      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.47767857142857145\n",
      "準正答率（騰落）: 0.48214285714285715\n",
      "学習時間:11.660255670547485[sec]\n",
      "\n",
      "len_seq 2131 \n",
      "\n",
      "x.shape= (2131, 300, 10)\n",
      "t.shape= (2131, 4) \n",
      "\n",
      "x_train.shape= (1917, 300, 10)\n",
      "x_test.shape= (214, 300, 10) \n",
      "\n",
      "t_train.shape= (1917, 4)\n",
      "t_test.shape= (214, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1725 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "1725/1725 [==============================] - 5s 3ms/step - loss: 1.3804 - categorical_accuracy: 0.3113 - val_loss: 1.3270 - val_categorical_accuracy: 0.4375\n",
      "Epoch 2/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.3068 - categorical_accuracy: 0.4104 - val_loss: 1.1911 - val_categorical_accuracy: 0.4740\n",
      "Epoch 3/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.1549 - categorical_accuracy: 0.4586 - val_loss: 0.8445 - val_categorical_accuracy: 0.4740\n",
      "Epoch 4/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.0673 - categorical_accuracy: 0.4551 - val_loss: 0.8327 - val_categorical_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.0473 - categorical_accuracy: 0.4516 - val_loss: 0.8409 - val_categorical_accuracy: 0.4792\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     14     35      0\n",
      "fall?      2     95     67      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.37850467289719625\n",
      "準正答率（騰落）: 0.38317757009345793\n",
      "学習時間:18.649315118789673[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1725 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "1725/1725 [==============================] - 5s 3ms/step - loss: 1.3536 - categorical_accuracy: 0.3443 - val_loss: 1.2644 - val_categorical_accuracy: 0.5052\n",
      "Epoch 2/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.1758 - categorical_accuracy: 0.4626 - val_loss: 0.8161 - val_categorical_accuracy: 0.5052\n",
      "Epoch 3/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.0579 - categorical_accuracy: 0.4684 - val_loss: 0.8444 - val_categorical_accuracy: 0.4844\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     77     84      0\n",
      "fall?      0     32     18      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4439252336448598\n",
      "準正答率（騰落）: 0.45794392523364486\n",
      "学習時間:13.1160569190979[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1725 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "1725/1725 [==============================] - 6s 3ms/step - loss: 1.3547 - categorical_accuracy: 0.3101 - val_loss: 1.2185 - val_categorical_accuracy: 0.4583\n",
      "Epoch 2/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.1387 - categorical_accuracy: 0.4383 - val_loss: 0.8248 - val_categorical_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.0414 - categorical_accuracy: 0.4806 - val_loss: 0.8713 - val_categorical_accuracy: 0.4896\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     16     25      0\n",
      "fall?      1     93     77      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.43457943925233644\n",
      "準正答率（騰落）: 0.4439252336448598\n",
      "学習時間:12.96344780921936[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1725 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "1725/1725 [==============================] - 6s 3ms/step - loss: 1.3328 - categorical_accuracy: 0.3710 - val_loss: 0.9760 - val_categorical_accuracy: 0.4844\n",
      "Epoch 2/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.0762 - categorical_accuracy: 0.4591 - val_loss: 0.9047 - val_categorical_accuracy: 0.4896\n",
      "Epoch 3/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.0267 - categorical_accuracy: 0.4684 - val_loss: 0.8279 - val_categorical_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.0186 - categorical_accuracy: 0.4574 - val_loss: 0.8593 - val_categorical_accuracy: 0.4740\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      7     17      0\n",
      "fall?      2    102     85      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.42990654205607476\n",
      "準正答率（騰落）: 0.43457943925233644\n",
      "学習時間:16.448243618011475[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1725 samples, validate on 192 samples\n",
      "Epoch 1/100\n",
      "1725/1725 [==============================] - 6s 4ms/step - loss: 1.3097 - categorical_accuracy: 0.3878 - val_loss: 0.8197 - val_categorical_accuracy: 0.4844\n",
      "Epoch 2/100\n",
      "1725/1725 [==============================] - 3s 2ms/step - loss: 1.0478 - categorical_accuracy: 0.4609 - val_loss: 0.8743 - val_categorical_accuracy: 0.4740\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      0      0      0\n",
      "fall?      2    109    102      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4766355140186916\n",
      "準正答率（騰落）: 0.48130841121495327\n",
      "学習時間:11.143402338027954[sec]\n",
      "\n",
      "len_seq 2031 \n",
      "\n",
      "x.shape= (2031, 400, 10)\n",
      "t.shape= (2031, 4) \n",
      "\n",
      "x_train.shape= (1827, 400, 10)\n",
      "x_test.shape= (204, 400, 10) \n",
      "\n",
      "t_train.shape= (1827, 4)\n",
      "t_test.shape= (204, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1644 samples, validate on 183 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 7s 4ms/step - loss: 1.3834 - categorical_accuracy: 0.2786 - val_loss: 1.3218 - val_categorical_accuracy: 0.4317\n",
      "Epoch 2/100\n",
      "1644/1644 [==============================] - 4s 2ms/step - loss: 1.3046 - categorical_accuracy: 0.4136 - val_loss: 1.1890 - val_categorical_accuracy: 0.4973\n",
      "Epoch 3/100\n",
      "1644/1644 [==============================] - 4s 3ms/step - loss: 1.1529 - categorical_accuracy: 0.4532 - val_loss: 0.8401 - val_categorical_accuracy: 0.4754\n",
      "Epoch 4/100\n",
      "1644/1644 [==============================] - 4s 3ms/step - loss: 1.0902 - categorical_accuracy: 0.4392 - val_loss: 0.8309 - val_categorical_accuracy: 0.4973\n",
      "Epoch 5/100\n",
      "1644/1644 [==============================] - 4s 2ms/step - loss: 1.0478 - categorical_accuracy: 0.4672 - val_loss: 0.8472 - val_categorical_accuracy: 0.4754\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     24     39      0\n",
      "fall?      2     80     59      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4068627450980392\n",
      "準正答率（騰落）: 0.4068627450980392\n",
      "学習時間:24.186601877212524[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1644 samples, validate on 183 samples\n",
      "Epoch 1/100\n",
      "1644/1644 [==============================] - 7s 4ms/step - loss: 1.3575 - categorical_accuracy: 0.3327 - val_loss: 1.2541 - val_categorical_accuracy: 0.4754\n",
      "Epoch 2/100\n",
      "1644/1644 [==============================] - 4s 2ms/step - loss: 1.1798 - categorical_accuracy: 0.4258 - val_loss: 0.8248 - val_categorical_accuracy: 0.4372\n",
      "Epoch 3/100\n",
      "1644/1644 [==============================] - 4s 2ms/step - loss: 1.0606 - categorical_accuracy: 0.4568 - val_loss: 0.8593 - val_categorical_accuracy: 0.4809\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     28     30      0\n",
      "fall?      1     76     68      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.47058823529411764\n",
      "準正答率（騰落）: 0.47549019607843135\n",
      "学習時間:16.176586627960205[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1644 samples, validate on 183 samples\n",
      "Epoch 1/100\n",
      "1644/1644 [==============================] - 7s 4ms/step - loss: 1.3541 - categorical_accuracy: 0.3078 - val_loss: 1.2199 - val_categorical_accuracy: 0.4590\n",
      "Epoch 2/100\n",
      "1644/1644 [==============================] - 4s 2ms/step - loss: 1.1529 - categorical_accuracy: 0.4653 - val_loss: 0.8374 - val_categorical_accuracy: 0.4973\n",
      "Epoch 3/100\n",
      "1644/1644 [==============================] - 4s 2ms/step - loss: 1.0259 - categorical_accuracy: 0.4708 - val_loss: 0.8665 - val_categorical_accuracy: 0.4754\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     11     16      0\n",
      "fall?      1     93     82      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.45588235294117646\n",
      "準正答率（騰落）: 0.46078431372549017\n",
      "学習時間:16.448440074920654[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1644 samples, validate on 183 samples\n",
      "Epoch 1/100\n",
      "1644/1644 [==============================] - 7s 5ms/step - loss: 1.3326 - categorical_accuracy: 0.3662 - val_loss: 0.9719 - val_categorical_accuracy: 0.4699\n",
      "Epoch 2/100\n",
      "1644/1644 [==============================] - 4s 3ms/step - loss: 1.0844 - categorical_accuracy: 0.4544 - val_loss: 0.8875 - val_categorical_accuracy: 0.4918\n",
      "Epoch 3/100\n",
      "1644/1644 [==============================] - 4s 3ms/step - loss: 1.0080 - categorical_accuracy: 0.4489 - val_loss: 0.8308 - val_categorical_accuracy: 0.5137\n",
      "Epoch 4/100\n",
      "1644/1644 [==============================] - 4s 3ms/step - loss: 1.0035 - categorical_accuracy: 0.4647 - val_loss: 0.8650 - val_categorical_accuracy: 0.4699\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      5     16      0\n",
      "fall?      2     99     82      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4264705882352941\n",
      "準正答率（騰落）: 0.4264705882352941\n",
      "学習時間:21.58787178993225[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1644 samples, validate on 183 samples\n",
      "Epoch 1/100\n",
      "1644/1644 [==============================] - 8s 5ms/step - loss: 1.3127 - categorical_accuracy: 0.3717 - val_loss: 0.8612 - val_categorical_accuracy: 0.4754\n",
      "Epoch 2/100\n",
      "1644/1644 [==============================] - 5s 3ms/step - loss: 1.0367 - categorical_accuracy: 0.4678 - val_loss: 0.8295 - val_categorical_accuracy: 0.4754\n",
      "Epoch 3/100\n",
      "1644/1644 [==============================] - 5s 3ms/step - loss: 1.0233 - categorical_accuracy: 0.4465 - val_loss: 0.9134 - val_categorical_accuracy: 0.4754\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      3      5      0\n",
      "fall?      2    101     93      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.47058823529411764\n",
      "準正答率（騰落）: 0.47058823529411764\n",
      "学習時間:18.941921949386597[sec]\n",
      "\n",
      "len_seq 1931 \n",
      "\n",
      "x.shape= (1931, 500, 10)\n",
      "t.shape= (1931, 4) \n",
      "\n",
      "x_train.shape= (1737, 500, 10)\n",
      "x_test.shape= (194, 500, 10) \n",
      "\n",
      "t_train.shape= (1737, 4)\n",
      "t_test.shape= (194, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1563 samples, validate on 174 samples\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3834 - categorical_accuracy: 0.2924 - val_loss: 1.3272 - val_categorical_accuracy: 0.4598\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3173 - categorical_accuracy: 0.3954 - val_loss: 1.2127 - val_categorical_accuracy: 0.5287\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1937 - categorical_accuracy: 0.4472 - val_loss: 0.8324 - val_categorical_accuracy: 0.4943\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0799 - categorical_accuracy: 0.4575 - val_loss: 0.7996 - val_categorical_accuracy: 0.4885\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0620 - categorical_accuracy: 0.4632 - val_loss: 0.8117 - val_categorical_accuracy: 0.4885\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     98     89      0\n",
      "fall?      0      2      3      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.520618556701031\n",
      "準正答率（騰落）: 0.5309278350515464\n",
      "学習時間:30.06100630760193[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1563 samples, validate on 174 samples\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3609 - categorical_accuracy: 0.3257 - val_loss: 1.2588 - val_categorical_accuracy: 0.5172\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1961 - categorical_accuracy: 0.4306 - val_loss: 0.7905 - val_categorical_accuracy: 0.4943\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0668 - categorical_accuracy: 0.4722 - val_loss: 0.8278 - val_categorical_accuracy: 0.4885\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    100     92      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5154639175257731\n",
      "準正答率（騰落）: 0.5257731958762887\n",
      "学習時間:20.626391887664795[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1563 samples, validate on 174 samples\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3623 - categorical_accuracy: 0.2860 - val_loss: 1.2362 - val_categorical_accuracy: 0.4483\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1617 - categorical_accuracy: 0.4402 - val_loss: 0.7832 - val_categorical_accuracy: 0.4943\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0421 - categorical_accuracy: 0.4645 - val_loss: 0.8584 - val_categorical_accuracy: 0.4885\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    100     92      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5154639175257731\n",
      "準正答率（騰落）: 0.5257731958762887\n",
      "学習時間:20.217923641204834[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  400 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1563 samples, validate on 174 samples\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3424 - categorical_accuracy: 0.3442 - val_loss: 0.9908 - val_categorical_accuracy: 0.4943\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0989 - categorical_accuracy: 0.4651 - val_loss: 0.8592 - val_categorical_accuracy: 0.4885\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0310 - categorical_accuracy: 0.4530 - val_loss: 0.8055 - val_categorical_accuracy: 0.5057\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0191 - categorical_accuracy: 0.4383 - val_loss: 0.8388 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     20     31      0\n",
      "fall?      1     80     61      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4175257731958763\n",
      "準正答率（騰落）: 0.422680412371134\n",
      "学習時間:26.45026469230652[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1563 samples, validate on 174 samples\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3330 - categorical_accuracy: 0.3628 - val_loss: 0.7984 - val_categorical_accuracy: 0.4943\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0775 - categorical_accuracy: 0.4555 - val_loss: 0.8509 - val_categorical_accuracy: 0.4943\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      4      1      0\n",
      "fall?      2     96     91      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4896907216494845\n",
      "準正答率（騰落）: 0.4896907216494845\n",
      "学習時間:16.82443118095398[sec]\n",
      "\n",
      "len_seq 1831 \n",
      "\n",
      "x.shape= (1831, 600, 10)\n",
      "t.shape= (1831, 4) \n",
      "\n",
      "x_train.shape= (1647, 600, 10)\n",
      "x_test.shape= (184, 600, 10) \n",
      "\n",
      "t_train.shape= (1647, 4)\n",
      "t_test.shape= (184, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  600\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1482 samples, validate on 165 samples\n",
      "Epoch 1/100\n",
      "1482/1482 [==============================] - 9s 6ms/step - loss: 1.3880 - categorical_accuracy: 0.2780 - val_loss: 1.3363 - val_categorical_accuracy: 0.4485\n",
      "Epoch 2/100\n",
      "1482/1482 [==============================] - 5s 4ms/step - loss: 1.3280 - categorical_accuracy: 0.3806 - val_loss: 1.2432 - val_categorical_accuracy: 0.5091\n",
      "Epoch 3/100\n",
      "1482/1482 [==============================] - 5s 4ms/step - loss: 1.2193 - categorical_accuracy: 0.4345 - val_loss: 0.9001 - val_categorical_accuracy: 0.4909\n",
      "Epoch 4/100\n",
      "1482/1482 [==============================] - 5s 4ms/step - loss: 1.1023 - categorical_accuracy: 0.4602 - val_loss: 0.7928 - val_categorical_accuracy: 0.4909\n",
      "Epoch 5/100\n",
      "1482/1482 [==============================] - 5s 4ms/step - loss: 1.0641 - categorical_accuracy: 0.4548 - val_loss: 0.8094 - val_categorical_accuracy: 0.4909\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     95     87      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5163043478260869\n",
      "準正答率（騰落）: 0.5271739130434783\n",
      "学習時間:31.61338472366333[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  600\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1482 samples, validate on 165 samples\n",
      "Epoch 1/100\n",
      "1482/1482 [==============================] - 10s 6ms/step - loss: 1.3652 - categorical_accuracy: 0.3401 - val_loss: 1.2868 - val_categorical_accuracy: 0.4788\n",
      "Epoch 2/100\n",
      "1482/1482 [==============================] - 5s 3ms/step - loss: 1.2228 - categorical_accuracy: 0.4339 - val_loss: 0.7972 - val_categorical_accuracy: 0.4788\n",
      "Epoch 3/100\n",
      "1482/1482 [==============================] - 5s 4ms/step - loss: 1.0980 - categorical_accuracy: 0.4622 - val_loss: 0.7921 - val_categorical_accuracy: 0.4909\n",
      "Epoch 4/100\n",
      "1482/1482 [==============================] - 5s 3ms/step - loss: 1.0469 - categorical_accuracy: 0.4534 - val_loss: 0.8643 - val_categorical_accuracy: 0.4909\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     47     49      0\n",
      "fall?      1     48     38      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.46195652173913043\n",
      "準正答率（騰落）: 0.4673913043478261\n",
      "学習時間:26.399492025375366[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  600\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1482 samples, validate on 165 samples\n",
      "Epoch 1/100\n",
      "1482/1482 [==============================] - 10s 6ms/step - loss: 1.3629 - categorical_accuracy: 0.2996 - val_loss: 1.2655 - val_categorical_accuracy: 0.4727\n",
      "Epoch 2/100\n",
      "1482/1482 [==============================] - 5s 4ms/step - loss: 1.1916 - categorical_accuracy: 0.4332 - val_loss: 0.8062 - val_categorical_accuracy: 0.4909\n",
      "Epoch 3/100\n",
      "1482/1482 [==============================] - 5s 4ms/step - loss: 1.0718 - categorical_accuracy: 0.4588 - val_loss: 0.8649 - val_categorical_accuracy: 0.5091\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     32     36      0\n",
      "fall?      1     63     51      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.45108695652173914\n",
      "準正答率（騰落）: 0.45652173913043476\n",
      "学習時間:21.55148720741272[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  600\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1482 samples, validate on 165 samples\n",
      "Epoch 1/100\n",
      "1482/1482 [==============================] - 10s 7ms/step - loss: 1.3419 - categorical_accuracy: 0.3394 - val_loss: 1.0714 - val_categorical_accuracy: 0.4909\n",
      "Epoch 2/100\n",
      "1482/1482 [==============================] - 6s 4ms/step - loss: 1.1385 - categorical_accuracy: 0.4460 - val_loss: 0.8912 - val_categorical_accuracy: 0.4970\n",
      "Epoch 3/100\n",
      "1482/1482 [==============================] - 6s 4ms/step - loss: 1.0245 - categorical_accuracy: 0.4588 - val_loss: 0.8009 - val_categorical_accuracy: 0.4909\n",
      "Epoch 4/100\n",
      "1482/1482 [==============================] - 6s 4ms/step - loss: 1.0220 - categorical_accuracy: 0.4690 - val_loss: 0.8478 - val_categorical_accuracy: 0.4848\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     59     61      0\n",
      "fall?      1     36     26      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.46195652173913043\n",
      "準正答率（騰落）: 0.4673913043478261\n",
      "学習時間:28.75184726715088[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  600\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1482 samples, validate on 165 samples\n",
      "Epoch 1/100\n",
      "1482/1482 [==============================] - 11s 7ms/step - loss: 1.3308 - categorical_accuracy: 0.3644 - val_loss: 0.7919 - val_categorical_accuracy: 0.4970\n",
      "Epoch 2/100\n",
      "1482/1482 [==============================] - 6s 4ms/step - loss: 1.0868 - categorical_accuracy: 0.4487 - val_loss: 0.9015 - val_categorical_accuracy: 0.4788\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     12     12      0\n",
      "fall?      1     83     75      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.47282608695652173\n",
      "準正答率（騰落）: 0.4782608695652174\n",
      "学習時間:18.292449712753296[sec]\n",
      "\n",
      "len_seq 1731 \n",
      "\n",
      "x.shape= (1731, 700, 10)\n",
      "t.shape= (1731, 4) \n",
      "\n",
      "x_train.shape= (1557, 700, 10)\n",
      "x_test.shape= (174, 700, 10) \n",
      "\n",
      "t_train.shape= (1557, 4)\n",
      "t_test.shape= (174, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  700\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1401 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "1401/1401 [==============================] - 11s 8ms/step - loss: 1.3813 - categorical_accuracy: 0.2934 - val_loss: 1.3347 - val_categorical_accuracy: 0.4487\n",
      "Epoch 2/100\n",
      "1401/1401 [==============================] - 6s 4ms/step - loss: 1.3281 - categorical_accuracy: 0.3776 - val_loss: 1.2331 - val_categorical_accuracy: 0.4744\n",
      "Epoch 3/100\n",
      "1401/1401 [==============================] - 6s 4ms/step - loss: 1.2213 - categorical_accuracy: 0.4090 - val_loss: 0.8651 - val_categorical_accuracy: 0.4679\n",
      "Epoch 4/100\n",
      "1401/1401 [==============================] - 6s 4ms/step - loss: 1.0857 - categorical_accuracy: 0.4597 - val_loss: 0.7891 - val_categorical_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1401/1401 [==============================] - 6s 4ms/step - loss: 1.0631 - categorical_accuracy: 0.5004 - val_loss: 0.7951 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     90     82      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5172413793103449\n",
      "準正答率（騰落）: 0.5287356321839081\n",
      "学習時間:36.52516794204712[sec]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  700\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1401 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "1401/1401 [==============================] - 11s 8ms/step - loss: 1.3632 - categorical_accuracy: 0.3440 - val_loss: 1.2868 - val_categorical_accuracy: 0.4295\n",
      "Epoch 2/100\n",
      "1401/1401 [==============================] - 6s 4ms/step - loss: 1.2286 - categorical_accuracy: 0.4226 - val_loss: 0.7885 - val_categorical_accuracy: 0.4808\n",
      "Epoch 3/100\n",
      "1401/1401 [==============================] - 6s 4ms/step - loss: 1.0972 - categorical_accuracy: 0.4540 - val_loss: 0.7988 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     90     82      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5172413793103449\n",
      "準正答率（騰落）: 0.5287356321839081\n",
      "学習時間:24.82659149169922[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  700\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1401 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "1401/1401 [==============================] - 12s 8ms/step - loss: 1.3647 - categorical_accuracy: 0.2934 - val_loss: 1.2606 - val_categorical_accuracy: 0.4359\n",
      "Epoch 2/100\n",
      "1401/1401 [==============================] - 6s 5ms/step - loss: 1.1727 - categorical_accuracy: 0.4418 - val_loss: 0.7700 - val_categorical_accuracy: 0.4744\n",
      "Epoch 3/100\n",
      "1401/1401 [==============================] - 6s 4ms/step - loss: 1.0748 - categorical_accuracy: 0.4625 - val_loss: 0.8820 - val_categorical_accuracy: 0.5064\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     82     74      0\n",
      "fall?      0      8      8      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5172413793103449\n",
      "準正答率（騰落）: 0.5287356321839081\n",
      "学習時間:25.339372634887695[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  700\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1401 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "1401/1401 [==============================] - 12s 8ms/step - loss: 1.3488 - categorical_accuracy: 0.3626 - val_loss: 1.1081 - val_categorical_accuracy: 0.4359\n",
      "Epoch 2/100\n",
      "1401/1401 [==============================] - 6s 5ms/step - loss: 1.1017 - categorical_accuracy: 0.4575 - val_loss: 0.8462 - val_categorical_accuracy: 0.4679\n",
      "Epoch 3/100\n",
      "1401/1401 [==============================] - 7s 5ms/step - loss: 1.0391 - categorical_accuracy: 0.4825 - val_loss: 0.8120 - val_categorical_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1401/1401 [==============================] - 6s 5ms/step - loss: 1.0262 - categorical_accuracy: 0.4640 - val_loss: 0.8323 - val_categorical_accuracy: 0.5192\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     69     70      0\n",
      "fall?      0     21     12      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.46551724137931033\n",
      "準正答率（騰落）: 0.47701149425287354\n",
      "学習時間:32.24996876716614[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  700\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1401 samples, validate on 156 samples\n",
      "Epoch 1/100\n",
      "1401/1401 [==============================] - 13s 10ms/step - loss: 1.3338 - categorical_accuracy: 0.3583 - val_loss: 0.8070 - val_categorical_accuracy: 0.4487\n",
      "Epoch 2/100\n",
      "1401/1401 [==============================] - 8s 5ms/step - loss: 1.0833 - categorical_accuracy: 0.4732 - val_loss: 0.8551 - val_categorical_accuracy: 0.4872\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     71     73      0\n",
      "fall?      0     19      9      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.45977011494252873\n",
      "準正答率（騰落）: 0.47126436781609193\n",
      "学習時間:22.3495352268219[sec]\n",
      "\n",
      "len_seq 1631 \n",
      "\n",
      "x.shape= (1631, 800, 10)\n",
      "t.shape= (1631, 4) \n",
      "\n",
      "x_train.shape= (1467, 800, 10)\n",
      "x_test.shape= (164, 800, 10) \n",
      "\n",
      "t_train.shape= (1467, 4)\n",
      "t_test.shape= (164, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  800\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1320 samples, validate on 147 samples\n",
      "Epoch 1/100\n",
      "1320/1320 [==============================] - 12s 9ms/step - loss: 1.3819 - categorical_accuracy: 0.2879 - val_loss: 1.3397 - val_categorical_accuracy: 0.4286\n",
      "Epoch 2/100\n",
      "1320/1320 [==============================] - 7s 5ms/step - loss: 1.3308 - categorical_accuracy: 0.3909 - val_loss: 1.2585 - val_categorical_accuracy: 0.4762\n",
      "Epoch 3/100\n",
      "1320/1320 [==============================] - 7s 5ms/step - loss: 1.2533 - categorical_accuracy: 0.4197 - val_loss: 1.0184 - val_categorical_accuracy: 0.4490\n",
      "Epoch 4/100\n",
      "1320/1320 [==============================] - 7s 5ms/step - loss: 1.1135 - categorical_accuracy: 0.4477 - val_loss: 0.7781 - val_categorical_accuracy: 0.5102\n",
      "Epoch 5/100\n",
      "1320/1320 [==============================] - 7s 5ms/step - loss: 1.1174 - categorical_accuracy: 0.4280 - val_loss: 0.7934 - val_categorical_accuracy: 0.5102\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     85     77      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5182926829268293\n",
      "準正答率（騰落）: 0.5304878048780488\n",
      "学習時間:41.290565967559814[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  800\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1320 samples, validate on 147 samples\n",
      "Epoch 1/100\n",
      "1320/1320 [==============================] - 13s 10ms/step - loss: 1.3631 - categorical_accuracy: 0.3409 - val_loss: 1.2956 - val_categorical_accuracy: 0.4354\n",
      "Epoch 2/100\n",
      "1320/1320 [==============================] - 7s 5ms/step - loss: 1.2489 - categorical_accuracy: 0.4348 - val_loss: 0.8129 - val_categorical_accuracy: 0.4422\n",
      "Epoch 3/100\n",
      "1320/1320 [==============================] - 7s 5ms/step - loss: 1.1231 - categorical_accuracy: 0.4500 - val_loss: 0.7940 - val_categorical_accuracy: 0.5034\n",
      "Epoch 4/100\n",
      "1320/1320 [==============================] - 7s 5ms/step - loss: 1.0593 - categorical_accuracy: 0.4712 - val_loss: 0.8641 - val_categorical_accuracy: 0.4762\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     51     49      0\n",
      "fall?      0     34     28      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4817073170731707\n",
      "準正答率（騰落）: 0.49390243902439024\n",
      "学習時間:35.00463914871216[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  800\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1320 samples, validate on 147 samples\n",
      "Epoch 1/100\n",
      "1320/1320 [==============================] - 13s 10ms/step - loss: 1.3706 - categorical_accuracy: 0.2773 - val_loss: 1.2728 - val_categorical_accuracy: 0.4218\n",
      "Epoch 2/100\n",
      "1320/1320 [==============================] - 7s 5ms/step - loss: 1.2062 - categorical_accuracy: 0.4273 - val_loss: 0.8135 - val_categorical_accuracy: 0.5102\n",
      "Epoch 3/100\n",
      "1320/1320 [==============================] - 7s 5ms/step - loss: 1.0928 - categorical_accuracy: 0.4765 - val_loss: 0.9214 - val_categorical_accuracy: 0.4694\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     28     30      0\n",
      "fall?      1     57     47      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4573170731707317\n",
      "準正答率（騰落）: 0.4634146341463415\n",
      "学習時間:28.304224491119385[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  800\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1320 samples, validate on 147 samples\n",
      "Epoch 1/100\n",
      "1320/1320 [==============================] - 14s 10ms/step - loss: 1.3542 - categorical_accuracy: 0.3462 - val_loss: 1.1874 - val_categorical_accuracy: 0.4422\n",
      "Epoch 2/100\n",
      "1320/1320 [==============================] - 8s 6ms/step - loss: 1.1556 - categorical_accuracy: 0.4402 - val_loss: 0.8988 - val_categorical_accuracy: 0.4422\n",
      "Epoch 3/100\n",
      "1320/1320 [==============================] - 8s 6ms/step - loss: 1.0721 - categorical_accuracy: 0.4523 - val_loss: 0.8212 - val_categorical_accuracy: 0.4354\n",
      "Epoch 4/100\n",
      "1320/1320 [==============================] - 7s 6ms/step - loss: 1.0360 - categorical_accuracy: 0.4583 - val_loss: 0.8266 - val_categorical_accuracy: 0.5102\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     85     77      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5182926829268293\n",
      "準正答率（騰落）: 0.5304878048780488\n",
      "学習時間:37.931294202804565[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  800\n",
      "n_hidden:  500 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1320 samples, validate on 147 samples\n",
      "Epoch 1/100\n",
      "1320/1320 [==============================] - 16s 12ms/step - loss: 1.3422 - categorical_accuracy: 0.3568 - val_loss: 0.8234 - val_categorical_accuracy: 0.4558\n",
      "Epoch 2/100\n",
      "1320/1320 [==============================] - 9s 7ms/step - loss: 1.1143 - categorical_accuracy: 0.4644 - val_loss: 0.8661 - val_categorical_accuracy: 0.4626\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     48     46      0\n",
      "fall?      1     37     31      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4817073170731707\n",
      "準正答率（騰落）: 0.4878048780487805\n",
      "学習時間:26.314614057540894[sec]\n",
      "\n",
      "len_seq 1531 \n",
      "\n",
      "x.shape= (1531, 900, 10)\n",
      "t.shape= (1531, 4) \n",
      "\n",
      "x_train.shape= (1377, 900, 10)\n",
      "x_test.shape= (154, 900, 10) \n",
      "\n",
      "t_train.shape= (1377, 4)\n",
      "t_test.shape= (154, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  900\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1239 samples, validate on 138 samples\n",
      "Epoch 1/100\n",
      "1239/1239 [==============================] - 13s 10ms/step - loss: 1.3854 - categorical_accuracy: 0.2809 - val_loss: 1.3442 - val_categorical_accuracy: 0.4348\n",
      "Epoch 2/100\n",
      "1239/1239 [==============================] - 7s 5ms/step - loss: 1.3421 - categorical_accuracy: 0.3592 - val_loss: 1.2719 - val_categorical_accuracy: 0.4203\n",
      "Epoch 3/100\n",
      "1239/1239 [==============================] - 6s 5ms/step - loss: 1.2717 - categorical_accuracy: 0.4132 - val_loss: 1.1100 - val_categorical_accuracy: 0.4420\n",
      "Epoch 4/100\n",
      "1239/1239 [==============================] - 7s 5ms/step - loss: 1.1447 - categorical_accuracy: 0.4520 - val_loss: 0.7888 - val_categorical_accuracy: 0.4420\n",
      "Epoch 5/100\n",
      "1239/1239 [==============================] - 7s 5ms/step - loss: 1.1148 - categorical_accuracy: 0.4568 - val_loss: 0.7888 - val_categorical_accuracy: 0.5217\n",
      "Epoch 6/100\n",
      "1239/1239 [==============================] - 7s 5ms/step - loss: 1.0741 - categorical_accuracy: 0.4544 - val_loss: 0.8173 - val_categorical_accuracy: 0.5217\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     80     71      0\n",
      "fall?      0      1      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5194805194805194\n",
      "準正答率（騰落）: 0.5324675324675324\n",
      "学習時間:46.92245626449585[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  900\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1239 samples, validate on 138 samples\n",
      "Epoch 1/100\n",
      "1239/1239 [==============================] - 13s 10ms/step - loss: 1.3687 - categorical_accuracy: 0.3188 - val_loss: 1.3009 - val_categorical_accuracy: 0.4348\n",
      "Epoch 2/100\n",
      "1239/1239 [==============================] - 7s 5ms/step - loss: 1.2794 - categorical_accuracy: 0.4213 - val_loss: 1.0235 - val_categorical_accuracy: 0.4275\n",
      "Epoch 3/100\n",
      "1239/1239 [==============================] - 6s 5ms/step - loss: 1.1160 - categorical_accuracy: 0.4730 - val_loss: 0.7812 - val_categorical_accuracy: 0.5217\n",
      "Epoch 4/100\n",
      "1239/1239 [==============================] - 7s 6ms/step - loss: 1.0762 - categorical_accuracy: 0.4383 - val_loss: 0.8503 - val_categorical_accuracy: 0.4638\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     49     44      0\n",
      "fall?      1     32     27      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4935064935064935\n",
      "準正答率（騰落）: 0.5\n",
      "学習時間:34.205074310302734[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  900\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1239 samples, validate on 138 samples\n",
      "Epoch 1/100\n",
      "1239/1239 [==============================] - 13s 11ms/step - loss: 1.3665 - categorical_accuracy: 0.2930 - val_loss: 1.2860 - val_categorical_accuracy: 0.4130\n",
      "Epoch 2/100\n",
      "1239/1239 [==============================] - 7s 6ms/step - loss: 1.2501 - categorical_accuracy: 0.3850 - val_loss: 0.7747 - val_categorical_accuracy: 0.5362\n",
      "Epoch 3/100\n",
      "1239/1239 [==============================] - 6s 5ms/step - loss: 1.1005 - categorical_accuracy: 0.4576 - val_loss: 0.8594 - val_categorical_accuracy: 0.5217\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     65     61      0\n",
      "fall?      0     16     10      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.487012987012987\n",
      "準正答率（騰落）: 0.5\n",
      "学習時間:28.182526350021362[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  900\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1239 samples, validate on 138 samples\n",
      "Epoch 1/100\n",
      "1239/1239 [==============================] - 14s 12ms/step - loss: 1.3565 - categorical_accuracy: 0.3285 - val_loss: 1.2305 - val_categorical_accuracy: 0.4348\n",
      "Epoch 2/100\n",
      "1239/1239 [==============================] - 8s 6ms/step - loss: 1.1798 - categorical_accuracy: 0.4181 - val_loss: 0.7986 - val_categorical_accuracy: 0.5072\n",
      "Epoch 3/100\n",
      "1239/1239 [==============================] - 8s 6ms/step - loss: 1.0668 - categorical_accuracy: 0.4762 - val_loss: 0.8342 - val_categorical_accuracy: 0.5072\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     59     56      0\n",
      "fall?      0     22     15      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4805194805194805\n",
      "準正答率（騰落）: 0.4935064935064935\n",
      "学習時間:30.925921201705933[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  900\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1239 samples, validate on 138 samples\n",
      "Epoch 1/100\n",
      "1239/1239 [==============================] - 16s 13ms/step - loss: 1.3534 - categorical_accuracy: 0.3487 - val_loss: 1.1747 - val_categorical_accuracy: 0.4420\n",
      "Epoch 2/100\n",
      "1239/1239 [==============================] - 9s 7ms/step - loss: 1.1462 - categorical_accuracy: 0.4617 - val_loss: 0.8848 - val_categorical_accuracy: 0.4348\n",
      "Epoch 3/100\n",
      "1239/1239 [==============================] - 9s 7ms/step - loss: 1.0595 - categorical_accuracy: 0.4665 - val_loss: 0.8201 - val_categorical_accuracy: 0.5145\n",
      "Epoch 4/100\n",
      "1239/1239 [==============================] - 9s 7ms/step - loss: 1.0396 - categorical_accuracy: 0.4786 - val_loss: 0.8653 - val_categorical_accuracy: 0.4855\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     65     63      0\n",
      "fall?      0     16      8      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.474025974025974\n",
      "準正答率（騰落）: 0.487012987012987\n",
      "学習時間:44.40793514251709[sec]\n",
      "\n",
      "len_seq 1431 \n",
      "\n",
      "x.shape= (1431, 1000, 10)\n",
      "t.shape= (1431, 4) \n",
      "\n",
      "x_train.shape= (1287, 1000, 10)\n",
      "x_test.shape= (144, 1000, 10) \n",
      "\n",
      "t_train.shape= (1287, 4)\n",
      "t_test.shape= (144, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  1000\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1158 samples, validate on 129 samples\n",
      "Epoch 1/100\n",
      "1158/1158 [==============================] - 14s 12ms/step - loss: 1.3867 - categorical_accuracy: 0.2746 - val_loss: 1.3533 - val_categorical_accuracy: 0.4031\n",
      "Epoch 2/100\n",
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.3455 - categorical_accuracy: 0.3627 - val_loss: 1.2896 - val_categorical_accuracy: 0.4031\n",
      "Epoch 3/100\n",
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.2750 - categorical_accuracy: 0.4024 - val_loss: 1.1466 - val_categorical_accuracy: 0.4419\n",
      "Epoch 4/100\n",
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.1574 - categorical_accuracy: 0.4275 - val_loss: 0.8170 - val_categorical_accuracy: 0.4419\n",
      "Epoch 5/100\n",
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.1152 - categorical_accuracy: 0.4611 - val_loss: 0.8153 - val_categorical_accuracy: 0.4884\n",
      "Epoch 6/100\n",
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.0670 - categorical_accuracy: 0.4905 - val_loss: 0.8370 - val_categorical_accuracy: 0.4884\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     77     66      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5347222222222222\n",
      "準正答率（騰落）: 0.5416666666666666\n",
      "学習時間:51.0698618888855[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  1000\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1158 samples, validate on 129 samples\n",
      "Epoch 1/100\n",
      "1158/1158 [==============================] - 15s 13ms/step - loss: 1.3671 - categorical_accuracy: 0.3282 - val_loss: 1.3083 - val_categorical_accuracy: 0.4341\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.2860 - categorical_accuracy: 0.4223 - val_loss: 1.0440 - val_categorical_accuracy: 0.4341\n",
      "Epoch 3/100\n",
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.1124 - categorical_accuracy: 0.4853 - val_loss: 0.8677 - val_categorical_accuracy: 0.4884\n",
      "Epoch 4/100\n",
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.1080 - categorical_accuracy: 0.4655 - val_loss: 0.8604 - val_categorical_accuracy: 0.4264\n",
      "Epoch 5/100\n",
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.0545 - categorical_accuracy: 0.4560 - val_loss: 0.9012 - val_categorical_accuracy: 0.4574\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     22     13      0\n",
      "fall?      1     55     53      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5208333333333334\n",
      "準正答率（騰落）: 0.5208333333333334\n",
      "学習時間:44.110305070877075[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  1000\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1158 samples, validate on 129 samples\n",
      "Epoch 1/100\n",
      "1158/1158 [==============================] - 15s 13ms/step - loss: 1.3705 - categorical_accuracy: 0.2608 - val_loss: 1.2971 - val_categorical_accuracy: 0.3488\n",
      "Epoch 2/100\n",
      "1158/1158 [==============================] - 8s 7ms/step - loss: 1.2397 - categorical_accuracy: 0.3903 - val_loss: 0.8230 - val_categorical_accuracy: 0.4884\n",
      "Epoch 3/100\n",
      "1158/1158 [==============================] - 7s 6ms/step - loss: 1.0961 - categorical_accuracy: 0.4698 - val_loss: 0.8762 - val_categorical_accuracy: 0.4341\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     55     53      0\n",
      "fall?      0     22     13      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4722222222222222\n",
      "準正答率（騰落）: 0.4791666666666667\n",
      "学習時間:30.941761255264282[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  1000\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1158 samples, validate on 129 samples\n",
      "Epoch 1/100\n",
      "1158/1158 [==============================] - 16s 14ms/step - loss: 1.3649 - categorical_accuracy: 0.3005 - val_loss: 1.2455 - val_categorical_accuracy: 0.4031\n",
      "Epoch 2/100\n",
      "1158/1158 [==============================] - 9s 7ms/step - loss: 1.1738 - categorical_accuracy: 0.4594 - val_loss: 0.8732 - val_categorical_accuracy: 0.4884\n",
      "Epoch 3/100\n",
      "1158/1158 [==============================] - 9s 7ms/step - loss: 1.0966 - categorical_accuracy: 0.4560 - val_loss: 0.8859 - val_categorical_accuracy: 0.4651\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     16     14      0\n",
      "fall?      1     61     52      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4722222222222222\n",
      "準正答率（騰落）: 0.4722222222222222\n",
      "学習時間:34.7738881111145[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  1000\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1158 samples, validate on 129 samples\n",
      "Epoch 1/100\n",
      "1158/1158 [==============================] - 19s 16ms/step - loss: 1.3576 - categorical_accuracy: 0.3342 - val_loss: 1.1904 - val_categorical_accuracy: 0.3953\n",
      "Epoch 2/100\n",
      "1158/1158 [==============================] - 10s 9ms/step - loss: 1.1634 - categorical_accuracy: 0.4361 - val_loss: 0.9422 - val_categorical_accuracy: 0.4341\n",
      "Epoch 3/100\n",
      "1158/1158 [==============================] - 10s 9ms/step - loss: 1.0615 - categorical_accuracy: 0.4603 - val_loss: 0.8404 - val_categorical_accuracy: 0.4264\n",
      "Epoch 4/100\n",
      "1158/1158 [==============================] - 10s 9ms/step - loss: 1.0428 - categorical_accuracy: 0.4767 - val_loss: 0.8600 - val_categorical_accuracy: 0.4806\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     56     54      0\n",
      "fall?      0     21     12      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4722222222222222\n",
      "準正答率（騰落）: 0.4791666666666667\n",
      "学習時間:50.07839608192444[sec]\n",
      "\n",
      "            USD_JPY_Open  USD_JPY_High  USD_JPY_Low  USD_JPY_Close  \\\n",
      "Date                                                                 \n",
      "2009-03-10      0.578359     -0.040339     0.010213      -0.182279   \n",
      "2009-03-11     -0.172143     -0.303061    -0.882147      -1.408618   \n",
      "2009-03-12     -1.418753     -0.324281    -1.442457       0.451283   \n",
      "2009-03-13      0.451283      0.131866     1.524847       0.326931   \n",
      "2009-03-16      0.377918      0.000000     0.861014       0.142697   \n",
      "2009-03-17      0.091710      0.323854     0.112205       0.416731   \n",
      "2009-03-18      0.416731     -0.131439    -2.477162      -2.433260   \n",
      "2009-03-19     -2.402086     -2.282013    -2.261775      -1.761421   \n",
      "2009-03-20     -1.834914     -0.352551     0.649941       1.438723   \n",
      "2009-03-23      1.251397      1.105326     1.580478       1.068198   \n",
      "2009-03-24      1.308158      1.235403     1.318883       0.954784   \n",
      "2009-03-25      0.975117     -0.203149     0.010316      -0.348004   \n",
      "2009-03-26     -0.378653      0.527331     0.514457       1.212754   \n",
      "2009-03-27      1.202624      0.000000    -0.339245      -0.813674   \n",
      "2009-03-30     -0.528188     -0.557839    -1.180871      -0.686584   \n",
      "2009-03-31     -0.961939      1.042150     1.304366       1.753179   \n",
      "2009-04-01      1.732969      0.110658     0.992691      -0.435422   \n",
      "2009-04-02     -0.415211      0.431403     0.203459       0.969509   \n",
      "2009-04-03      0.969509      0.449484     0.940684       0.740967   \n",
      "2009-04-06      0.960199      1.080449     1.011678       0.705803   \n",
      "2009-04-07      0.466757     -0.335770    -0.489536      -0.556274   \n",
      "2009-04-08     -0.536461     -0.247611    -0.562420      -0.649580   \n",
      "2009-04-09     -0.659607     -0.297944     0.341846       0.649580   \n",
      "2009-04-10      0.659607      0.168944     0.580466      -0.079721   \n",
      "2009-04-13      0.009961     -0.019861    -0.359892      -0.199581   \n",
      "2009-04-14     -0.279274     -0.278469    -1.117893      -1.145281   \n",
      "2009-04-15     -1.155269     -0.759776    -0.619700       0.363087   \n",
      "2009-04-16      0.363087     -0.130542     0.386494      -0.070497   \n",
      "2009-04-17     -0.070497      0.210791     0.192688      -0.050385   \n",
      "2009-04-20     -0.050385     -0.361628    -1.079770      -1.298588   \n",
      "...                  ...           ...          ...            ...   \n",
      "2018-09-20     -0.062330      0.115581    -0.107047       0.177968   \n",
      "2018-09-21      0.160199      0.257355     0.320799       0.071098   \n",
      "2018-09-24      0.088889     -0.035458     0.026687       0.204127   \n",
      "2018-09-25      0.186410      0.150609     0.266477       0.150609   \n",
      "2018-09-26      0.159504      0.115019    -0.097626      -0.212691   \n",
      "2018-09-27     -0.257104      0.317825    -0.044407       0.592634   \n",
      "2018-09-28      0.637114      0.211323     0.593421       0.264224   \n",
      "2018-10-01      0.281864      0.289843     0.396599       0.237206   \n",
      "2018-10-02      0.228431     -0.008771    -0.140833      -0.254800   \n",
      "2018-10-03     -0.263621      0.437599    -0.026428       0.736264   \n",
      "2018-10-04      0.701450      0.000000     0.105671      -0.525349   \n",
      "2018-10-05     -0.516842     -0.393753    -0.044016      -0.184526   \n",
      "2018-10-08     -0.149418     -0.131596    -0.662576      -0.423057   \n",
      "2018-10-09     -0.440762     -0.484007     0.044309      -0.247612   \n",
      "2018-10-10     -0.194553     -0.105914    -0.524096      -0.586095   \n",
      "2018-10-11     -0.630469     -0.664513    -0.410532      -0.124766   \n",
      "2018-10-12     -0.142628     -0.008890     0.044705       0.035663   \n",
      "2018-10-15      0.062425     -0.258157    -0.223724      -0.375101   \n",
      "2018-10-16     -0.366186      0.089095     0.107450       0.419662   \n",
      "2018-10-17      0.437481      0.311208     0.223484       0.346898   \n",
      "2018-10-18      0.337958      0.044379    -0.071460      -0.400374   \n",
      "2018-10-19     -0.418169     -0.079897     0.169635       0.320428   \n",
      "2018-10-22      0.320456      0.212917     0.204964       0.204181   \n",
      "2018-10-23      0.204199     -0.035455    -0.338862      -0.328670   \n",
      "2018-10-24     -0.319801     -0.088692     0.133899      -0.169197   \n",
      "2018-10-25     -0.187024     -0.062131    -0.250089       0.151400   \n",
      "2018-10-26      0.187024     -0.204417    -0.394266      -0.437013   \n",
      "2018-10-29     -0.463748      0.097817     0.358488       0.401410   \n",
      "2018-10-30      0.410348      0.461116     0.455216       0.621230   \n",
      "2018-10-31      0.621230      0.282711     0.444287      -0.035395   \n",
      "\n",
      "            USD_JPY_diff  EUR_JPY_Open  EUR_JPY_High  EUR_JPY_Low  \\\n",
      "Date                                                                \n",
      "2009-03-10     -0.182279      0.080257      0.453263     0.297991   \n",
      "2009-03-11     -1.418753      0.384339     -0.254210    -0.241546   \n",
      "2009-03-12      0.451283     -0.199992      0.547338    -1.559866   \n",
      "2009-03-13      0.326931      1.019767      0.976155     2.682122   \n",
      "2009-03-16      0.091710     -0.103097      0.834736     0.461270   \n",
      "2009-03-17      0.416731      1.010508     -0.147716     0.892616   \n",
      "2009-03-18     -2.433260      0.790209      0.998654     0.681848   \n",
      "2009-03-19     -1.792595      1.046562      0.384409     0.109290   \n",
      "2009-03-20      1.481042     -0.409567      0.130363     0.668743   \n",
      "2009-03-23      1.297843      1.193102      1.573878     1.155815   \n",
      "2009-03-24      0.944469      1.133652      1.475185     0.694739   \n",
      "2009-03-25     -0.378653     -0.242388     -1.241602    -0.503395   \n",
      "2009-03-26      1.212754      0.461545      0.779673     1.193341   \n",
      "2009-03-27     -0.803544      0.782018     -0.029875    -2.246427   \n",
      "2009-03-30     -0.961939     -2.449040     -2.503629    -2.337596   \n",
      "2009-03-31      1.753179     -1.484716      1.005953     1.413784   \n",
      "2009-04-01     -0.415211      2.127412      0.015164     1.270941   \n",
      "2009-04-02      0.969509     -0.443324      1.721265     0.353602   \n",
      "2009-04-03      0.740967      2.556291      0.727654     2.148335   \n",
      "2009-04-06      0.486571      1.460313      1.650868     0.941852   \n",
      "2009-04-07     -0.536461     -0.287409     -1.355382    -1.635200   \n",
      "2009-04-08     -0.649580     -1.636941     -1.314196    -0.988000   \n",
      "2009-04-09      0.659607     -0.662354     -0.209487     0.700208   \n",
      "2009-04-10     -0.079721     -0.143586     -0.902805    -0.242995   \n",
      "2009-04-13     -0.289263     -0.022690      1.298963     0.060804   \n",
      "2009-04-14     -1.155269      1.143213      0.171431    -0.418777   \n",
      "2009-04-15      0.363087     -1.910141     -1.894509    -0.865939   \n",
      "2009-04-16     -0.070497      0.152335      0.181984    -0.431933   \n",
      "2009-04-17     -0.050385     -0.411837     -0.417537    -0.449335   \n",
      "2009-04-20     -1.298588     -1.207103     -1.494567    -2.094934   \n",
      "...                  ...           ...           ...          ...   \n",
      "2018-09-20      0.186874     -0.022889      0.620838     0.076429   \n",
      "2018-09-21      0.097773      1.047527      0.451842     0.950469   \n",
      "2018-09-24      0.213012     -0.188957     -0.052610    -0.159049   \n",
      "2018-09-25      0.177211      0.226706      0.052610     0.340510   \n",
      "2018-09-26     -0.194984      0.293952      0.000000    -0.120937   \n",
      "2018-09-27      0.654754     -0.414798     -0.323613    -0.477617   \n",
      "2018-09-28      0.281864     -0.272438     -0.309539    -0.312060   \n",
      "2018-10-01      0.237206     -0.037897      0.143564     0.433576   \n",
      "2018-10-02     -0.246024      0.015161     -0.347932    -0.800157   \n",
      "2018-10-03      0.753861     -0.539617      0.000000     0.191095   \n",
      "2018-10-04     -0.472938      0.068564     -0.303536    -0.168144   \n",
      "2018-10-05     -0.140622     -0.175312     -0.159726    -0.084178   \n",
      "2018-10-08     -0.414262     -0.045784     -0.106626    -0.868869   \n",
      "2018-10-09     -0.221112     -0.735410     -0.780298    -0.146837   \n",
      "2018-10-10     -0.612655     -0.200108      0.207143    -0.015469   \n",
      "2018-10-11     -0.106952     -0.424629     -0.222504    -0.085123   \n",
      "2018-10-12      0.071339      0.509339      0.222504     0.154715   \n",
      "2018-10-15     -0.366186     -0.262063     -0.537925    -0.216668   \n",
      "2018-10-16      0.419662     -0.108108      0.376851     0.232126   \n",
      "2018-10-17      0.329079      0.439426     -0.099843    -0.177915   \n",
      "2018-10-18     -0.409253     -0.346754     -0.330960    -0.668067   \n",
      "2018-10-19      0.329343     -0.852718     -0.053981     0.109060   \n",
      "2018-10-22      0.213068      0.821837      0.392625     0.605451   \n",
      "2018-10-23     -0.319801     -0.154548     -0.616572    -0.808085   \n",
      "2018-10-24     -0.169197     -0.286544     -0.146996    -0.312549   \n",
      "2018-10-25      0.169227     -0.895889     -0.605733    -0.219367   \n",
      "2018-10-26     -0.454810      0.039119     -0.398049    -0.716285   \n",
      "2018-10-29      0.410348     -0.266312      0.242140     0.535730   \n",
      "2018-10-30      0.621230      0.211541      0.155909     0.376442   \n",
      "2018-10-31     -0.035395      0.382768      0.085646    -0.054810   \n",
      "\n",
      "            EUR_JPY_Close  \n",
      "Date                       \n",
      "2009-03-10       0.376317  \n",
      "2009-03-11      -0.199992  \n",
      "2009-03-12       1.035618  \n",
      "2009-03-13       0.332305  \n",
      "2009-03-16       0.567109  \n",
      "2009-03-17       0.790147  \n",
      "2009-03-18       1.054192  \n",
      "2009-03-19      -0.386280  \n",
      "2009-03-20       0.709606  \n",
      "2009-03-23       1.563306  \n",
      "2009-03-24      -0.257595  \n",
      "2009-03-25       0.491885  \n",
      "2009-03-26       0.804485  \n",
      "2009-03-27      -2.517573  \n",
      "2009-03-30      -1.430861  \n",
      "2009-03-31       2.134874  \n",
      "2009-04-01      -0.458576  \n",
      "2009-04-02       2.556291  \n",
      "2009-04-03       0.921666  \n",
      "2009-04-06       0.265997  \n",
      "2009-04-07      -1.659203  \n",
      "2009-04-08      -0.654852  \n",
      "2009-04-09      -0.143586  \n",
      "2009-04-10      -0.113503  \n",
      "2009-04-13       1.271411  \n",
      "2009-04-14      -1.947525  \n",
      "2009-04-15       0.144723  \n",
      "2009-04-16      -0.404226  \n",
      "2009-04-17      -1.261264  \n",
      "2009-04-20      -2.088052  \n",
      "...                   ...  \n",
      "2018-09-20       1.070016  \n",
      "2018-09-21      -0.166201  \n",
      "2018-09-24       0.173749  \n",
      "2018-09-25       0.316504  \n",
      "2018-09-26      -0.422228  \n",
      "2018-09-27      -0.272377  \n",
      "2018-09-28      -0.068210  \n",
      "2018-10-01       0.030321  \n",
      "2018-10-02      -0.531957  \n",
      "2018-10-03       0.167491  \n",
      "2018-10-04      -0.220843  \n",
      "2018-10-05      -0.114421  \n",
      "2018-10-08      -0.704660  \n",
      "2018-10-09      -0.238563  \n",
      "2018-10-10      -0.385982  \n",
      "2018-10-11       0.563034  \n",
      "2018-10-12      -0.277265  \n",
      "2018-10-15      -0.200726  \n",
      "2018-10-16       0.385654  \n",
      "2018-10-17      -0.269802  \n",
      "2018-10-18      -0.844934  \n",
      "2018-10-19       0.898952  \n",
      "2018-10-22      -0.223982  \n",
      "2018-10-23      -0.302010  \n",
      "2018-10-24      -0.841126  \n",
      "2018-10-25      -0.031289  \n",
      "2018-10-26      -0.180103  \n",
      "2018-10-29       0.156629  \n",
      "2018-10-30       0.367116  \n",
      "2018-10-31      -0.351467  \n",
      "\n",
      "[2509 rows x 9 columns]\n",
      "df_t.shape= (2508, 4) \n",
      "\n",
      "x_data.shape = (2508, 9)\n",
      "t_data.shape = (2508, 4) \n",
      "\n",
      "len_seq 2409 \n",
      "\n",
      "x.shape= (2409, 100, 9)\n",
      "t.shape= (2409, 4) \n",
      "\n",
      "x_train.shape= (2168, 100, 9)\n",
      "x_test.shape= (241, 100, 9) \n",
      "\n",
      "t_train.shape= (2168, 4)\n",
      "t_test.shape= (241, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  100 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1951 samples, validate on 217 samples\n",
      "Epoch 1/100\n",
      "1951/1951 [==============================] - 9s 5ms/step - loss: 1.3749 - categorical_accuracy: 0.3234 - val_loss: 1.3368 - val_categorical_accuracy: 0.4562\n",
      "Epoch 2/100\n",
      "1951/1951 [==============================] - 1s 707us/step - loss: 1.3000 - categorical_accuracy: 0.4331 - val_loss: 1.1668 - val_categorical_accuracy: 0.5023\n",
      "Epoch 3/100\n",
      "1951/1951 [==============================] - 1s 647us/step - loss: 1.1063 - categorical_accuracy: 0.4577 - val_loss: 0.8582 - val_categorical_accuracy: 0.4608\n",
      "Epoch 4/100\n",
      "1951/1951 [==============================] - 1s 708us/step - loss: 1.0678 - categorical_accuracy: 0.4557 - val_loss: 0.8690 - val_categorical_accuracy: 0.4470\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    105     95      1\n",
      "fall?      0     19     19      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5145228215767634\n",
      "準正答率（騰落）: 0.5228215767634855\n",
      "学習時間:14.316197872161865[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1951 samples, validate on 217 samples\n",
      "Epoch 1/100\n",
      "1951/1951 [==============================] - 9s 5ms/step - loss: 1.3627 - categorical_accuracy: 0.3537 - val_loss: 1.2982 - val_categorical_accuracy: 0.5069\n",
      "Epoch 2/100\n",
      "1951/1951 [==============================] - 1s 680us/step - loss: 1.1569 - categorical_accuracy: 0.4593 - val_loss: 0.8876 - val_categorical_accuracy: 0.4608\n",
      "Epoch 3/100\n",
      "1951/1951 [==============================] - 1s 702us/step - loss: 1.0541 - categorical_accuracy: 0.4475 - val_loss: 0.9068 - val_categorical_accuracy: 0.5023\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      0      0      0\n",
      "fall?      2    124    114      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4730290456431535\n",
      "準正答率（騰落）: 0.47717842323651455\n",
      "学習時間:13.154594898223877[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1951 samples, validate on 217 samples\n",
      "Epoch 1/100\n",
      "1951/1951 [==============================] - 10s 5ms/step - loss: 1.3563 - categorical_accuracy: 0.3557 - val_loss: 1.2489 - val_categorical_accuracy: 0.5253\n",
      "Epoch 2/100\n",
      "1951/1951 [==============================] - 1s 742us/step - loss: 1.1105 - categorical_accuracy: 0.4680 - val_loss: 0.8915 - val_categorical_accuracy: 0.4608\n",
      "Epoch 3/100\n",
      "1951/1951 [==============================] - 1s 700us/step - loss: 1.0230 - categorical_accuracy: 0.4541 - val_loss: 0.8623 - val_categorical_accuracy: 0.5253\n",
      "Epoch 4/100\n",
      "1951/1951 [==============================] - 1s 702us/step - loss: 1.0171 - categorical_accuracy: 0.4608 - val_loss: 0.8646 - val_categorical_accuracy: 0.5438\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     42     42      0\n",
      "fall?      2     82     72      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4730290456431535\n",
      "準正答率（騰落）: 0.47717842323651455\n",
      "学習時間:15.039889335632324[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1951 samples, validate on 217 samples\n",
      "Epoch 1/100\n",
      "1951/1951 [==============================] - 10s 5ms/step - loss: 1.3370 - categorical_accuracy: 0.3839 - val_loss: 0.9167 - val_categorical_accuracy: 0.5023\n",
      "Epoch 2/100\n",
      "1951/1951 [==============================] - 1s 762us/step - loss: 1.0628 - categorical_accuracy: 0.4700 - val_loss: 0.8819 - val_categorical_accuracy: 0.5253\n",
      "Epoch 3/100\n",
      "1951/1951 [==============================] - 1s 682us/step - loss: 1.0286 - categorical_accuracy: 0.4628 - val_loss: 0.8803 - val_categorical_accuracy: 0.4608\n",
      "Epoch 4/100\n",
      "1951/1951 [==============================] - 1s 745us/step - loss: 1.0211 - categorical_accuracy: 0.4639 - val_loss: 0.8812 - val_categorical_accuracy: 0.5300\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     10      6      0\n",
      "fall?      2    114    108      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4896265560165975\n",
      "準正答率（騰落）: 0.49377593360995853\n",
      "学習時間:15.355080604553223[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  100\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1951 samples, validate on 217 samples\n",
      "Epoch 1/100\n",
      "1951/1951 [==============================] - 10s 5ms/step - loss: 1.3204 - categorical_accuracy: 0.3870 - val_loss: 0.8685 - val_categorical_accuracy: 0.5392\n",
      "Epoch 2/100\n",
      "1951/1951 [==============================] - 2s 789us/step - loss: 1.0569 - categorical_accuracy: 0.4464 - val_loss: 0.8951 - val_categorical_accuracy: 0.5023\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      0      0      0\n",
      "fall?      2    124    114      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4730290456431535\n",
      "準正答率（騰落）: 0.47717842323651455\n",
      "学習時間:12.958203315734863[sec]\n",
      "\n",
      "len_seq 2309 \n",
      "\n",
      "x.shape= (2309, 200, 9)\n",
      "t.shape= (2309, 4) \n",
      "\n",
      "x_train.shape= (2078, 200, 9)\n",
      "x_test.shape= (231, 200, 9) \n",
      "\n",
      "t_train.shape= (2078, 4)\n",
      "t_test.shape= (231, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1870 samples, validate on 208 samples\n",
      "Epoch 1/100\n",
      "1870/1870 [==============================] - 11s 6ms/step - loss: 1.3757 - categorical_accuracy: 0.3139 - val_loss: 1.3384 - val_categorical_accuracy: 0.4183\n",
      "Epoch 2/100\n",
      "1870/1870 [==============================] - 2s 1ms/step - loss: 1.3015 - categorical_accuracy: 0.4428 - val_loss: 1.1800 - val_categorical_accuracy: 0.4856\n",
      "Epoch 3/100\n",
      "1870/1870 [==============================] - 2s 1ms/step - loss: 1.0991 - categorical_accuracy: 0.4497 - val_loss: 0.8267 - val_categorical_accuracy: 0.4712\n",
      "Epoch 4/100\n",
      "1870/1870 [==============================] - 2s 1ms/step - loss: 1.0666 - categorical_accuracy: 0.4620 - val_loss: 0.8433 - val_categorical_accuracy: 0.4519\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    107     98      1\n",
      "fall?      0     10     13      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5194805194805194\n",
      "準正答率（騰落）: 0.5281385281385281\n",
      "学習時間:19.22046160697937[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1870 samples, validate on 208 samples\n",
      "Epoch 1/100\n",
      "1870/1870 [==============================] - 11s 6ms/step - loss: 1.3643 - categorical_accuracy: 0.3390 - val_loss: 1.2931 - val_categorical_accuracy: 0.4952\n",
      "Epoch 2/100\n",
      "1870/1870 [==============================] - 3s 1ms/step - loss: 1.1526 - categorical_accuracy: 0.4567 - val_loss: 0.8326 - val_categorical_accuracy: 0.4471\n",
      "Epoch 3/100\n",
      "1870/1870 [==============================] - 2s 1ms/step - loss: 1.0504 - categorical_accuracy: 0.4471 - val_loss: 0.8852 - val_categorical_accuracy: 0.5192\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     41     37      0\n",
      "fall?      2     76     74      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.49783549783549785\n",
      "準正答率（騰落）: 0.5021645021645021\n",
      "学習時間:17.119880437850952[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1870 samples, validate on 208 samples\n",
      "Epoch 1/100\n",
      "1870/1870 [==============================] - 11s 6ms/step - loss: 1.3627 - categorical_accuracy: 0.3321 - val_loss: 1.2731 - val_categorical_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1870/1870 [==============================] - 2s 1ms/step - loss: 1.1184 - categorical_accuracy: 0.4727 - val_loss: 0.8771 - val_categorical_accuracy: 0.4904\n",
      "Epoch 3/100\n",
      "1870/1870 [==============================] - 2s 1ms/step - loss: 1.0291 - categorical_accuracy: 0.4647 - val_loss: 0.8391 - val_categorical_accuracy: 0.4808\n",
      "Epoch 4/100\n",
      "1870/1870 [==============================] - 2s 1ms/step - loss: 1.0295 - categorical_accuracy: 0.4626 - val_loss: 0.8463 - val_categorical_accuracy: 0.4856\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    104    100      1\n",
      "fall?      0     13     11      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.49783549783549785\n",
      "準正答率（騰落）: 0.5064935064935064\n",
      "学習時間:19.690476894378662[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1870 samples, validate on 208 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1870/1870 [==============================] - 12s 6ms/step - loss: 1.3416 - categorical_accuracy: 0.3781 - val_loss: 0.8837 - val_categorical_accuracy: 0.4952\n",
      "Epoch 2/100\n",
      "1870/1870 [==============================] - 3s 1ms/step - loss: 1.0857 - categorical_accuracy: 0.4642 - val_loss: 0.9736 - val_categorical_accuracy: 0.4904\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      0      0      0\n",
      "fall?      2    117    111      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4805194805194805\n",
      "準正答率（騰落）: 0.48484848484848486\n",
      "学習時間:15.534166097640991[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  200\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1870 samples, validate on 208 samples\n",
      "Epoch 1/100\n",
      "1870/1870 [==============================] - 12s 6ms/step - loss: 1.3256 - categorical_accuracy: 0.3877 - val_loss: 0.9352 - val_categorical_accuracy: 0.4904\n",
      "Epoch 2/100\n",
      "1870/1870 [==============================] - 3s 1ms/step - loss: 1.0675 - categorical_accuracy: 0.4738 - val_loss: 0.8513 - val_categorical_accuracy: 0.4471\n",
      "Epoch 3/100\n",
      "1870/1870 [==============================] - 3s 1ms/step - loss: 1.0216 - categorical_accuracy: 0.4529 - val_loss: 0.8618 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     13      9      0\n",
      "fall?      2    104    102      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.49783549783549785\n",
      "準正答率（騰落）: 0.5021645021645021\n",
      "学習時間:18.650238037109375[sec]\n",
      "\n",
      "len_seq 2209 \n",
      "\n",
      "x.shape= (2209, 300, 9)\n",
      "t.shape= (2209, 4) \n",
      "\n",
      "x_train.shape= (1988, 300, 9)\n",
      "x_test.shape= (221, 300, 9) \n",
      "\n",
      "t_train.shape= (1988, 4)\n",
      "t_test.shape= (221, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1789 samples, validate on 199 samples\n",
      "Epoch 1/100\n",
      "1789/1789 [==============================] - 13s 7ms/step - loss: 1.3721 - categorical_accuracy: 0.3231 - val_loss: 1.3454 - val_categorical_accuracy: 0.4724\n",
      "Epoch 2/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.3197 - categorical_accuracy: 0.4108 - val_loss: 1.2477 - val_categorical_accuracy: 0.4824\n",
      "Epoch 3/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.1625 - categorical_accuracy: 0.4606 - val_loss: 0.8536 - val_categorical_accuracy: 0.4824\n",
      "Epoch 4/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.0581 - categorical_accuracy: 0.4762 - val_loss: 0.8281 - val_categorical_accuracy: 0.4925\n",
      "Epoch 5/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.0422 - categorical_accuracy: 0.4572 - val_loss: 0.8465 - val_categorical_accuracy: 0.5025\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     33     35      0\n",
      "fall?      2     78     72      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4751131221719457\n",
      "準正答率（騰落）: 0.4796380090497738\n",
      "学習時間:25.671562910079956[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1789 samples, validate on 199 samples\n",
      "Epoch 1/100\n",
      "1789/1789 [==============================] - 13s 7ms/step - loss: 1.3664 - categorical_accuracy: 0.3633 - val_loss: 1.3204 - val_categorical_accuracy: 0.5025\n",
      "Epoch 2/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.2097 - categorical_accuracy: 0.4505 - val_loss: 0.8222 - val_categorical_accuracy: 0.4824\n",
      "Epoch 3/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.0456 - categorical_accuracy: 0.4757 - val_loss: 0.8473 - val_categorical_accuracy: 0.4774\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     99     99      1\n",
      "fall?      0     12      8      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4841628959276018\n",
      "準正答率（騰落）: 0.49321266968325794\n",
      "学習時間:20.470264434814453[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1789 samples, validate on 199 samples\n",
      "Epoch 1/100\n",
      "1789/1789 [==============================] - 13s 7ms/step - loss: 1.3650 - categorical_accuracy: 0.3443 - val_loss: 1.3008 - val_categorical_accuracy: 0.4774\n",
      "Epoch 2/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.1518 - categorical_accuracy: 0.4617 - val_loss: 0.8123 - val_categorical_accuracy: 0.4824\n",
      "Epoch 3/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.0240 - categorical_accuracy: 0.4634 - val_loss: 0.8823 - val_categorical_accuracy: 0.5126\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     29     22      0\n",
      "fall?      2     82     85      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5158371040723982\n",
      "準正答率（騰落）: 0.5203619909502263\n",
      "学習時間:20.40481185913086[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1789 samples, validate on 199 samples\n",
      "Epoch 1/100\n",
      "1789/1789 [==============================] - 13s 8ms/step - loss: 1.3534 - categorical_accuracy: 0.3561 - val_loss: 1.2281 - val_categorical_accuracy: 0.5276\n",
      "Epoch 2/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.1065 - categorical_accuracy: 0.4572 - val_loss: 0.9382 - val_categorical_accuracy: 0.4724\n",
      "Epoch 3/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.0398 - categorical_accuracy: 0.4589 - val_loss: 0.8193 - val_categorical_accuracy: 0.5226\n",
      "Epoch 4/100\n",
      "1789/1789 [==============================] - 3s 2ms/step - loss: 1.0148 - categorical_accuracy: 0.4639 - val_loss: 0.8659 - val_categorical_accuracy: 0.5377\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     42     40      0\n",
      "fall?      1     69     67      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.49321266968325794\n",
      "準正答率（騰落）: 0.502262443438914\n",
      "学習時間:24.623743295669556[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  300\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1789 samples, validate on 199 samples\n",
      "Epoch 1/100\n",
      "1789/1789 [==============================] - 14s 8ms/step - loss: 1.3383 - categorical_accuracy: 0.3784 - val_loss: 0.8485 - val_categorical_accuracy: 0.4824\n",
      "Epoch 2/100\n",
      "1789/1789 [==============================] - 4s 2ms/step - loss: 1.0717 - categorical_accuracy: 0.4707 - val_loss: 0.8803 - val_categorical_accuracy: 0.4925\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    111    107      1\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.502262443438914\n",
      "準正答率（騰落）: 0.5113122171945701\n",
      "学習時間:18.972657680511475[sec]\n",
      "\n",
      "len_seq 2109 \n",
      "\n",
      "x.shape= (2109, 400, 9)\n",
      "t.shape= (2109, 4) \n",
      "\n",
      "x_train.shape= (1898, 400, 9)\n",
      "x_test.shape= (211, 400, 9) \n",
      "\n",
      "t_train.shape= (1898, 4)\n",
      "t_test.shape= (211, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1708 samples, validate on 190 samples\n",
      "Epoch 1/100\n",
      "1708/1708 [==============================] - 15s 9ms/step - loss: 1.3783 - categorical_accuracy: 0.2910 - val_loss: 1.3438 - val_categorical_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.3177 - categorical_accuracy: 0.4333 - val_loss: 1.2477 - val_categorical_accuracy: 0.4895\n",
      "Epoch 3/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.1804 - categorical_accuracy: 0.4368 - val_loss: 0.8190 - val_categorical_accuracy: 0.4789\n",
      "Epoch 4/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.0771 - categorical_accuracy: 0.4643 - val_loss: 0.8011 - val_categorical_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.0284 - categorical_accuracy: 0.4602 - val_loss: 0.8442 - val_categorical_accuracy: 0.4895\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     76     74      0\n",
      "fall?      2     30     28      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4928909952606635\n",
      "準正答率（騰落）: 0.4976303317535545\n",
      "学習時間:31.579468965530396[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1708 samples, validate on 190 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1708/1708 [==============================] - 15s 9ms/step - loss: 1.3681 - categorical_accuracy: 0.3372 - val_loss: 1.3142 - val_categorical_accuracy: 0.4684\n",
      "Epoch 2/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.2049 - categorical_accuracy: 0.4473 - val_loss: 0.8211 - val_categorical_accuracy: 0.4789\n",
      "Epoch 3/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.0480 - categorical_accuracy: 0.4678 - val_loss: 0.8346 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    106    102      1\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5023696682464455\n",
      "準正答率（騰落）: 0.5118483412322274\n",
      "学習時間:24.139015436172485[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1708 samples, validate on 190 samples\n",
      "Epoch 1/100\n",
      "1708/1708 [==============================] - 15s 9ms/step - loss: 1.3680 - categorical_accuracy: 0.3173 - val_loss: 1.2973 - val_categorical_accuracy: 0.4579\n",
      "Epoch 2/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.1385 - categorical_accuracy: 0.4655 - val_loss: 0.8208 - val_categorical_accuracy: 0.4789\n",
      "Epoch 3/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.0182 - categorical_accuracy: 0.4567 - val_loss: 0.8942 - val_categorical_accuracy: 0.4579\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     99     95      1\n",
      "fall?      0      7      7      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5023696682464455\n",
      "準正答率（騰落）: 0.5118483412322274\n",
      "学習時間:24.290300846099854[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1708 samples, validate on 190 samples\n",
      "Epoch 1/100\n",
      "1708/1708 [==============================] - 15s 9ms/step - loss: 1.3543 - categorical_accuracy: 0.4052 - val_loss: 1.2382 - val_categorical_accuracy: 0.4895\n",
      "Epoch 2/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.0960 - categorical_accuracy: 0.4783 - val_loss: 0.9569 - val_categorical_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.0280 - categorical_accuracy: 0.4590 - val_loss: 0.8087 - val_categorical_accuracy: 0.4842\n",
      "Epoch 4/100\n",
      "1708/1708 [==============================] - 4s 2ms/step - loss: 1.0113 - categorical_accuracy: 0.4526 - val_loss: 0.8528 - val_categorical_accuracy: 0.5000\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     72     76      0\n",
      "fall?      1     34     26      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.46445497630331756\n",
      "準正答率（騰落）: 0.47393364928909953\n",
      "学習時間:29.117711067199707[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  400\n",
      "n_hidden:  500 \n",
      "\n",
      "Train on 1708 samples, validate on 190 samples\n",
      "Epoch 1/100\n",
      "1708/1708 [==============================] - 16s 9ms/step - loss: 1.3459 - categorical_accuracy: 0.3788 - val_loss: 0.8984 - val_categorical_accuracy: 0.4789\n",
      "Epoch 2/100\n",
      "1708/1708 [==============================] - 5s 3ms/step - loss: 1.0950 - categorical_accuracy: 0.4672 - val_loss: 0.8697 - val_categorical_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1708/1708 [==============================] - 4s 3ms/step - loss: 1.0141 - categorical_accuracy: 0.4666 - val_loss: 0.8121 - val_categorical_accuracy: 0.4684\n",
      "Epoch 4/100\n",
      "1708/1708 [==============================] - 4s 3ms/step - loss: 1.0036 - categorical_accuracy: 0.4637 - val_loss: 0.8637 - val_categorical_accuracy: 0.4684\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     82     74      0\n",
      "fall?      1     24     28      1\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5213270142180095\n",
      "準正答率（騰落）: 0.5308056872037915\n",
      "学習時間:30.82355284690857[sec]\n",
      "\n",
      "len_seq 2009 \n",
      "\n",
      "x.shape= (2009, 500, 9)\n",
      "t.shape= (2009, 4) \n",
      "\n",
      "x_train.shape= (1808, 500, 9)\n",
      "x_test.shape= (201, 500, 9) \n",
      "\n",
      "t_train.shape= (1808, 4)\n",
      "t_test.shape= (201, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1627 samples, validate on 181 samples\n",
      "Epoch 1/100\n",
      "1627/1627 [==============================] - 17s 10ms/step - loss: 1.3737 - categorical_accuracy: 0.3227 - val_loss: 1.3469 - val_categorical_accuracy: 0.4254\n",
      "Epoch 2/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.3215 - categorical_accuracy: 0.4210 - val_loss: 1.2458 - val_categorical_accuracy: 0.4696\n",
      "Epoch 3/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.1726 - categorical_accuracy: 0.4616 - val_loss: 0.8117 - val_categorical_accuracy: 0.4972\n",
      "Epoch 4/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.0774 - categorical_accuracy: 0.4634 - val_loss: 0.8184 - val_categorical_accuracy: 0.4807\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2    103     96      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5124378109452736\n",
      "準正答率（騰落）: 0.5223880597014925\n",
      "学習時間:32.255407094955444[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1627 samples, validate on 181 samples\n",
      "Epoch 1/100\n",
      "1627/1627 [==============================] - 17s 10ms/step - loss: 1.3722 - categorical_accuracy: 0.3042 - val_loss: 1.3186 - val_categorical_accuracy: 0.5304\n",
      "Epoch 2/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.2369 - categorical_accuracy: 0.4284 - val_loss: 0.8002 - val_categorical_accuracy: 0.5138\n",
      "Epoch 3/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.0696 - categorical_accuracy: 0.4487 - val_loss: 0.8369 - val_categorical_accuracy: 0.5304\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      3      6      0\n",
      "fall?      2    100     90      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4626865671641791\n",
      "準正答率（騰落）: 0.4626865671641791\n",
      "学習時間:27.592390775680542[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1627 samples, validate on 181 samples\n",
      "Epoch 1/100\n",
      "1627/1627 [==============================] - 17s 11ms/step - loss: 1.3688 - categorical_accuracy: 0.2987 - val_loss: 1.2970 - val_categorical_accuracy: 0.5028\n",
      "Epoch 2/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.1782 - categorical_accuracy: 0.4579 - val_loss: 0.7980 - val_categorical_accuracy: 0.4862\n",
      "Epoch 3/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.0493 - categorical_accuracy: 0.4665 - val_loss: 0.8741 - val_categorical_accuracy: 0.5249\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     16     14      0\n",
      "fall?      1     87     82      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.48756218905472637\n",
      "準正答率（騰落）: 0.4925373134328358\n",
      "学習時間:28.92340612411499[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1627 samples, validate on 181 samples\n",
      "Epoch 1/100\n",
      "1627/1627 [==============================] - 18s 11ms/step - loss: 1.3593 - categorical_accuracy: 0.3596 - val_loss: 1.1851 - val_categorical_accuracy: 0.5249\n",
      "Epoch 2/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.1370 - categorical_accuracy: 0.4610 - val_loss: 0.9587 - val_categorical_accuracy: 0.5083\n",
      "Epoch 3/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.0567 - categorical_accuracy: 0.4530 - val_loss: 0.8277 - val_categorical_accuracy: 0.4972\n",
      "Epoch 4/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.0112 - categorical_accuracy: 0.4794 - val_loss: 0.8115 - val_categorical_accuracy: 0.4862\n",
      "Epoch 5/100\n",
      "1627/1627 [==============================] - 5s 3ms/step - loss: 1.0140 - categorical_accuracy: 0.4561 - val_loss: 0.8448 - val_categorical_accuracy: 0.5856\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      1     39     39      0\n",
      "fall?      1     64     57      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.47761194029850745\n",
      "準正答率（騰落）: 0.48258706467661694\n",
      "学習時間:39.5489068031311[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  500\n",
      "n_hidden:  500 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1627 samples, validate on 181 samples\n",
      "Epoch 1/100\n",
      "1627/1627 [==============================] - 19s 11ms/step - loss: 1.3462 - categorical_accuracy: 0.3860 - val_loss: 0.7957 - val_categorical_accuracy: 0.5359\n",
      "Epoch 2/100\n",
      "1627/1627 [==============================] - 6s 3ms/step - loss: 1.0722 - categorical_accuracy: 0.4591 - val_loss: 0.8435 - val_categorical_accuracy: 0.5138\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      3      0      0\n",
      "fall?      2    100     96      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4925373134328358\n",
      "準正答率（騰落）: 0.4925373134328358\n",
      "学習時間:25.42298674583435[sec]\n",
      "\n",
      "len_seq 1909 \n",
      "\n",
      "x.shape= (1909, 600, 9)\n",
      "t.shape= (1909, 4) \n",
      "\n",
      "x_train.shape= (1718, 600, 9)\n",
      "x_test.shape= (191, 600, 9) \n",
      "\n",
      "t_train.shape= (1718, 4)\n",
      "t_test.shape= (191, 4) \n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  600\n",
      "n_hidden:  100 \n",
      "\n",
      "Train on 1546 samples, validate on 172 samples\n",
      "Epoch 1/100\n",
      "1546/1546 [==============================] - 19s 12ms/step - loss: 1.3742 - categorical_accuracy: 0.3260 - val_loss: 1.3488 - val_categorical_accuracy: 0.3895\n",
      "Epoch 2/100\n",
      "1546/1546 [==============================] - 6s 4ms/step - loss: 1.3267 - categorical_accuracy: 0.4153 - val_loss: 1.2665 - val_categorical_accuracy: 0.5233\n",
      "Epoch 3/100\n",
      "1546/1546 [==============================] - 6s 4ms/step - loss: 1.2187 - categorical_accuracy: 0.4586 - val_loss: 0.9164 - val_categorical_accuracy: 0.4942\n",
      "Epoch 4/100\n",
      "1546/1546 [==============================] - 6s 4ms/step - loss: 1.0626 - categorical_accuracy: 0.4508 - val_loss: 0.7878 - val_categorical_accuracy: 0.4884\n",
      "Epoch 5/100\n",
      "1546/1546 [==============================] - 6s 4ms/step - loss: 1.0556 - categorical_accuracy: 0.4618 - val_loss: 0.7909 - val_categorical_accuracy: 0.5116\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0     58     47      0\n",
      "fall?      2     39     45      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5392670157068062\n",
      "準正答率（騰落）: 0.5392670157068062\n",
      "学習時間:43.13920283317566[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  600\n",
      "n_hidden:  200 \n",
      "\n",
      "Train on 1546 samples, validate on 172 samples\n",
      "Epoch 1/100\n",
      "1546/1546 [==============================] - 19s 12ms/step - loss: 1.3707 - categorical_accuracy: 0.3344 - val_loss: 1.3159 - val_categorical_accuracy: 0.5465\n",
      "Epoch 2/100\n",
      "1546/1546 [==============================] - 6s 4ms/step - loss: 1.2625 - categorical_accuracy: 0.4528 - val_loss: 0.8215 - val_categorical_accuracy: 0.4942\n",
      "Epoch 3/100\n",
      "1546/1546 [==============================] - 6s 4ms/step - loss: 1.0707 - categorical_accuracy: 0.4508 - val_loss: 0.8065 - val_categorical_accuracy: 0.4884\n",
      "Epoch 4/100\n",
      "1546/1546 [==============================] - 6s 4ms/step - loss: 1.0282 - categorical_accuracy: 0.4625 - val_loss: 0.8396 - val_categorical_accuracy: 0.4942\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      0      0      0      0\n",
      "fall?      2     97     92      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.4816753926701571\n",
      "準正答率（騰落）: 0.4816753926701571\n",
      "学習時間:38.64156985282898[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  600\n",
      "n_hidden:  300 \n",
      "\n",
      "Train on 1546 samples, validate on 172 samples\n",
      "Epoch 1/100\n",
      "1546/1546 [==============================] - 19s 13ms/step - loss: 1.3684 - categorical_accuracy: 0.3254 - val_loss: 1.2998 - val_categorical_accuracy: 0.5116\n",
      "Epoch 2/100\n",
      "1546/1546 [==============================] - 6s 4ms/step - loss: 1.1978 - categorical_accuracy: 0.4534 - val_loss: 0.7816 - val_categorical_accuracy: 0.4942\n",
      "Epoch 3/100\n",
      "1546/1546 [==============================] - 6s 4ms/step - loss: 1.0385 - categorical_accuracy: 0.4489 - val_loss: 0.9039 - val_categorical_accuracy: 0.4884\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "        jump!  rise!  fall!  drop!\n",
      "jump?      0      0      0      0\n",
      "rise?      2     97     92      0\n",
      "fall?      0      0      0      0\n",
      "drop?      0      0      0      0 \n",
      "\n",
      "正答率: 0.5078534031413613\n",
      "準正答率（騰落）: 0.518324607329843\n",
      "学習時間:32.77224946022034[sec]\n",
      "\n",
      "model:  LSTM\n",
      "day:  1\n",
      "since:  2009-3-10\n",
      "maxlen:  600\n",
      "n_hidden:  400 \n",
      "\n",
      "Train on 1546 samples, validate on 172 samples\n",
      "Epoch 1/100\n",
      "1546/1546 [==============================] - 21s 14ms/step - loss: 1.3612 - categorical_accuracy: 0.3376 - val_loss: 1.2443 - val_categorical_accuracy: 0.5174\n",
      "Epoch 2/100\n",
      "1546/1546 [==============================] - 7s 4ms/step - loss: 1.1467 - categorical_accuracy: 0.4567 - val_loss: 0.8721 - val_categorical_accuracy: 0.4884\n",
      "Epoch 3/100\n",
      "1546/1546 [==============================] - 7s 4ms/step - loss: 1.0281 - categorical_accuracy: 0.4631 - val_loss: 0.8055 - val_categorical_accuracy: 0.4942\n",
      "Epoch 4/100\n",
      " 512/1546 [========>.....................] - ETA: 3s - loss: 0.9801 - categorical_accuracy: 0.4785"
     ]
    }
   ],
   "source": [
    "result_csv = pd.DataFrame(columns=['time', 'day', 'model', 'start date', 'end date', 'maxlen', 'n_hidden', 'correct', 'semi_correct', 'combination'])\n",
    "debug_csv = pd.DataFrame(columns=['time', 'x_train.shape', 't_train.shape', 'batch size', 'epochs'])\n",
    "\n",
    "# 学習モデル\n",
    "for learning_model in learning_model_list:\n",
    "    # 学習期間\n",
    "    for year in year_list:\n",
    "        while True:\n",
    "            # 学習データ\n",
    "            max_correct_number = -1 # 最高正答率を出したデータフレームの番号 \n",
    "            for df, df_name, df_number in zip(df_list, df_list_name, range(len(df_list))):\n",
    "                # 基本となる入力をdf_xに代入\n",
    "                df_x = df_target\n",
    "            \n",
    "                # データフレームを一つ加える\n",
    "                df_x = df_x.join(df, how='inner', rsuffix='_' + df_name)         \n",
    "            \n",
    "                #指定の期間を抽出\n",
    "                if end_date == '':\n",
    "                    df_x = df_x[year:]\n",
    "                else:\n",
    "                    df_x = df_x[year:end_date]\n",
    "                \n",
    "                # ●デバッグ\n",
    "                if is_debug == True:\n",
    "                    print(df_x)\n",
    "            \n",
    "                # ラベルデータを作成する列を抽出------------------------------------------------------\n",
    "                target = df_x[target_name]\n",
    "            \n",
    "                #空のデータフレーム作成\n",
    "                df_t = pd.DataFrame(index=df_x.index, columns=['jump', 'rise', 'fall', 'drop'])\n",
    "                df_t = df_t.fillna(0) #０で埋める\n",
    "\n",
    "                #条件にあった値を置換する\n",
    "                df_t.loc[0.995033085 <= target, 'jump'] = 1\n",
    "                df_t.loc[(0 <= target) & (target < 0.995033085), 'rise'] = 1\n",
    "                df_t.loc[(-0.995033085 <= target) & (target < 0), 'fall'] = 1\n",
    "                df_t.loc[target < -0.995033085, 'drop'] = 1\n",
    "\n",
    "                df_t = df_t.shift(-1 * x_days_later, axis=0)#予測先日数分だけ縦にずらす\n",
    "                df_t = df_t.drop(df_t.index[-1*x_days_later:], axis=0)#ラベルデータ末尾の行を削除\n",
    "                df_x = df_x.drop(df_x.index[-1*x_days_later:], axis=0)#学習データの末尾の行を削除\n",
    "\n",
    "                # ●デバッグ\n",
    "                if is_debug == True:\n",
    "                    print('df_t.shape=', df_t.shape, '\\n')\n",
    "            \n",
    "                #インデックスと列名を外し２次元配列に変換------------------------------------\n",
    "                x_data = df_x.values\n",
    "                t_data = df_t.values\n",
    "        \n",
    "                if is_debug == True:\n",
    "                    print('x_data.shape =', x_data.shape)\n",
    "                    print('t_data.shape =', t_data.shape, '\\n')\n",
    "            \n",
    "                # 入力系列------------------------------------------------------\n",
    "                maxlen = min_maxlen\n",
    "                while maxlen <= max_maxlen:\n",
    "                    n_in = x_data.shape[1]   # 学習データ（＝入力）の列数\n",
    "                    n_out = t_data.shape[1]  # ラベルデータ（=出力）の列数\n",
    "                    len_seq = x_data.shape[0] - maxlen + 1\n",
    "                    print('len_seq', len_seq, '\\n')#●デバッグ\n",
    "                    data = []\n",
    "                    target = []\n",
    "\n",
    "                    #\n",
    "                    for i in range(0, len_seq):\n",
    "                        data.append(x_data[i:i+maxlen, :])\n",
    "                        target.append(t_data[i+maxlen-1, :])\n",
    "\n",
    "                    x = np.array(data).reshape(len(data), maxlen, n_in)\n",
    "                    t = np.array(target).reshape(len(data), n_out)\n",
    "\n",
    "                    if is_debug == True:\n",
    "                        print('x.shape=', x.shape)\n",
    "                        print('t.shape=', t.shape, '\\n')\n",
    "\n",
    "                    # ここからソースコードの後半\n",
    "                    n_train = int(len(data)*0.9)              # 訓練データ長\n",
    "                    x_train,x_test = np.vsplit(x, [n_train])  # 学習データを訓練用とテスト用に分割\n",
    "                    t_train,t_test = np.vsplit(t, [n_train])  # ラベルデータを訓練用とテスト用に分割\n",
    "\n",
    "                    if is_debug == True:\n",
    "                        print('x_train.shape=', x_train.shape)\n",
    "                        print('x_test.shape=', x_test.shape, '\\n')\n",
    "                        print('t_train.shape=', t_train.shape)\n",
    "                        print('t_test.shape=', t_test.shape, '\\n')\n",
    "                   \n",
    "                    # メイン処理----------------------------------------------------------\n",
    "                    # 隠れ層のユニット\n",
    "                    n_hidden = min_n_hidden\n",
    "                    while n_hidden <= max_n_hidden:\n",
    "                        epochs = 100      # エポック数（同じデータでの学習回数）\n",
    "                        batch_size = 256  #バッチサイズ\n",
    "                \n",
    "                        #パラメータの表示\n",
    "                        print('model: ', learning_model)\n",
    "                        print('day: ', x_days_later)\n",
    "                        print('since: ', year)\n",
    "                        print('maxlen: ', maxlen)\n",
    "                        print('n_hidden: ', n_hidden, '\\n')\n",
    "                \n",
    "                        # モデル定義\n",
    "                        prediction = Prediction(maxlen, n_hidden, n_in, n_out, learning_model)\n",
    "                    \n",
    "                        # 学習時間の計測開始\n",
    "                        start = time.time()\n",
    "                    \n",
    "                        # 学習（●学習時間がどんどん伸びていくのはなぜなのか？）\n",
    "                        model = prediction.train(x_train, t_train, batch_size, epochs)\n",
    "                    \n",
    "                        # 学習時間の計測終了と表示\n",
    "                        end = time.time()\n",
    "\n",
    "                        #予測精度の評価------------------------------------------------------\n",
    "\n",
    "                        # 正答率、準正答率（騰落）集計\n",
    "                        preds = model.predict(x_test)\n",
    "                \n",
    "                        #正解数を数える変数\n",
    "                        correct = 0\n",
    "                        semi_correct = 0\n",
    "                \n",
    "                        #表を作るためのデータフレーム\n",
    "                        matrix = pd.DataFrame(columns=['jump!', 'rise!', 'fall!', 'drop!'], index=['jump?', 'rise?', 'fall?', 'drop?'])\n",
    "                        matrix = matrix.fillna(0)\n",
    "\n",
    "                        #正解数を数える\n",
    "                        for i in range(len(preds)):\n",
    "                            pred = np.argmax(preds[i,:])#argmaxとは配列の最大要素のインデックスを返すメソッドである\n",
    "                            tar = np.argmax(t_test[i,:])\n",
    "                            matrix.iat[pred, tar] = matrix.iat[pred, tar] + 1 #●マトリックスのセルをインクリメント\n",
    "                            if pred == tar :#完全一致\n",
    "                               correct += 1\n",
    "                            else :\n",
    "                                if pred+tar == 1 or pred+tar == 5 :\n",
    "                                    semi_correct += 1\n",
    "                \n",
    "                        #正答率と準正答率を求める\n",
    "                        correct_rate = 1.0 *correct / len(preds) \n",
    "                        semi_correct_rate = 1.0 * (correct+semi_correct) / len(preds)\n",
    "                    \n",
    "                        # もし正答率が最高記録をだしたら更新\n",
    "                        if semi_correct_rate > max_correct:\n",
    "                            max_correct = semi_correct_rate\n",
    "                            max_correct_number = df_number\n",
    "                \n",
    "                        #csvに記録\n",
    "                        series = pd.Series([int(end - start),\n",
    "                                            x_days_later,\n",
    "                                            learning_model,\n",
    "                                            year,\n",
    "                                            end_date,\n",
    "                                            maxlen,\n",
    "                                            n_hidden,\n",
    "                                            correct_rate,\n",
    "                                            semi_correct_rate,\n",
    "                                            df_x_name + ' ' + df_name],\n",
    "                                            index = result_csv.columns)\n",
    "                        result_csv = result_csv.append(series, ignore_index = True)\n",
    "                        result_csv.to_csv('./log/log.csv', index=False)\n",
    "                        \n",
    "                        #csvに記録\n",
    "                        series2 = pd.Series([int(end - start),\n",
    "                                             x_train.shape,\n",
    "                                             t_train.shape,\n",
    "                                             batch_size,\n",
    "                                             epochs],\n",
    "                                             index = debug_csv.columns)\n",
    "                        debug_csv = debug_csv.append(series2, ignore_index = True)\n",
    "                        debug_csv.to_csv('./log/debug.csv', index=False)\n",
    "                \n",
    "                        #表と正答率と学習時間を表示\n",
    "                        print('\\n', matrix, '\\n')\n",
    "                        print(\"正答率:\", 1.0 * correct / len(preds))\n",
    "                        print(\"準正答率（騰落）:\", 1.0 * (correct+semi_correct) / len(preds))\n",
    "                        print (\"学習時間:{0}\".format(end - start) + \"[sec]\\n\")\n",
    "                \n",
    "                \n",
    "                        #次のステップへ\n",
    "                        #del prediction # 効果なし\n",
    "                        #gc.collect() # 効果なし\n",
    "                        n_hidden += 100\n",
    "                    \n",
    "                    #次のステップへ\n",
    "                    maxlen += 100\n",
    "            \n",
    "            # もし正答率を更新しなければ\n",
    "            if max_correct_number == -1:\n",
    "                break\n",
    "            else:# そうでなければ新たなデータフレームをdf_targetに付属させてもう一回\n",
    "                df_target = df_target.join(df_list.pop(max_correct_number))\n",
    "                df_x_name += ' ' + df_list_name.pop(max_correct_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算終了の合図"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    winsound.Beep(784,300)\n",
    "    winsound.Beep(698,300)\n",
    "    winsound.Beep(784,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
